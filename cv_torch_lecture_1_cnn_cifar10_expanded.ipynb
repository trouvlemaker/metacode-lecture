{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae167db",
   "metadata": {},
   "source": [
    "# 📘 1강 (PyTorch, CPU): CIFAR-10 분류 — **데이터 탐색 → MLP vs CNN → 내부 시각화 → 오분류 분석 → 개선 → 챌린지**\n",
    "\n",
    "> **촬영용 스크립트 가이드 포함**: 각 섹션 상단에 말하기 포인트와 질문 프롬프트를 넣었습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2804145",
   "metadata": {},
   "source": [
    "## 0. 환경 설정 및 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09765e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, numpy as np, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "# 역정규화 유틸\n",
    "inv_mean = np.array([0.4914,0.4822,0.4465])\n",
    "inv_std  = np.array([0.2470,0.2435,0.2616])\n",
    "def denorm(img_tensor):\n",
    "    img = img_tensor.permute(1,2,0).cpu().numpy()\n",
    "    img = img * inv_std + inv_mean\n",
    "    return np.clip(img, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab86de3",
   "metadata": {},
   "source": [
    "## 1. 데이터 탐색 심화 (≈6분)\n",
    "\n",
    "**말하기 포인트:**  \n",
    "- 사람은 선/색/질감으로 사물을 구분합니다. 모델도 비슷한 단서(특징)를 학습합니다.\n",
    "- CIFAR-10의 크기/채널/범위를 확인하고, 입력 전처리의 필요성을 짚습니다.\n",
    "\n",
    "**질문:** “여러분은 자동차와 개를 사진에서 어떻게 구분하시나요?”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dab88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리: 정규화\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616))\n",
    "])\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616))\n",
    "])\n",
    "\n",
    "root='./data'\n",
    "train_full = datasets.CIFAR10(root=root, train=True, download=True, transform=train_tf)\n",
    "test_set   = datasets.CIFAR10(root=root, train=False, download=True, transform=test_tf)\n",
    "class_names = train_full.classes\n",
    "\n",
    "# Split\n",
    "val_ratio=0.2\n",
    "val_len  = int(len(train_full)*val_ratio)\n",
    "train_len= len(train_full)-val_len\n",
    "train_set, val_set = random_split(train_full,[train_len,val_len])\n",
    "\n",
    "train_loader=DataLoader(train_set,batch_size=128,shuffle=True,num_workers=0)\n",
    "val_loader  =DataLoader(val_set,  batch_size=128,shuffle=False,num_workers=0)\n",
    "test_loader =DataLoader(test_set,  batch_size=128,shuffle=False,num_workers=0)\n",
    "\n",
    "print('Train/Val/Test sizes:', len(train_set), len(val_set), len(test_set))\n",
    "print('Sample image shape (C,H,W):', train_set[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82964fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 클래스별 샘플 5장씩 시각화\n",
    "import math\n",
    "fig, axes = plt.subplots(10, 5, figsize=(8,16))\n",
    "counts = {c:0 for c in class_names}\n",
    "for x,y in train_loader:\n",
    "    for img, lab in zip(x, y):\n",
    "        c = class_names[lab.item()]\n",
    "        if counts[c] < 5:\n",
    "            ax = axes[class_names.index(c), counts[c]]\n",
    "            ax.imshow(denorm(img)); ax.set_axis_off()\n",
    "            if counts[c]==0: ax.set_ylabel(c, rotation=0, labelpad=30, va='center')\n",
    "            counts[c]+=1\n",
    "    if all(counts[c]>=5 for c in class_names): break\n",
    "plt.suptitle('각 클래스 샘플 5장', fontsize=14); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 자동차 vs 개 RGB 채널별 히스토그램 비교\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "raw_train = CIFAR10(root='./data', train=True, download=False)  # PIL 이미지 접근용\n",
    "def collect_pixels(label_name, max_imgs=200):\n",
    "    idx_label = class_names.index(label_name)\n",
    "    vals = []\n",
    "    cnt = 0\n",
    "    for img, lab in raw_train:\n",
    "        if lab == idx_label:\n",
    "            vals.append(np.array(img))  # (H,W,3), 0~255\n",
    "            cnt += 1\n",
    "            if cnt>=max_imgs: break\n",
    "    arr = np.stack(vals, axis=0)  # (N,H,W,3)\n",
    "    return arr\n",
    "\n",
    "cars = collect_pixels('automobile', max_imgs=200)\n",
    "dogs = collect_pixels('dog', max_imgs=200)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "for i, ch in enumerate(['R','G','B']):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.hist(cars[:,:,:,i].ravel(), bins=50, alpha=0.6, label='car')\n",
    "    plt.hist(dogs[:,:,:,i].ravel(), bins=50, alpha=0.6, label='dog')\n",
    "    plt.title(f'Channel {ch} Histogram'); plt.legend()\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "print('cars array:', cars.shape, 'dogs array:', dogs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ce5655",
   "metadata": {},
   "source": [
    "## 2. Baseline 비교 (≈6분)\n",
    "\n",
    "**말하기 포인트:**  \n",
    "- MLP는 공간 정보를 활용하지 못함 → 파라미터 수 대비 비효율적.  \n",
    "- CNN은 지역(커널) 단위로 가중치를 공유 → 효율성↑, 일반화↑.\n",
    "\n",
    "**질문:** “같은 파라미터 수라면 어떤 구조가 더 유리할까요?”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c91553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*32*3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.flatten(x))\n",
    "\n",
    "class CNN_V1(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "mlp = MLP().to(device)\n",
    "cnn = CNN_V1().to(device)\n",
    "print('MLP params:', count_params(mlp))\n",
    "print('CNN_V1 params:', count_params(cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, loss_fn, optim_):\n",
    "    model.train(); tl=0; tc=0; n=0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        optim_.zero_grad()\n",
    "        out = model(x); loss = loss_fn(out,y)\n",
    "        loss.backward(); optim_.step()\n",
    "        tl += loss.item()*x.size(0)\n",
    "        tc += (out.argmax(1)==y).sum().item(); n += x.size(0)\n",
    "    return tl/n, tc/n\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader, loss_fn):\n",
    "    model.eval(); tl=0; tc=0; n=0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        out = model(x); loss = loss_fn(out,y)\n",
    "        tl += loss.item()*x.size(0)\n",
    "        tc += (out.argmax(1)==y).sum().item(); n += x.size(0)\n",
    "    return tl/n, tc/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e894462",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "def train_model(model, epochs=5, lr=1e-3):\n",
    "    optim_ = optim.Adam(model.parameters(), lr=lr)\n",
    "    hist = {'train_acc':[], 'val_acc':[], 'train_loss':[], 'val_loss':[]}\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_l, tr_a = train_epoch(model, train_loader, criterion, optim_)\n",
    "        va_l, va_a = eval_epoch(model, val_loader, criterion)\n",
    "        hist['train_loss'].append(tr_l); hist['val_loss'].append(va_l)\n",
    "        hist['train_acc'].append(tr_a);  hist['val_acc'].append(va_a)\n",
    "        print(f'[Ep {ep}/{epochs}] train={tr_a:.3f}/{tr_l:.3f}  val={va_a:.3f}/{va_l:.3f}')\n",
    "    return hist\n",
    "\n",
    "mlp_hist = train_model(mlp, epochs=5)\n",
    "cnn_hist = train_model(cnn, epochs=10)  # CNN은 조금 더 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 나란히 플롯\n",
    "def plot_hist(h, title):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(h['train_acc'], label='train_acc')\n",
    "    plt.plot(h['val_acc'], label='val_acc')\n",
    "    plt.title(title+'(Accuracy)'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(h['train_loss'], label='train_loss')\n",
    "    plt.plot(h['val_loss'], label='val_loss')\n",
    "    plt.title(title+'(Loss)'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_hist(mlp_hist, 'MLP ')\n",
    "plot_hist(cnn_hist, 'CNN_V1 ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603661c",
   "metadata": {},
   "source": [
    "## 3. CNN 내부 시각화 (≈5분)\n",
    "\n",
    "**말하기 포인트:**  \n",
    "- 초기 필터는 엣지/색상 같은 저수준 특징을 뽑습니다.  \n",
    "- 이후 레이어로 갈수록 패턴/형태 같은 고수준 특징으로 이어집니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 첫 Conv 레이어 필터 가중치 시각화\n",
    "w = cnn.features[0].weight.data.cpu()  # (out, in, k, k)\n",
    "w_min, w_max = w.min().item(), w.max().item()\n",
    "grid = []\n",
    "for i in range(min(32, w.shape[0])):  # 32개까지만\n",
    "    filt = w[i]\n",
    "    # 채널 평균으로 2D 맵 만들기\n",
    "    fmap = filt.mean(0)\n",
    "    grid.append((fmap - w_min)/(w_max - w_min + 1e-9))\n",
    "grid = torch.stack(grid,0).numpy()\n",
    "\n",
    "cols = 8; rows = (len(grid)+cols-1)//cols\n",
    "plt.figure(figsize=(10, 2*rows))\n",
    "for i, g in enumerate(grid):\n",
    "    plt.subplot(rows, cols, i+1); plt.imshow(g, cmap='gray'); plt.axis('off')\n",
    "plt.suptitle('첫 Conv 필터(평균 채널)'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 테스트 이미지 1장의 첫 Conv 특징맵\n",
    "with torch.no_grad():\n",
    "    x, _ = next(iter(test_loader))\n",
    "    x = x[0:1].to(device)\n",
    "    features = cnn.features[0](x)  # 첫 Conv 결과 (N=1, C=32, H, W)\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(features[0,i].cpu(), cmap='gray'); plt.axis('off')\n",
    "plt.suptitle('첫 Conv Feature Maps'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bcdc04",
   "metadata": {},
   "source": [
    "## 4. 오분류 분석 심화 (≈5분)\n",
    "\n",
    "**말하기 포인트:**  \n",
    "- Confusion Matrix로 **자주 헷갈리는 클래스 쌍**을 찾습니다.  \n",
    "- 해당 쌍의 샘플을 여러 장 보여주며, 공통 패턴을 토론합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    model.eval(); ys=[]; ps=[]\n",
    "    for x,y in loader:\n",
    "        x = x.to(device); out = model(x)\n",
    "        ps.append(out.argmax(1).cpu().numpy()); ys.append(y.numpy())\n",
    "    return np.concatenate(ys), np.concatenate(ps)\n",
    "\n",
    "y_true, y_pred = get_all_preds(cnn, test_loader)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(10)))\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, interpolation='nearest'); plt.title('Confusion Matrix')\n",
    "plt.colorbar(); plt.xticks(range(10), class_names, rotation=45); plt.yticks(range(10), class_names)\n",
    "plt.tight_layout(); plt.xlabel('Predicted'); plt.ylabel('True'); plt.show()\n",
    "\n",
    "# Top-3 혼동 클래스 쌍 추출\n",
    "pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i!=j and cm[i,j]>0:\n",
    "            pairs.append(((i,j), cm[i,j]))\n",
    "pairs = sorted(pairs, key=lambda x: x[1], reverse=True)[:3]\n",
    "print('Top-3 혼동 클래스 쌍:', [(class_names[i], class_names[j], n) for (i,j), n in pairs])\n",
    "\n",
    "# 각 쌍에서 오분류 샘플 6장 표시\n",
    "raw_test = datasets.CIFAR10(root='./data', train=False, download=False, transform=transforms.ToTensor())\n",
    "idx_map = list(range(len(raw_test)))  # 원본 인덱스 접근용\n",
    "# test_loader 순서와 raw_test 인덱스는 다를 수 있으므로, 라벨 기반으로 스캔\n",
    "def find_mismatch_indices(true_label, pred_label, max_show=6):\n",
    "    out_idx = []\n",
    "    count = 0\n",
    "    # brute-force: 전체 예측을 다시 순차로 확인\n",
    "    ptr = 0\n",
    "    for batch_x, batch_y in DataLoader(test_set, batch_size=128, shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            logits = cnn(batch_x.to(device))\n",
    "            preds = logits.argmax(1).cpu().numpy()\n",
    "        for k in range(len(batch_y)):\n",
    "            if batch_y[k].item()==true_label and preds[k]==pred_label:\n",
    "                out_idx.append(ptr+k)\n",
    "                count += 1\n",
    "                if count>=max_show: return out_idx\n",
    "        ptr += len(batch_y)\n",
    "    return out_idx\n",
    "\n",
    "for (i,j), _ in pairs:\n",
    "    ids = find_mismatch_indices(i,j, max_show=6)\n",
    "    if not ids: continue\n",
    "    plt.figure(figsize=(6,3))\n",
    "    for k, idx in enumerate(ids):\n",
    "        img,_ = raw_test[idx]\n",
    "        plt.subplot(2,3,k+1); plt.imshow(img.permute(1,2,0)); plt.axis('off')\n",
    "        plt.title(f'T:{class_names[i]} → P:{class_names[j]}')\n",
    "    plt.suptitle(f'혼동 사례: {class_names[i]} vs {class_names[j]}'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a8b5c",
   "metadata": {},
   "source": [
    "## 5. 성능 개선 기법 (≈6분)\n",
    "\n",
    "**말하기 포인트:**  \n",
    "- 증강, 정규화, 드롭아웃/배치정규화, 옵티마이저 변경 등으로 과적합을 제어하고 일반화를 개선합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강 파이프라인과 BN/Dropout을 포함한 개선 모델\n",
    "aug_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616))\n",
    "])\n",
    "train_full_aug = datasets.CIFAR10(root='./data', train=True, download=False, transform=aug_tf)\n",
    "train_set2, val_set2 = random_split(train_full_aug, [train_len, val_len])\n",
    "train_loader2=DataLoader(train_set2,batch_size=128,shuffle=True,num_workers=0)\n",
    "val_loader2  =DataLoader(val_set2,  batch_size=128,shuffle=False,num_workers=0)\n",
    "\n",
    "class CNN_V2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32,32,3,padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout(0.2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64,64,3,padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "cnn2 = CNN_V2().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer 실험: SGD vs Adam\n",
    "opt_name = 'SGD'  # 'Adam'으로 변경하여 비교 실험\n",
    "optimizer = optim.SGD(cnn2.parameters(), lr=0.01, momentum=0.9) if opt_name=='SGD' else optim.Adam(cnn2.parameters(), lr=1e-3)\n",
    "\n",
    "hist2={'train_acc':[],'val_acc':[],'train_loss':[],'val_loss':[]}\n",
    "for ep in range(1, 12):  # 약간 더 학습\n",
    "    tr_l,tr_a = train_epoch(cnn2, train_loader2, criterion, optimizer)\n",
    "    va_l,va_a = eval_epoch(cnn2, val_loader2, criterion)\n",
    "    hist2['train_loss'].append(tr_l); hist2['val_loss'].append(va_l)\n",
    "    hist2['train_acc'].append(tr_a);  hist2['val_acc'].append(va_a)\n",
    "    print(f'[CNN_V2][{opt_name}][Ep {ep}] train={tr_a:.3f}/{tr_l:.3f}  val={va_a:.3f}/{va_l:.3f}')\n",
    "\n",
    "# 성능 비교\n",
    "def plot_hist(h, title):\n",
    "    plt.figure(figsize=(6,4)); plt.plot(h['train_acc'],label='train_acc'); plt.plot(h['val_acc'],label='val_acc'); plt.title(title+' Acc'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    plt.figure(figsize=(6,4)); plt.plot(h['train_loss'],label='train_loss'); plt.plot(h['val_loss'],label='val_loss'); plt.title(title+' Loss'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_hist(hist2, f'CNN_V2 ({opt_name})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936fe06",
   "metadata": {},
   "source": [
    "## 6. 실습 챌린지 (≈2분)\n",
    "\n",
    "- **레이어 수 늘리기**: Conv 블록 추가 후 성능/시간 변화 비교  \n",
    "- **증강 강도 조절**: `ColorJitter`, `RandomErasing` 등 추가하여 일반화 확인  \n",
    "- **Optimizer 교체**: SGD ↔ Adam, 학습률 스케줄러(`StepLR`, `CosineAnnealingLR`) 도입\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
