{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-5, 2강 TTS(텍스트→음성) 기초와 보이스 클로닝 — Coqui TTS\n",
        "\n",
        "- 목표: TTS 기본 파이프라인 이해, 멀티스피커/멀티언어 모델 사용, 간단 보이스 클로닝 실습\n",
        "- 데이터: 짧은 텍스트 문장과 참조 화자 오디오(30~60초)\n",
        "- 규칙(강의용): 시각화는 `matplotlib`만 사용, 불필요한 외부 의존 최소화\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 구성 (Overview)\n",
        "1) TTS 개요 & 파이프라인(보이스 클로닝 포함)\n",
        "2) 환경 준비(라이브러리/폰트/경고) 및 `DEVICE` 출력\n",
        "3) 데이터 준비: 참조 화자 오디오 전처리(16kHz/모노)\n",
        "4) Google Cloud TTS — 설치·샘플\n",
        "5) 텍스트 전처리: 정규화/문장 분할의 영향 실험\n",
        "6) 합성 속도/길이 벤치마크(간단)\n",
        "7) 시각화: 파형/멜스펙 + 청취 포인트\n",
        "8) 마무리 및 과제(응용/평가)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. TTS 개요 — 파이프라인과 보이스 클로닝\n",
        "\n",
        "- 텍스트→음성(TTS) 파이프라인은 일반적으로 다음 단계를 거칩니다.\n",
        "  1) 텍스트 전처리(Text Normalization, 문장 분할)\n",
        "  2) 발음/음운 변환(언어별 G2P/발음사전 또는 End-to-End)\n",
        "  3) 어쿠스틱 모델(스펙트로그램/음성 특성 예측)\n",
        "  4) 보코더(Vocoder, 예: HiFi-GAN/BigVGAN 계열)로 파형 생성\n",
        "- 최근 모델은 2–4 단계를 End-to-End로 통합하거나 토큰/디퓨전 기반을 사용하며, 다국어·다화자·제로샷 보이스 클로닝을 지원하는 모델들이 존재합니다.\n",
        "\n",
        "#### 보이스 클로닝(Zero-shot Speaker Adaptation)\n",
        "- 짧은 참조 음성(30–60초)으로 화자 임베딩을 추출해, 새로운 텍스트를 해당 화자 톤으로 합성\n",
        "- 참고: 참조 음성의 언어/발음, 녹음 품질, 배경잡음이 클로닝 품질에 큰 영향\n",
        "\n",
        "#### 품질에 영향을 주는 요인\n",
        "- 텍스트: 숫자·기호·영문 혼용 → 정규화 필요, 문장부호로 억양 유도\n",
        "- 오디오: 참조 음성의 SNR, 마이크 품질, 리버브/노이즈\n",
        "- 모델: 언어 지원 범위, 학습 데이터 커버리지, 보코더 품질\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 준비 및 라이브러리 임포트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os, warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch, torchaudio\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=r\"Glyph.*missing from font.*\", category=UserWarning)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.rcParams['font.family'] = 'AppleGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', DEVICE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 데이터 준비 — 오디오 16k/모노\n",
        "- 녹음/샘플 WAV를 16kHz/모노로 통일해 TTS 입출력 품질 비교와 재현성을 확보합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_mono_16k(path: str, out_path: str = 'tmp_16k_mono.wav') -> str:\n",
        "    wav, sr = torchaudio.load(path)\n",
        "    if wav.size(0) > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)\n",
        "    if sr != 16000:\n",
        "        wav = torchaudio.transforms.Resample(sr, 16000)(wav)\n",
        "    torchaudio.save(out_path, wav, 16000)\n",
        "    return out_path\n",
        "\n",
        "# 예시\n",
        "# ensure_mono_16k('input.wav', 'tmp_16k_mono.wav')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tmp_16k_mono.wav'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensure_mono_16k('./data/speech/1_0000.wav', 'tmp_16k_mono.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2-1. 텍스트 전처리와 문장 분할\n",
        "- **텍스트 정규화(Text Normalization)**: 숫자, 기호, 단위, 영어 혼용을 **읽기 쉬운 형태**로 바꾸어 발음을 안정화합니다.\n",
        "  - 예) \"1kg\" → \"1 킬로그램\", \"A/S\" → \"에이에스\"\n",
        "- **문장 분할(Sentence Splitting)**: 문장부호(`.?!`, 쉼표)로 문장을 짧게 쪼개면 억양이 안정적이고 지연이 줄어듭니다.\n",
        "- 실습: 동일 문장을 분할 유무/부호 유무에 따라 합성 품질(억양/호흡)을 비교합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "정규화 전: 오늘 기온은 23.5도, 바람이 강합니다! 1kg짜리 샘플과 A/S 절차를 안내합니다.\n",
            "정규화 후: 오늘 기온은 23.5도, 바람이 강합니다! 1kg짜리 샘플과 에이에스 절차를 안내합니다.\n",
            "문장 분할: ['오늘 기온은 23.', '5도, 바람이 강합니다!', '1kg짜리 샘플과 에이에스 절차를 안내합니다.']\n"
          ]
        }
      ],
      "source": [
        "# 텍스트 정규화 & 문장 분할 유틸\n",
        "import re\n",
        "from typing import List\n",
        "\n",
        "def normalize_korean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    간단한 한글 중심 텍스트 정규화 예시.\n",
        "    - 숫자·단위/기호 일부를 읽기 쉬운 형태로 치환\n",
        "    - 과도한 공백 축소\n",
        "    참고: 실제 서비스는 언어별 규칙과 도메인 사전을 체계화해야 함\n",
        "    \"\"\"\n",
        "    rules = [\n",
        "        (r\"\\bA/S\\b\", \"에이에스\"),\n",
        "        (r\"\\bAS\\b\", \"에이에스\"),\n",
        "        (r\"\\bkg\\b\", \"킬로그램\"),\n",
        "        (r\"\\bkm\\b\", \"킬로미터\"),\n",
        "    ]\n",
        "    out = text\n",
        "    for pat, rep in rules:\n",
        "        out = re.sub(pat, rep, out, flags=re.IGNORECASE)\n",
        "    out = re.sub(r\"\\s+\", \" \", out).strip()\n",
        "    return out\n",
        "\n",
        "def split_sentences(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    문장부호(.?!;) 기준 간단 분할. 쉼표는 선택적으로 유지.\n",
        "    \"\"\"\n",
        "    parts = re.split(r\"([.!?;])\", text)\n",
        "    sents = []\n",
        "    buf = \"\"\n",
        "    for p in parts:\n",
        "        if re.match(r\"[.!?;]\", p):\n",
        "            buf += p\n",
        "            sents.append(buf.strip())\n",
        "            buf = \"\"\n",
        "        else:\n",
        "            buf += p\n",
        "    if buf.strip():\n",
        "        sents.append(buf.strip())\n",
        "    return [s for s in sents if s]\n",
        "\n",
        "# 데모용 문장\n",
        "RAW_TEXT = \"오늘 기온은 23.5도, 바람이 강합니다! 1kg짜리 샘플과 A/S 절차를 안내합니다.\"\n",
        "print('정규화 전:', RAW_TEXT)\n",
        "print('정규화 후:', normalize_korean_text(RAW_TEXT))\n",
        "print('문장 분할:', split_sentences(normalize_korean_text(RAW_TEXT)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2-2. Google Cloud TTS — 개요\n",
        "- 클라우드 API 기반 TTS로, 고품질/다양한 보이스를 제공하며 SDK로 쉽게 사용 가능합니다.\n",
        "- 아래에 설치/설정 및 최소 동작 샘플 코드를 제공합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GCP 의존성 설치 보조 (필요 시 실행)\n",
        "# - GCP TTS: google-cloud-texttospeech\n",
        "try:\n",
        "    ensure\n",
        "except NameError:\n",
        "    import importlib, sys, subprocess\n",
        "    def ensure(pkg: str, pip_name: str | None = None):\n",
        "        name = pip_name or pkg\n",
        "        try:\n",
        "            importlib.import_module(pkg)\n",
        "        except Exception:\n",
        "            print(f'Installing {name} ...')\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', name, '--quiet'])\n",
        "\n",
        "# macOS에서 libsndfile이 필요할 수 있습니다: Homebrew → `brew install libsndfile`\n",
        "ensure('google.cloud.texttospeech', 'google-cloud-texttospeech')\n",
        "ensure('onnxruntime')\n",
        "ensure('soundfile')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2-2-2) Google Cloud TTS — 설치 및 설정\n",
        "- 설치: `pip install google-cloud-texttospeech`\n",
        "- GCP 프로젝트/결제 설정 → API 활성화 → 서비스 계정 키(JSON) 발급\n",
        "- 인증: 환경 변수 설정 또는 코드 내에서 자격증명 로딩\n",
        "  - macOS/zsh 예: `export GOOGLE_APPLICATION_CREDENTIALS=\"/absolute/path/key.json\"`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"cp-100-187113-690d09617cf5.json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Cloud TTS 최소 동작 예제 (텍스트 → WAV)\n",
        "# 요구: pip install google-cloud-texttospeech\n",
        "from google.cloud import texttospeech\n",
        "import base64\n",
        "import wave\n",
        "\n",
        "\n",
        "def gcp_tts_synthesize(text: str, out_wav: str = 'gcp_out.wav', language_code: str = 'ko-KR', voice_name: str | None = None, speaking_rate: float = 1.0):\n",
        "    client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "    voice_params = dict(language_code=language_code)\n",
        "    if voice_name:\n",
        "        voice_params['name'] = voice_name\n",
        "    voice = texttospeech.VoiceSelectionParams(**voice_params)\n",
        "\n",
        "    audio_config = texttospeech.AudioConfig(\n",
        "        audio_encoding=texttospeech.AudioEncoding.LINEAR16,\n",
        "        speaking_rate=speaking_rate,\n",
        "        sample_rate_hertz=24000\n",
        "    )\n",
        "\n",
        "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
        "    response = client.synthesize_speech(\n",
        "        input=synthesis_input,\n",
        "        voice=voice,\n",
        "        audio_config=audio_config\n",
        "    )\n",
        "\n",
        "    # LINEAR16 PCM → WAV 래핑\n",
        "    pcm = response.audio_content\n",
        "    with wave.open(out_wav, 'wb') as f:\n",
        "        f.setnchannels(1)\n",
        "        f.setsampwidth(2)  # 16-bit\n",
        "        f.setframerate(24000)\n",
        "        f.writeframes(pcm)\n",
        "    return out_wav\n",
        "\n",
        "# 실행 예시(주석 해제)\n",
        "# gcp_tts_synthesize('안녕하세요. 구글 클라우드 TTS 데모입니다.', 'gcp_out.wav', language_code='ko-KR')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758549640.775566  201140 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'gcp_out.wav'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gcp_tts_synthesize('안녕하세요. 구글 클라우드 TTS 데모입니다.', 'gcp_out.wav', language_code='ko-KR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2-2-3) 결론/추천\n",
        "- 고품질·다양한 보이스·운영 단순: Google Cloud TTS 권장\n",
        "- 비용/네트워크 의존 고려: 문자 과금, 키 관리 필요\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 합성 속도/길이 벤치마크(간단)\n",
        "- 동일 문장 세트로 Piper CLI/GCP TTS 합성 시간을 비교합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def bench_gcp(texts: list[str], language_code: str = 'ko-KR'):\n",
        "    rows = []\n",
        "    for t in texts:\n",
        "        t0 = time.perf_counter()\n",
        "        gcp_tts_synthesize(t, 'bench_gcp.wav', language_code=language_code)\n",
        "        rows.append({'engine': 'gcp', 'len': len(t), 'sec': round(time.perf_counter()-t0, 2)})\n",
        "    return rows\n",
        "\n",
        "# 예시\n",
        "# texts = ['안녕하세요.', '오늘은 TTS 벤치마크를 진행합니다.', '문장이 길어질수록 시간이 늘어납니다. 적절한 길이로 분할하세요.']\n",
        "# print(bench_gcp(texts, 'ko-KR'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 시각화 — 파형/멜스펙과 청취 포인트\n",
        "- 합성 결과를 파형과 멜 스펙트로그램으로 확인합니다.\n",
        "- 억양/호흡/잡음(메탈릭) 체크 포인트를 함께 제시합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_wave_and_melspec(wav_path: str):\n",
        "    \"\"\"\n",
        "    WAV 파일을 로드하여 파형과 멜 스펙트로그램을 시각화합니다.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(wav_path):\n",
        "        raise FileNotFoundError('합성 파일을 찾을 수 없습니다: ' + wav_path)\n",
        "    wav, sr = torchaudio.load(wav_path)\n",
        "    if wav.size(0) > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)\n",
        "    # 파형\n",
        "    t = np.arange(wav.size(1)) / sr\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    plt.plot(t, wav.squeeze(0).numpy(), color='steelblue')\n",
        "    plt.title('Waveform')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    # 멜 스펙트로그램\n",
        "    mel = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=sr, n_fft=1024, hop_length=256, n_mels=80\n",
        "    )(wav)\n",
        "    mel_db = torchaudio.transforms.AmplitudeToDB()(mel)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.imshow(mel_db.squeeze(0).numpy(), aspect='auto', origin='lower', cmap='magma')\n",
        "    plt.title('Mel-Spectrogram (dB)')\n",
        "    plt.xlabel('Frames')\n",
        "    plt.ylabel('Mel bins')\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 예시(주석 해제)\n",
        "# plot_wave_and_melspec('tts_ko.wav')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 마무리 및 과제 제안(업데이트)\n",
        "- 참조 화자 오디오 1↔2~3개 비교(클로닝 안정성)\n",
        "- 문장 길이/부호/언어 변화에 따른 억양/자연스러움 비교\n",
        "- 음성 품질 점검 체크리스트(발음·억양·잡음)\n",
        "- 확장: 영어 문장에 한국어 억양 유도하기(쉼표/강세 단서 추가)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (metacode)",
      "language": "python",
      "name": "metacode-lecture"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
