{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2d319d",
   "metadata": {},
   "source": [
    "# üìò 1Í∞ï (CPU-Optimized, PyTorch): CNN Í∏∞Ï¥à ‚Äî CIFAR-10\n",
    "\n",
    "**GPU ÏóÜÏñ¥ÎèÑ Ïã§Ìñâ Í∞ÄÎä•**Ìï©ÎãàÎã§. Îã§Îßå ÌïôÏäµ ÏãúÍ∞ÑÏùÄ Í∏∏Ïñ¥Ïßà Ïàò ÏûàÏúºÎØÄÎ°ú ÏïÑÎûò Í∏∞Î≥∏ ÏÑ§Ï†ï(ÏûëÏùÄ Î∞∞Ïπò/ÏóêÌè≠)ÏúºÎ°ú Íµ¨ÏÑ±ÌñàÏäµÎãàÎã§.\n",
    "- Í∏∞Î≥∏: `epochs=8`, `batch_size=64`, `num_workers=0` (Windows/ÎÖ∏Ìä∏Î∂Å ÌôòÍ≤Ω Ìò∏ÌôòÏÑ±‚Üë)\n",
    "- ÌïÑÏöîÌïòÎ©¥ `epochs`/`batch_size`Î•º Ï°∞Ï†ïÌïòÏÑ∏Ïöî.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, numpy as np, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775648ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ÏÖã/Ï†ÑÏ≤òÎ¶¨\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616))\n",
    "])\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616))\n",
    "])\n",
    "\n",
    "root='./data'\n",
    "train_full = datasets.CIFAR10(root=root, train=True, download=True, transform=train_tf)\n",
    "test_set   = datasets.CIFAR10(root=root, train=False, download=True, transform=test_tf)\n",
    "class_names = train_full.classes\n",
    "\n",
    "# Train/Val split\n",
    "val_ratio=0.2\n",
    "val_len  = int(len(train_full)*val_ratio)\n",
    "train_len= len(train_full)-val_len\n",
    "train_set, val_set = random_split(train_full,[train_len,val_len])\n",
    "\n",
    "batch_size=64\n",
    "num_workers=0  # CPU Ìò∏Ìôò/ÏïàÏ†ïÏÑ± ÏúÑÌï¥ 0 Í∂åÏû•\n",
    "train_loader=DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "val_loader  =DataLoader(val_set,  batch_size=batch_size,shuffle=False,num_workers=num_workers)\n",
    "test_loader =DataLoader(test_set,  batch_size=batch_size,shuffle=False,num_workers=num_workers)\n",
    "\n",
    "len(train_set),len(val_set),len(test_set),class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î™®Îç∏/ÌïôÏäµ Ïú†Ìã∏\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128,num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.features(x); x=self.classifier(x); return x\n",
    "\n",
    "def train_epoch(model,loader,loss_fn,optim_):\n",
    "    model.train(); total_loss=0; correct=0; total=0\n",
    "    for x,y in loader:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        optim_.zero_grad()\n",
    "        logits=model(x); loss=loss_fn(logits,y)\n",
    "        loss.backward(); optim_.step()\n",
    "        total_loss+=loss.item()*x.size(0)\n",
    "        correct+=(logits.argmax(1)==y).sum().item()\n",
    "        total+=x.size(0)\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model,loader,loss_fn):\n",
    "    model.eval(); total_loss=0; correct=0; total=0\n",
    "    for x,y in loader:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        logits=model(x); loss=loss_fn(logits,y)\n",
    "        total_loss+=loss.item()*x.size(0)\n",
    "        correct+=(logits.argmax(1)==y).sum().item()\n",
    "        total+=x.size(0)\n",
    "    return total_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌïôÏäµ\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS=8\n",
    "hist={'train_acc':[],'val_acc':[],'train_loss':[],'val_loss':[]}\n",
    "best_va=0.0; best_state=None\n",
    "\n",
    "for ep in range(1,EPOCHS+1):\n",
    "    tr_loss,tr_acc = train_epoch(model,train_loader,criterion,optimizer)\n",
    "    va_loss,va_acc = eval_epoch(model,val_loader,criterion)\n",
    "    hist['train_loss'].append(tr_loss); hist['val_loss'].append(va_loss)\n",
    "    hist['train_acc'].append(tr_acc);   hist['val_acc'].append(va_acc)\n",
    "    print(f'[Ep {ep}/{EPOCHS}] train_acc={tr_acc:.3f} val_acc={va_acc:.3f}')\n",
    "    if va_acc>best_va: best_va=va_acc; best_state=model.state_dict().copy()\n",
    "if best_state: model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473af99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌïôÏäµ Í≥°ÏÑ†\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_hist(h):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(h['train_acc'],label='train_acc'); plt.plot(h['val_acc'],label='val_acc')\n",
    "    plt.title('Accuracy'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(h['train_loss'],label='train_loss'); plt.plot(h['val_loss'],label='val_loss')\n",
    "    plt.title('Loss'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌÖåÏä§Ìä∏ ÌèâÍ∞Ä + ÌòºÎèôÌñâÎ†¨\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def preds_and_labels(model, loader):\n",
    "    model.eval(); ys=[]; ps=[]\n",
    "    for x,y in loader:\n",
    "        x=x.to(device); logits=model(x)\n",
    "        ps.append(logits.argmax(1).cpu().numpy())\n",
    "        ys.append(y.numpy())\n",
    "    return np.concatenate(ys), np.concatenate(ps)\n",
    "\n",
    "te_loss, te_acc = eval_epoch(model,test_loader,criterion)\n",
    "print(f'[TEST] acc={te_acc:.4f}, loss={te_loss:.4f}')\n",
    "y_true, y_pred = preds_and_labels(model,test_loader)\n",
    "\n",
    "cm = confusion_matrix(y_true,y_pred,labels=list(range(10)))\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm,interpolation='nearest')\n",
    "plt.title('Confusion Matrix'); plt.colorbar()\n",
    "plt.xticks(range(10),class_names,rotation=45); plt.yticks(range(10),class_names)\n",
    "plt.tight_layout(); plt.xlabel('Pred'); plt.ylabel('True'); plt.show()\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÄÏû•/Î°úÎî©\n",
    "torch.save(model.state_dict(),'cnn_cpu_opt.pt')\n",
    "print('saved: cnn_cpu_opt.pt')\n",
    "m2 = CNN().to(device); m2.load_state_dict(torch.load('cnn_cpu_opt.pt', map_location=device)); m2.eval()\n",
    "print('reload ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
