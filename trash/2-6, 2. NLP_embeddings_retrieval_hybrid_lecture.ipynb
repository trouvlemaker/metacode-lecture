{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-6, 2강 NLP 임베딩 검색 — SBERT/TF‑IDF/Hybrid (CPU)\n",
        "\n",
        "- 목표: AG News 코퍼스에서 SBERT/TF‑IDF/Hybrid 검색 성능 비교 분석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 구성 (Overview)\n",
        "- 0. 환경 설정 및 라이브러리\n",
        "- 1. 데이터 로드 및 corpus 생성 (AG News)\n",
        "- 2. 임베딩 2가지 — SBERT / TF‑IDF\n",
        "- 3. 검색 — SBERT / TF‑IDF / Hybrid\n",
        "- 4. 검색 성능 및 속도 분석 (Recall@k, MRR, 시간)\n",
        "- 5. 추가: 하이브리드 알파 스윕, 파라미터화\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 설정 및 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kimjinseok/Desktop/metacode-lecture/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 0. 환경 설정 및 라이브러리\n",
        "# =========================\n",
        "\n",
        "# 표준 라이브러리\n",
        "import os, time, random\n",
        "from typing import List, Tuple, Dict\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# 서드파티: 수치/데이터/시각화\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 서드파티: 사이킷런(전처리/평가/최근접 이웃)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import pairwise_distances, pairwise_distances_argmin_min\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# SBERT 임베딩\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "# 데이터셋 로드\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 경고 억제 (환경 차이로 발생하는 워닝 최소화)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=r\".*matmul.*\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Matplotlib: 한글 폰트 및 마이너스 기호 설정\n",
        "# -----------------------------------------\n",
        "plt.rcParams[\"font.family\"] = \"AppleGothic\"  # macOS\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "# ------------------------\n",
        "# 재현성(시드) 고정\n",
        "# ------------------------\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# =========================\n",
        "# 타이머 유틸\n",
        "# =========================\n",
        "@contextmanager\n",
        "def timer(msg: str):\n",
        "    t0 = time.perf_counter()\n",
        "    yield\n",
        "    print(f\"[TIME] {msg}: {time.perf_counter()-t0:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 데이터 로드 및 corpus 생성 (AG News)\n",
        "- label, title, description을 결합해 문서 텍스트를 구성\n",
        "- 소규모 서브셋(클래스당 N개)으로 코퍼스와 쿼리 세트 분리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 172457.19 examples/s]\n",
            "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 264589.25 examples/s]\n",
            "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 303549.95 examples/s]\n",
            "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 304123.31 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1200 corpus | 120 queries\n",
            "labels: [0, 1, 2, 3]\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 1. AG News 로드 및 코퍼스/쿼리 구성\n",
        "# =========================\n",
        "LABEL_NAMES: List[str] = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "N_PER_CLASS = int(os.environ.get(\"N_PER_CLASS\", 300))  # 코퍼스용\n",
        "N_QUERY_PER_CLASS = int(os.environ.get(\"N_QUERY_PER_CLASS\", 30))  # 쿼리용\n",
        "\n",
        "\n",
        "def load_ag_news_texts(n_per_class: int) -> Tuple[List[str], List[int]]:\n",
        "    ds = load_dataset(\"ag_news\", split=\"train\")\n",
        "    texts, labels = [], []\n",
        "    for lab in range(4):\n",
        "        sub = ds.filter(lambda ex: ex[\"label\"] == lab).select(range(n_per_class))\n",
        "        # title + description 결합 (없으면 text만 사용)\n",
        "        for r in sub:\n",
        "            title = r.get(\"title\") or \"\"\n",
        "            desc = r.get(\"description\") or r.get(\"text\") or \"\"\n",
        "            txt = (str(title) + \" \\n\" + str(desc)).strip()\n",
        "            texts.append(txt)\n",
        "            labels.append(int(r[\"label\"]))\n",
        "    return texts, labels\n",
        "\n",
        "# 전체에서 코퍼스/쿼리 분할 (클래스 균등)\n",
        "corpus_texts, corpus_labels = load_ag_news_texts(N_PER_CLASS)\n",
        "query_texts, query_labels = load_ag_news_texts(N_QUERY_PER_CLASS)\n",
        "\n",
        "print(len(corpus_texts), \"corpus\", \"|\", len(query_texts), \"queries\")\n",
        "print(\"labels:\", sorted(set(corpus_labels)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 임베딩 — SBERT / TF‑IDF\n",
        "- CPU 강제 사용, 임베딩 L2 정규화로 코사인 검색 가속\n",
        "- 대용량 대비를 위한 간단 캐싱(npz) 지원\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIME] 임베딩 생성 및 캐싱: 34.26s\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 2. 임베딩 생성 유틸 (캐싱 포함)\n",
        "# =========================\n",
        "VEC_MAX_FEATURES = int(os.environ.get(\"VEC_MAX_FEATURES\", 30000))\n",
        "SBERT_MODEL = os.environ.get(\"SBERT_MODEL\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "CACHE_DIR = os.environ.get(\"EMB_CACHE\", \"data\")\n",
        "\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def sbert_encode(texts: List[str], batch_size: int = 64) -> np.ndarray:\n",
        "    model = SentenceTransformer(SBERT_MODEL, device=\"cpu\")\n",
        "    # encode → numpy, no auto-normalize (직접 수행)\n",
        "    embs = model.encode(\n",
        "        texts,\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=False,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=False,\n",
        "    ).astype(np.float64)\n",
        "    # L2 normalize + NaN/Inf 방지\n",
        "    norms = np.linalg.norm(embs, axis=1, keepdims=True)\n",
        "    embs = embs / np.clip(norms, 1e-12, None)\n",
        "    embs = np.nan_to_num(embs, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    return embs\n",
        "\n",
        "\n",
        "def tfidf_fit_transform(corpus: List[str]) -> Tuple[object, np.ndarray]:\n",
        "    vec = TfidfVectorizer(max_features=VEC_MAX_FEATURES, ngram_range=(1,2))\n",
        "    X = vec.fit_transform(corpus)\n",
        "    return vec, X\n",
        "\n",
        "\n",
        "def save_npz(path: str, **arrays):\n",
        "    np.savez_compressed(path, **arrays)\n",
        "\n",
        "\n",
        "def load_npz(path: str) -> Dict[str, np.ndarray]:\n",
        "    with np.load(path, allow_pickle=False) as f:\n",
        "        return {k: f[k] for k in f.files}\n",
        "\n",
        "\n",
        "# 실제 임베딩 생성 + 캐싱\n",
        "with timer(\"임베딩 생성 및 캐싱\"):\n",
        "    # SBERT 캐시\n",
        "    sbert_cache = os.path.join(CACHE_DIR, \"embeddings_agnews_sbert.npz\")\n",
        "    if os.path.exists(sbert_cache):\n",
        "        dat = load_npz(sbert_cache)\n",
        "        corpus_sbert = dat[\"corpus_sbert\"]\n",
        "    else:\n",
        "        corpus_sbert = sbert_encode(corpus_texts)\n",
        "        save_npz(sbert_cache, corpus_sbert=corpus_sbert)\n",
        "\n",
        "    # 쿼리도 즉시 생성 (캐싱은 선택)\n",
        "    query_sbert = sbert_encode(query_texts)\n",
        "\n",
        "    # TF-IDF 캐시\n",
        "    tfidf_cache = os.path.join(CACHE_DIR, \"embeddings_agnews_tfidf.npz\")\n",
        "    if os.path.exists(tfidf_cache):\n",
        "        dat = load_npz(tfidf_cache)\n",
        "        # 벡터라이저는 재학습 필요하므로 캐시에서는 행렬만 사용하지 않음\n",
        "        # 학습 재현을 위해 다시 fit 수행\n",
        "        vectorizer, X_corpus = tfidf_fit_transform(corpus_texts)\n",
        "    else:\n",
        "        vectorizer, X_corpus = tfidf_fit_transform(corpus_texts)\n",
        "        save_npz(tfidf_cache, X_corpus=X_corpus.astype(np.float32).toarray())\n",
        "        # 주의: 간단화를 위해 dense 저장. 실제 대용량은 joblib+희소 저장 권장\n",
        "\n",
        "    X_query = vectorizer.transform(query_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 검색 — SBERT / TF‑IDF / Hybrid\n",
        "- SBERT: 코사인 유사도 기반 top‑k\n",
        "- TF‑IDF: 코사인 유사도 기반 top‑k (희소 행렬 고려)\n",
        "- Hybrid: α·SBERT + (1-α)·TF‑IDF 점수 결합\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIME] 검색 실행 (top-5): 0.03s\n",
            "[Query] Venezuelans Vote Early in Referendum on Chavez Rule (Reuters) Reuters - Venezuelans turned out early\\and in large number ...\n",
            "SBERT → ['Venezuelans Vote Early in Referendum on Chavez Rule (Reuters) Reuters - Venezuel', 'Venezuelans vote on Chavez rule A referendum is under way in Venezuela to decide', 'Venezuelans Rush to Vote in Referendum on Chavez  CARACAS, Venezuela (Reuters) -', \"Venezuela Holds Referendum on President CARACAS, Venezuela - The opposition's lo\", 'Chavez Wins Venezuela Referendum-Preliminary Result  CARACAS, Venezuela (Reuters']\n",
            "TF-IDF → ['Venezuelans Vote Early in Referendum on Chavez Rule (Reuters) Reuters - Venezuel', 'Venezuelans Rush to Vote in Referendum on Chavez  CARACAS, Venezuela (Reuters) -', 'Venezuelans Throng to Polls in Chavez Referendum  CARACAS, Venezuela (Reuters) -', 'Venezuela Voters Crowd Polls in Chavez Referendum  CARACAS, Venezuela (Reuters) ', 'Venezuelans vote on Chavez rule A referendum is under way in Venezuela to decide']\n",
            "Hybrid → ['Venezuelans Vote Early in Referendum on Chavez Rule (Reuters) Reuters - Venezuel', 'Venezuelans vote on Chavez rule A referendum is under way in Venezuela to decide', 'Venezuelans Rush to Vote in Referendum on Chavez  CARACAS, Venezuela (Reuters) -', \"Venezuela Holds Referendum on President CARACAS, Venezuela - The opposition's lo\", 'Chavez Wins Venezuela Referendum-Preliminary Result  CARACAS, Venezuela (Reuters']\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 3. 검색 함수들 (SBERT / TF-IDF / Hybrid)\n",
        "# =========================\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "def topk_indices(scores: np.ndarray, k: int) -> np.ndarray:\n",
        "    # scores: shape (num_queries, num_corpus)\n",
        "    return np.argpartition(-scores, kth=min(k, scores.shape[1]-1), axis=1)[:, :k]\n",
        "\n",
        "\n",
        "def search_sbert(query_embs: np.ndarray, corpus_embs: np.ndarray, top_k: int = 5) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    # 코사인 = dot (이미 L2 정규화 가정)\n",
        "    sims = (query_embs @ corpus_embs.T)  # (Q, C)\n",
        "    idx = topk_indices(sims, top_k)\n",
        "    # 정렬된 인덱스와 점수 반환\n",
        "    sorted_idx = np.take_along_axis(idx, np.argsort(np.take_along_axis(sims, idx, axis=1) * -1, axis=1), axis=1)\n",
        "    sorted_scores = np.take_along_axis(sims, sorted_idx, axis=1)\n",
        "    return sorted_idx, sorted_scores\n",
        "\n",
        "\n",
        "def search_tfidf(X_query, X_corpus, top_k: int = 5) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    sims = cosine_similarity(X_query, X_corpus)  # (Q, C)\n",
        "    idx = topk_indices(sims, top_k)\n",
        "    sorted_idx = np.take_along_axis(idx, np.argsort(np.take_along_axis(sims, idx, axis=1) * -1, axis=1), axis=1)\n",
        "    sorted_scores = np.take_along_axis(sims, sorted_idx, axis=1)\n",
        "    return sorted_idx, sorted_scores\n",
        "\n",
        "\n",
        "def search_hybrid(query_embs: np.ndarray, corpus_embs: np.ndarray, X_query, X_corpus, alpha: float = 0.5, top_k: int = 5):\n",
        "    idx_s, sbert = search_sbert(query_embs, corpus_embs, top_k)\n",
        "    idx_t, tfidf = search_tfidf(X_query, X_corpus, top_k)\n",
        "    # 동일 top_k 위치에서 단순 가중 합산 (후처리 간소화)\n",
        "    # 실제 서비스는 전체 점수 재정렬 권장\n",
        "    hybrid = alpha * sbert + (1 - alpha) * tfidf\n",
        "    # 각 쿼리별로 재정렬\n",
        "    idx = np.arange(hybrid.shape[0])[:, None]\n",
        "    order = np.argsort(-hybrid, axis=1)\n",
        "    final_idx = np.take_along_axis(idx_s, order, axis=1)\n",
        "    final_scores = np.take_along_axis(hybrid, order, axis=1)\n",
        "    return final_idx, final_scores\n",
        "\n",
        "\n",
        "# 샘플 검색 실행\n",
        "with timer(\"검색 실행 (top-5)\"):\n",
        "    topk = 5\n",
        "    s_idx, s_scores = search_sbert(query_sbert, corpus_sbert, topk)\n",
        "    t_idx, t_scores = search_tfidf(X_query, X_corpus, topk)\n",
        "    h_idx, h_scores = search_hybrid(query_sbert, corpus_sbert, X_query, X_corpus, alpha=0.5, top_k=topk)\n",
        "\n",
        "# 결과 예시 출력 (첫 쿼리)\n",
        "q0 = 0\n",
        "print(\"[Query]\", query_texts[q0][:120].replace(\"\\n\",\" \"), \"...\")\n",
        "print(\"SBERT →\", [corpus_texts[i][:80].replace(\"\\n\",\" \") for i in s_idx[q0]])\n",
        "print(\"TF-IDF →\", [corpus_texts[i][:80].replace(\"\\n\",\" \") for i in t_idx[q0]])\n",
        "print(\"Hybrid →\", [corpus_texts[i][:80].replace(\"\\n\",\" \") for i in h_idx[q0]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 결과 예시 출력 (첫 쿼리)\u001b[39;00m\n\u001b[32m      2\u001b[39m q0 = \u001b[33m\"\u001b[39m\u001b[33mwhat is the impact of interest rate hikes on the stock market?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[Query]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mquery_texts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mq0\u001b[49m\u001b[43m]\u001b[49m[:\u001b[32m120\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSBERT →\u001b[39m\u001b[33m\"\u001b[39m, [corpus_texts[i][:\u001b[32m80\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m s_idx[q0]])\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTF-IDF →\u001b[39m\u001b[33m\"\u001b[39m, [corpus_texts[i][:\u001b[32m80\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m t_idx[q0]])\n",
            "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "# 결과 예시 출력 (첫 쿼리)\n",
        "q0 = \"what is the impact of interest rate hikes on the stock market?\"\n",
        "print(\"[Query]\", query_texts[q0][:120].replace(\"\\n\",\" \"), \"...\")\n",
        "print(\"SBERT →\", [corpus_texts[i][:80].replace(\"\\n\",\" \") for i in s_idx[q0]])\n",
        "print(\"TF-IDF →\", [corpus_texts[i][:80].replace(\"\\n\",\" \") for i in t_idx[q0]])\n",
        "print(\"Hybrid →\", [corpus_texts[i][:80].replace(\"\\n\",\" \") for i in h_idx[q0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 검색 결과 성능 및 속도 분석\n",
        "- 지표: Recall@k, MRR\n",
        "- 속도: 쿼리 임베딩 계산 포함/제외를 분리 측정 (SBERT), TF‑IDF 변환 포함/제외\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall@1 | SBERT=1.000 TF-IDF=1.000 Hybrid=1.000\n",
            "Recall@3 | SBERT=1.000 TF-IDF=1.000 Hybrid=1.000\n",
            "Recall@5 | SBERT=1.000 TF-IDF=1.000 Hybrid=1.000\n",
            "Recall@10 | SBERT=1.000 TF-IDF=1.000 Hybrid=1.000\n",
            "MRR | SBERT=1.000 TF-IDF=1.000 Hybrid=1.000\n",
            "{'nq': 64, 'sbert_total_s': 3.526, 'sbert_search_s': 0.002, 'tfidf_total_s': 0.015, 'tfidf_search_s': 0.005}\n",
            "{'nq': 128, 'sbert_total_s': 4.461, 'sbert_search_s': 0.005, 'tfidf_total_s': 0.027, 'tfidf_search_s': 0.012}\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 4. 평가: Recall@k, MRR + 속도\n",
        "# =========================\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def recall_at_k(topk_idx: np.ndarray, true_labels: List[int], corpus_labels: List[int], k: int) -> float:\n",
        "    Q = len(true_labels)\n",
        "    hit = 0\n",
        "    corpus_labels_arr = np.array(corpus_labels)\n",
        "    for q in range(Q):\n",
        "        labs = corpus_labels_arr[topk_idx[q, :k]]\n",
        "        if true_labels[q] in labs:\n",
        "            hit += 1\n",
        "    return hit / Q\n",
        "\n",
        "\n",
        "def mrr(topk_idx: np.ndarray, true_labels: List[int], corpus_labels: List[int]) -> float:\n",
        "    Q = len(true_labels)\n",
        "    rr_sum = 0.0\n",
        "    corpus_labels_arr = np.array(corpus_labels)\n",
        "    for q in range(Q):\n",
        "        labs = corpus_labels_arr[topk_idx[q]]\n",
        "        target = true_labels[q]\n",
        "        pos = np.where(labs == target)[0]\n",
        "        if pos.size > 0:\n",
        "            rr_sum += 1.0 / (pos[0] + 1)\n",
        "    return rr_sum / Q\n",
        "\n",
        "\n",
        "# 지표 계산\n",
        "for k in [1, 3, 5, 10]:\n",
        "    r_s = recall_at_k(s_idx, query_labels, corpus_labels, k)\n",
        "    r_t = recall_at_k(t_idx, query_labels, corpus_labels, k)\n",
        "    r_h = recall_at_k(h_idx, query_labels, corpus_labels, k)\n",
        "    print(f\"Recall@{k} | SBERT={r_s:.3f} TF-IDF={r_t:.3f} Hybrid={r_h:.3f}\")\n",
        "\n",
        "print(\"MRR | SBERT={:.3f} TF-IDF={:.3f} Hybrid={:.3f}\".format(\n",
        "    mrr(s_idx, query_labels, corpus_labels),\n",
        "    mrr(t_idx, query_labels, corpus_labels),\n",
        "    mrr(h_idx, query_labels, corpus_labels),\n",
        "))\n",
        "\n",
        "# 속도 벤치마크 (소규모)\n",
        "def bench_speed(nq=64):\n",
        "    samp_q = query_texts[:nq]\n",
        "    # SBERT: 임베딩 포함 시간\n",
        "    t0 = time.perf_counter()\n",
        "    q_emb = sbert_encode(samp_q)\n",
        "    _ = search_sbert(q_emb, corpus_sbert, 5)\n",
        "    t_sbert_total = time.perf_counter() - t0\n",
        "\n",
        "    # SBERT: 임베딩 제외 시간 (순수 검색)\n",
        "    t0 = time.perf_counter()\n",
        "    _ = search_sbert(q_emb, corpus_sbert, 5)\n",
        "    t_sbert_search = time.perf_counter() - t0\n",
        "\n",
        "    # TF-IDF: 변환 포함 시간\n",
        "    t0 = time.perf_counter()\n",
        "    Xq = vectorizer.transform(samp_q)\n",
        "    _ = search_tfidf(Xq, X_corpus, 5)\n",
        "    t_tfidf_total = time.perf_counter() - t0\n",
        "\n",
        "    # TF-IDF: 변환 제외 (순수 검색)\n",
        "    t0 = time.perf_counter()\n",
        "    _ = search_tfidf(Xq, X_corpus, 5)\n",
        "    t_tfidf_search = time.perf_counter() - t0\n",
        "\n",
        "    print({\n",
        "        'nq': nq,\n",
        "        'sbert_total_s': round(t_sbert_total, 3),\n",
        "        'sbert_search_s': round(t_sbert_search, 3),\n",
        "        'tfidf_total_s': round(t_tfidf_total, 3),\n",
        "        'tfidf_search_s': round(t_tfidf_search, 3),\n",
        "    })\n",
        "\n",
        "bench_speed(64)\n",
        "bench_speed(128)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 추가: 하이브리드 알파 스윕 및 설정 파라미터화\n",
        "- α ∈ {0.0, 0.25, 0.5, 0.75, 1.0}에 대해 Recall@k, MRR 비교\n",
        "- 환경변수로 주요 파라미터 제어(N_PER_CLASS, VEC_MAX_FEATURES, SBERT_MODEL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>Recall@1</th>\n",
              "      <th>Recall@5</th>\n",
              "      <th>MRR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alpha  Recall@1  Recall@5  MRR\n",
              "0   0.00       1.0       1.0  1.0\n",
              "1   0.25       1.0       1.0  1.0\n",
              "2   0.50       1.0       1.0  1.0\n",
              "3   0.75       1.0       1.0  1.0\n",
              "4   1.00       1.0       1.0  1.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =========================\n",
        "# 5. 하이브리드 알파 스윕\n",
        "# =========================\n",
        "ALPHAS = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "K = 5\n",
        "\n",
        "rows = []\n",
        "for a in ALPHAS:\n",
        "    idx, _ = search_hybrid(query_sbert, corpus_sbert, X_query, X_corpus, alpha=a, top_k=K)\n",
        "    rows.append({\n",
        "        'alpha': a,\n",
        "        'Recall@1': recall_at_k(idx, query_labels, corpus_labels, 1),\n",
        "        'Recall@5': recall_at_k(idx, query_labels, corpus_labels, 5),\n",
        "        'MRR': mrr(idx, query_labels, corpus_labels)\n",
        "    })\n",
        "\n",
        "pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. 자유 질의 검색 및 간단 평가\n",
        "- 사용자가 입력한 자연어 질의에 대해 SBERT/TF‑IDF/Hybrid 결과를 비교\n",
        "- 정답 라벨이 없는 경우 키워드 기반 약식 qrels로 Precision@k/Recall@k/nDCG@k 산출\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SBERT | P@5=1.000 R@5=0.004 nDCG@5=0.476\n",
            "TF-IDF | P@5=1.000 R@5=0.004 nDCG@5=1.000\n",
            "Hybrid | P@5=1.000 R@5=0.004 nDCG@5=0.476\n",
            "\n",
            "[SBERT Top-5] What is the impact of interest rate hikes on the stock market?\n",
            "- Treasuries Up, Rate Hike Still in Offing (Reuters) Reuters - U.S. Treasury debt made moderate gains\\on Tuesday after a key reading of U.S. i\n",
            "- Election-Year Rate Hike Puzzles Some WASHINGTON - Going against conventional wisdom, the Federal Reserve is raising interest rates in an ele\n",
            "- South Korea lowers interest rates South Korea's central bank cuts interest rates by a quarter percentage point to 3.5 in a bid to drive grow\n",
            "- Stocks Higher on Oil Price Relief (Reuters) Reuters - U.S. stocks gained on Monday, getting\\a boost from lower oil prices after news the Ven\n",
            "- Stocks Rise on Drop in Consumer Prices A drop in consumer prices and a decline in crude oil futures Tuesday allowed investors to put aside w\n",
            "\n",
            "[TF-IDF Top-5] What is the impact of interest rate hikes on the stock market?\n",
            "- Dollar Gains on Euro After Muted U.S. CPI  NEW YORK (Reuters) - The dollar posted gains against the  euro on Tuesday, digesting a slew of U.\n",
            "- Veteran inventor in market float Trevor Baylis, the veteran inventor famous for creating the Freeplay clockwork radio, is planning to float \n",
            "- Hungarian central bank cuts key interest rate by half percentage point (AFP) AFP - The Hungarian central bank cut its benchmark interest rat\n",
            "- Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings a\n",
            "- Nikkei Falls Over 1 Pct on Oil Worries (Reuters) Reuters - Tokyo's Nikkei fell more than one percent\\by mid-morning on Monday as investors s\n",
            "\n",
            "[Hybrid Top-5] What is the impact of interest rate hikes on the stock market?\n",
            "- Treasuries Up, Rate Hike Still in Offing (Reuters) Reuters - U.S. Treasury debt made moderate gains\\on Tuesday after a key reading of U.S. i\n",
            "- Election-Year Rate Hike Puzzles Some WASHINGTON - Going against conventional wisdom, the Federal Reserve is raising interest rates in an ele\n",
            "- South Korea lowers interest rates South Korea's central bank cuts interest rates by a quarter percentage point to 3.5 in a bid to drive grow\n",
            "- Stocks Higher on Oil Price Relief (Reuters) Reuters - U.S. stocks gained on Monday, getting\\a boost from lower oil prices after news the Ven\n",
            "- Stocks Rise on Drop in Consumer Prices A drop in consumer prices and a decline in crude oil futures Tuesday allowed investors to put aside w\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 6. 자유 질의 검색 + 약식 평가\n",
        "# =========================\n",
        "from typing import Iterable\n",
        "\n",
        "\n",
        "def tokenize_simple(s: str) -> List[str]:\n",
        "    return [w.lower() for w in str(s).split() if w.strip()]\n",
        "\n",
        "\n",
        "def keyword_qrels(query: str, docs: List[str], top_k: int = 10) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    아주 단순한 키워드 일치 기반 relevance 벡터 생성(0/1/2 점수).\n",
        "    - query 토큰이 문서에 포함되면 가산\n",
        "    - 점수 0/1/2로 제한하여 nDCG에서 사용\n",
        "    \"\"\"\n",
        "    qtok = set(tokenize_simple(query))\n",
        "    rel = np.zeros(len(docs), dtype=np.int32)\n",
        "    for i, d in enumerate(docs):\n",
        "        dtok = set(tokenize_simple(d))\n",
        "        inter = len(qtok.intersection(dtok))\n",
        "        if inter >= 3:\n",
        "            rel[i] = 2\n",
        "        elif inter >= 1:\n",
        "            rel[i] = 1\n",
        "    return rel\n",
        "\n",
        "\n",
        "def precision_at_k(rels: np.ndarray, top_idx: np.ndarray, k: int) -> float:\n",
        "    hits = 0\n",
        "    for i in top_idx[:k]:\n",
        "        hits += 1 if rels[i] > 0 else 0\n",
        "    return hits / k\n",
        "\n",
        "\n",
        "def recall_at_k_from_rels(rels: np.ndarray, top_idx: np.ndarray, k: int) -> float:\n",
        "    total_rel = int(np.sum(rels > 0))\n",
        "    if total_rel == 0:\n",
        "        return 0.0\n",
        "    hits = 0\n",
        "    for i in top_idx[:k]:\n",
        "        hits += 1 if rels[i] > 0 else 0\n",
        "    return hits / total_rel\n",
        "\n",
        "\n",
        "def ndcg_at_k(rels: np.ndarray, top_idx: np.ndarray, k: int) -> float:\n",
        "    gains = [(2**int(rels[i]) - 1) for i in top_idx[:k]]\n",
        "    dcg = 0.0\n",
        "    for r, g in enumerate(gains, start=1):\n",
        "        dcg += g / np.log2(r + 1)\n",
        "    # Ideal DCG\n",
        "    ideal = sorted([(2**int(x) - 1) for x in rels], reverse=True)[:k]\n",
        "    idcg = 0.0\n",
        "    for r, g in enumerate(ideal, start=1):\n",
        "        idcg += g / np.log2(r + 1)\n",
        "    return (dcg / idcg) if idcg > 0 else 0.0\n",
        "\n",
        "\n",
        "# 사용자 질의 예시\n",
        "q = 'What is the impact of interest rate hikes on the stock market?'\n",
        "\n",
        "# 검색 실행\n",
        "q_emb = sbert_encode([q])\n",
        "Xq = vectorizer.transform([q])\n",
        "\n",
        "s_idx1, s_sc1 = search_sbert(q_emb, corpus_sbert, top_k=10)\n",
        "t_idx1, t_sc1 = search_tfidf(Xq, X_corpus, top_k=10)\n",
        "h_idx1, h_sc1 = search_hybrid(q_emb, corpus_sbert, Xq, X_corpus, alpha=0.5, top_k=10)\n",
        "\n",
        "# 약식 qrels 생성 (전체 코퍼스 기준 relevance)\n",
        "rels = keyword_qrels(q, corpus_texts)\n",
        "\n",
        "# 지표 계산 (top-10)\n",
        "for name, idxs in [(\"SBERT\", s_idx1[0]), (\"TF-IDF\", t_idx1[0]), (\"Hybrid\", h_idx1[0])]:\n",
        "    p5 = precision_at_k(rels, idxs, 5)\n",
        "    r5 = recall_at_k_from_rels(rels, idxs, 5)\n",
        "    n5 = ndcg_at_k(rels, idxs, 5)\n",
        "    print(f\"{name} | P@5={p5:.3f} R@5={r5:.3f} nDCG@5={n5:.3f}\")\n",
        "\n",
        "# 상위 결과 미리보기\n",
        "def preview(name: str, idxs: Iterable[int], k: int = 5):\n",
        "    print(f\"\\n[{name} Top-{k}] {q}\")\n",
        "    for i in list(idxs)[:k]:\n",
        "        print(\"-\", corpus_texts[i][:140].replace(\"\\n\",\" \"))\n",
        "\n",
        "preview(\"SBERT\", s_idx1[0])\n",
        "preview(\"TF-IDF\", t_idx1[0])\n",
        "preview(\"Hybrid\", h_idx1[0])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (metacode)",
      "language": "python",
      "name": "metacode-lecture"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
