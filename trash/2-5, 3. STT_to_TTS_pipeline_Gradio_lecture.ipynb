{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-5, 3강 STT→후처리→TTS 파이프라인 — Gradio 데모\n",
        "\n",
        "- 목표: 음성 입력→전사→정규화→합성까지 하나의 파이프라인 구성\n",
        "- 데이터: 수강생 음성 파일(또는 마이크 입력)\n",
        "- 규칙(강의용): UI는 `gradio` 최소구성, 내부 처리는 `whisper`/`TTS`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 구성\n",
        "- 파이프라인 설계(입력→전사→정규화→합성)\n",
        "- Whisper 전사(타임스탬프/언어 지정)\n",
        "- 텍스트 후처리(간단 정규화, 금칙어 제거 예)\n",
        "- Coqui TTS 합성(문장 단위 분할 합성)\n",
        "- Gradio UI 구성(업로드→전사→합성→다운로드)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 준비 및 라이브러리 임포트\n",
        "- `whisper`, `TTS`, `torchaudio`, `gradio`\n",
        "- 폰트/경고 설정, 디바이스 확인\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "try:\n",
        "    import whisper\n",
        "    _HAS_WHISPER = True\n",
        "except Exception:\n",
        "    _HAS_WHISPER = False\n",
        "\n",
        "try:\n",
        "    from TTS.api import TTS as COQUI_TTS\n",
        "    _HAS_TTS = True\n",
        "except Exception:\n",
        "    _HAS_TTS = False\n",
        "\n",
        "try:\n",
        "    import gradio as gr\n",
        "    _HAS_GRADIO = True\n",
        "except Exception:\n",
        "    _HAS_GRADIO = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=r\"Glyph.*missing from font.*\", category=UserWarning)\n",
        "\n",
        "plt.rcParams['font.family'] = 'AppleGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', DEVICE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 유틸: 오디오 로딩/저장, 간단 텍스트 정규화\n",
        "- 16kHz/모노 변환, 문장 분할, 기초 정규화(공백/특수문자 간소화)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_audio_16k_mono(path: str):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError('오디오 파일 없음: ' + path)\n",
        "    wav, sr = torchaudio.load(path)\n",
        "    if wav.size(0) > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)\n",
        "    if sr != 16000:\n",
        "        wav = torchaudio.transforms.Resample(sr, 16000)(wav)\n",
        "        sr = 16000\n",
        "    return wav.squeeze(0), sr\n",
        "\n",
        "_sentence_splitter = re.compile(r\"(?<=[.!?。？!])\\s+\")\n",
        "_non_korean_keep = re.compile(r\"[^0-9A-Za-z가-힣.,!?\\s]\")\n",
        "\n",
        "def normalize_text(text: str) -> list[str]:\n",
        "    text = _non_korean_keep.sub(\" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    sentences = re.split(_sentence_splitter, text) if text else []\n",
        "    # 빈 문장 제거\n",
        "    return [s for s in sentences if s]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. STT/Whisper: 전사 함수(타임스탬프 포함 옵션)\n",
        "- 긴 파일은 분할 전사(선택), 여기서는 단일 파일 전사 예시\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def whisper_transcribe(path: str, model_name: str = 'base', language: str | None = None):\n",
        "    if not _HAS_WHISPER:\n",
        "        raise ImportError('whisper 설치 필요: pip install -U openai-whisper')\n",
        "    model = whisper.load_model(model_name, device=DEVICE)\n",
        "    out = model.transcribe(path, language=language)\n",
        "    return out['text']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. TTS(Coqui): 문장 단위 합성 및 병합\n",
        "- 문장별 합성 후 사이에 짧은 무음 패딩을 삽입해 자연스러운 연결\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tts_sentences(sentences: list[str], speaker_wavs: list[str], language: str = 'ko', pad_ms: int = 200, cleanup: bool = True):\n",
        "    if not _HAS_TTS:\n",
        "        raise ImportError('Coqui TTS 설치 필요: pip install TTS')\n",
        "    tts = COQUI_TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=(DEVICE=='cuda'))\n",
        "    sr = 24000  # xtts 기본 샘플레이트(모델/버전에 따라 다를 수 있습니다)\n",
        "    print('TTS 샘플레이트(가정):', sr)\n",
        "    wavs = []\n",
        "    silence = torch.zeros(int(sr * (pad_ms/1000.0)))\n",
        "    tmp_files = []\n",
        "    for s in sentences:\n",
        "        tmp = f\"seg_{abs(hash(s))%10_000}.wav\"\n",
        "        tts.tts_to_file(text=s, speaker_wav=speaker_wavs, language=language, file_path=tmp)\n",
        "        tmp_files.append(tmp)\n",
        "        w, r = torchaudio.load(tmp)\n",
        "        print('segment sr:', r)\n",
        "        w = w.mean(dim=0) if w.size(0) > 1 else w.squeeze(0)\n",
        "        if r != sr:\n",
        "            w = torchaudio.transforms.Resample(r, sr)(w.unsqueeze(0)).squeeze(0)\n",
        "        wavs.append(w)\n",
        "        wavs.append(silence.clone())\n",
        "    out = torch.cat(wavs) if wavs else torch.zeros(1)\n",
        "    out_path = 'pipeline_tts.wav'\n",
        "    torchaudio.save(out_path, out.unsqueeze(0), sr)\n",
        "    if cleanup:\n",
        "        for f in tmp_files:\n",
        "            try:\n",
        "                os.remove(f)\n",
        "            except Exception:\n",
        "                pass\n",
        "    return out_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 파이프라인 함수\n",
        "- 파일 입력→전사→정규화→문장별 합성→다운로드 경로 반환\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_pipeline(audio_path: str, language: str = 'ko', model_name: str = 'base', ref_wavs: list[str] | None = None):\n",
        "    # 1) 전사\n",
        "    text = whisper_transcribe(audio_path, model_name=model_name, language=language)\n",
        "    # 2) 텍스트 정규화/분할\n",
        "    sentences = normalize_text(text)\n",
        "    if not sentences:\n",
        "        sentences = [text]\n",
        "    # 3) 합성\n",
        "    if not ref_wavs:\n",
        "        raise ValueError('참조 화자 오디오(ref_wavs)가 필요합니다.')\n",
        "    out_wav = tts_sentences(sentences, ref_wavs, language=language)\n",
        "    return text, out_wav\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Gradio UI\n",
        "- 파일 업로드, 언어/모델 선택, 참조 화자 업로드, 결과 표시\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def app():\n",
        "    if not _HAS_GRADIO:\n",
        "        raise ImportError('gradio 설치 필요: pip install gradio')\n",
        "\n",
        "    def process(audio_file, language, model_name, ref_audio_files):\n",
        "        if audio_file is None or not audio_file:\n",
        "            return '오디오 파일을 업로드하세요.', None\n",
        "        # Gradio는 {'name': path, ...} 또는 str 경로를 줄 수 있음\n",
        "        in_path = audio_file if isinstance(audio_file, str) else audio_file.get('name')\n",
        "        refs = []\n",
        "        if ref_audio_files:\n",
        "            for f in ref_audio_files:\n",
        "                p = f if isinstance(f, str) else f.get('name')\n",
        "                # 16k/모노 보정 파일로 교체 저장\n",
        "                w, sr = load_audio_16k_mono(p)\n",
        "                tmp = f\"ref_{abs(hash(p))%10_000}.wav\"\n",
        "                torchaudio.save(tmp, w.unsqueeze(0), sr)\n",
        "                refs.append(tmp)\n",
        "        if not refs:\n",
        "            return '참조 화자 오디오를 업로드하세요.', None\n",
        "        text, out_wav = run_pipeline(in_path, language=language, model_name=model_name, ref_wavs=refs)\n",
        "        return text, out_wav\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# STT→TTS 파이프라인 데모\")\n",
        "        with gr.Row():\n",
        "            audio_in = gr.Audio(type=\"filepath\", label=\"입력 오디오\")\n",
        "            ref_in = gr.Files(label=\"참조 화자 오디오(1~3개)\")\n",
        "        with gr.Row():\n",
        "            lang = gr.Dropdown(choices=[\"ko\",\"en\",\"ja\"], value=\"ko\", label=\"언어\")\n",
        "            model = gr.Dropdown(choices=[\"tiny\",\"base\",\"small\"], value=\"base\", label=\"Whisper 모델\")\n",
        "        run_btn = gr.Button(\"전사→정규화→합성 실행\")\n",
        "        transcript = gr.Textbox(label=\"전사 결과\")\n",
        "        audio_out = gr.Audio(label=\"합성 결과\")\n",
        "        run_btn.click(process, inputs=[audio_in, lang, model, ref_in], outputs=[transcript, audio_out])\n",
        "    return demo\n",
        "\n",
        "# 실행 예시 (주피터에서는 아래 두 줄을 수동으로 실행)\n",
        "# if _HAS_GRADIO:\n",
        "#     demo = app()\n",
        "#     demo.launch()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
