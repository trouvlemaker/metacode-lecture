{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-6, 2강 임베딩 기반 유사도 검색 & 미니 RAG (CPU)\n",
        "\n",
        "- 목표: 문서 임베딩으로 top‑k 검색 구현, 간단 템플릿 요약으로 미니 RAG 구성\n",
        "- 데이터: 짧은 문서 코퍼스(뉴스 제목/요약), 2k 정도 샘플\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 구성 (Overview)\n",
        "- 코퍼스 로드/정제 → SBERT 임베딩 생성/캐시 → 최근접 탐색(코사인) → 미니 RAG 응답 조합 → 간단 데모\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0-1. 1강(텍스트 분류) ↔ 2강(임베딩·RAG) 연계 개요\n",
        "- 1강 요지: 전통 ML(TF‑IDF+LR) vs 문장 임베딩(SBERT+LR) 비교, 속도/성능 트레이드오프 확인\n",
        "- 2강 초점: SBERT 임베딩을 활용한 유사도 기반 검색과 미니 RAG 조합\n",
        "- 브리지 포인트:\n",
        "  - TF‑IDF: 단어 빈도 기반(빠름, 실시간/대량 처리 유리), 의미적 유사도 한계\n",
        "  - SBERT: 문맥 의미 기반(정확도/일반화 장점), CPU 단독 시 속도/추론비용 부담\n",
        "  - 실무: 하이브리드(스파스 TF‑IDF + 덴스 SBERT) 혹은 단계적 파이프라인이 효과적\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 설정 및 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os, time, random, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "\n",
        "plt.rcParams['font.family'] = 'AppleGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# 시드 고정\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 코퍼스 준비\n",
        "- `datasets`에서 뉴스 샘플 로드(없으면 간단 더미 데이터)\n",
        "- 텍스트 길이 필터, 중복 제거\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def load_news_corpus(n_per_class: int = 500) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    AG News 데이터셋에서 클래스별로 동일한 수의 샘플을 추출하여 로드합니다.\n",
        "\n",
        "    Args:\n",
        "        n_per_class (int): 각 클래스에서 가져올 샘플 수 (기본=500)\n",
        "\n",
        "    Returns:\n",
        "        df (pd.DataFrame): 뉴스 데이터 프레임\n",
        "            - text  : 뉴스 기사 텍스트\n",
        "            - label : 카테고리 (0=World, 1=Sports, 2=Business, 3=Sci/Tech)\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------\n",
        "    # AG News 전체 데이터 로드 (train split: 120k 샘플)\n",
        "    # -------------------------\n",
        "    ds = load_dataset('ag_news', split='train')\n",
        "\n",
        "    rows = []\n",
        "    # -------------------------\n",
        "    # 0~3 라벨별로 균등 샘플링\n",
        "    # -------------------------\n",
        "    for lab in range(4):\n",
        "        # 해당 라벨에 속하는 기사에서 n_per_class개 추출\n",
        "        sub = ds.filter(lambda ex: ex['label'] == lab).select(range(n_per_class))\n",
        "        for r in sub:\n",
        "            rows.append({\n",
        "                'text': r['text'],    # 전체 뉴스 기사 텍스트\n",
        "                'label': r['label']   # 클래스 라벨\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # 텍스트 길이 필터링 (너무 짧거나 긴 기사 제거)\n",
        "    df['len'] = df['text'].str.len()\n",
        "    df = df[(df['len'] >= 30) & (df['len'] <= 500)]\n",
        "\n",
        "    # 중복 제거 및 인덱스 리셋\n",
        "    df = df.drop_duplicates('text').drop(columns=['len']).reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 275974.94 examples/s]\n",
            "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 202594.18 examples/s]\n",
            "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 245371.69 examples/s]\n",
            "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 278898.69 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1170, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Venezuelans Vote Early in Referendum on Chavez...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S.Koreans Clash with Police on Iraq Troop Disp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  Venezuelans Vote Early in Referendum on Chavez...      0\n",
              "1  S.Koreans Clash with Police on Iraq Troop Disp...      0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 각 클래스에서 300개씩 샘플링하여 코퍼스 생성\n",
        "corpus = load_news_corpus(300)\n",
        "\n",
        "# 데이터셋 크기와 앞부분 샘플 확인\n",
        "print(corpus.shape)\n",
        "corpus.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 임베딩 생성 및 캐시(npz)\n",
        "- 소형 SBERT 모델 사용, CPU 배치 인코딩\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2-1. (옵션) SBERT 미설치/다운로드 불가 시 TF‑IDF 검색으로 폴백\n",
        "- 실습/현장 환경에서 `sentence-transformers` 설치나 모델 다운로드가 어려울 수 있음\n",
        "- 이때 간단한 TF‑IDF 코사인 유사도 검색으로 대체하여 데모 지속\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TF-IDF 폴백 구현 (SBERT 미사용 시)\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 전역 캐시 (코퍼스 로드 후 채움)\n",
        "_VEC = None\n",
        "_MAT = None\n",
        "\n",
        "\n",
        "def tfidf_build(corpus_texts: List[str], max_features: int = 30000):\n",
        "    \"\"\"\n",
        "    코퍼스를 TF-IDF로 변환하고 전역 캐시에 저장합니다.\n",
        "    - normalize/L2는 사이킷런 내부에서 처리됨\n",
        "    - 희소 행렬을 유지해 메모리 절약\n",
        "    \"\"\"\n",
        "    global _VEC, _MAT\n",
        "    _VEC = TfidfVectorizer(max_features=max_features, ngram_range=(1, 2))\n",
        "    _MAT = _VEC.fit_transform(corpus_texts)\n",
        "    return _VEC, _MAT\n",
        "\n",
        "\n",
        "def tfidf_search(query: str, k: int = 5) -> List[Tuple[int, float, str]]:\n",
        "    \"\"\"\n",
        "    TF-IDF 코사인 유사도로 top-k 문서를 반환합니다.\n",
        "    반환: (문서인덱스, 유사도, 원문)\n",
        "    \"\"\"\n",
        "    if _VEC is None or _MAT is None:\n",
        "        raise RuntimeError('먼저 tfidf_build를 호출해 코퍼스를 준비하세요.')\n",
        "    qv = _VEC.transform([query])\n",
        "    sim = cosine_similarity(qv, _MAT)[0]  # shape: (n_docs,)\n",
        "    top = np.argsort(-sim)[:k]\n",
        "    return [(int(i), float(sim[i]), idx_text[i]) for i in top]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-1. 하이브리드 검색(개념): TF‑IDF + SBERT\n",
        "- 스파스(TF‑IDF)와 덴스(SBERT) 각각의 장점을 결합\n",
        "- 간단 가이드: 두 유사도 점수를 0~1 정규화 후 \\(\\alpha\\) 가중 합 → 상위 k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (선택) 간단 하이브리드 구현 — TF‑IDF + SBERT 가중합\n",
        "# 전제: SBERT(E, idx_text)와 TF‑IDF(_VEC, _MAT, idx_text)가 준비되어 있다고 가정\n",
        "\n",
        "def hybrid_search(query: str, k: int = 5, alpha: float = 0.5):\n",
        "    \"\"\"\n",
        "    두 점수의 가중합으로 상위 k개 반환\n",
        "    alpha: SBERT 가중(0~1), (1-alpha): TF‑IDF 가중\n",
        "    \"\"\"\n",
        "    # SBERT 점수 (정규화 임베딩 기준: 코사인 유사도 = dot)\n",
        "    qv = embed_corpus([query], batch_size=1)  # shape: (1, dim)\n",
        "    sbert_scores = (E @ qv[0]).astype(float)  # shape: (n_docs,)\n",
        "\n",
        "    # TF‑IDF 점수\n",
        "    tfidf_scores = None\n",
        "    if _VEC is not None and _MAT is not None:\n",
        "        qv2 = _VEC.transform([query])\n",
        "        tfidf_scores = cosine_similarity(qv2, _MAT)[0]\n",
        "        tfidf_scores = np.asarray(tfidf_scores, dtype=float)\n",
        "\n",
        "    # 경우의 수 처리\n",
        "    if sbert_scores is None and tfidf_scores is None:\n",
        "        raise RuntimeError('SBERT/TF‑IDF 어느 쪽도 준비되지 않았습니다.')\n",
        "    if sbert_scores is None:\n",
        "        scores = tfidf_scores\n",
        "    elif tfidf_scores is None:\n",
        "        scores = sbert_scores\n",
        "    else:\n",
        "        # 간단 min-max 정규화 후 가중합\n",
        "        def norm01(x):\n",
        "            x_min, x_max = float(np.min(x)), float(np.max(x))\n",
        "            if x_max - x_min < 1e-12:\n",
        "                return np.zeros_like(x)\n",
        "            return (x - x_min) / (x_max - x_min)\n",
        "        scores = alpha*norm01(sbert_scores) + (1-alpha)*norm01(tfidf_scores)\n",
        "\n",
        "    top = np.argsort(-scores)[:k]\n",
        "    return [(int(i), float(scores[i]), idx_text[i]) for i in top]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. CPU 환경 팁(실무)\n",
        "- SBERT: `all-MiniLM-L6-v2` 등 경량 모델, `device='cpu'`, `batch_size` 완만 조절\n",
        "- 캐시: 임베딩 `npz` 저장/로드, 최초 1회만 생성\n",
        "- 검색: `NearestNeighbors(metric='cosine', algorithm='brute')`는 소규모/데모에 충분\n",
        "- 폴백: 설치/다운로드 불가 시 TF‑IDF 경로 사용, 가능하면 하이브리드로 보완\n",
        "- 추론 속도: 실시간 질의 다량 처리 시 쿼리 배치 처리 또는 인덱스 라이브러리(FAISS/Annoy) 고려\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. 실습 과제(선택)\n",
        "1) 질의 5개를 자체 정의하고, SBERT / TF‑IDF / 하이브리드 각각의 top‑3 결과를 비교해보세요.\n",
        "2) 하이브리드의 \\(\\alpha\\) 값을 {0.2, 0.5, 0.8}로 바꿔 결과 변화를 관찰하세요.\n",
        "3) `compose_response` 템플릿을 수정해, 점수/출처 표시를 개선해보세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1170, 384)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def embed_corpus(texts: list[str], model_name='sentence-transformers/all-MiniLM-L6-v2', batch_size=64):\n",
        "    model = SentenceTransformer(model_name, device='cpu')\n",
        "    outs = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        v = model.encode(texts[i:i+batch_size], batch_size=batch_size, show_progress_bar=False, convert_to_numpy=True, normalize_embeddings=True)\n",
        "        outs.append(v)\n",
        "    return np.vstack(outs)\n",
        "\n",
        "cache_path = './data/embeddings_agnews.npz'\n",
        "if os.path.exists(cache_path):\n",
        "    dat = np.load(cache_path, allow_pickle=True)\n",
        "    E = dat['E']; idx_text = dat['idx_text']\n",
        "    idx_text = idx_text.tolist()\n",
        "else:\n",
        "    _t0 = time.perf_counter()\n",
        "    E = embed_corpus(corpus['text'].tolist(), batch_size=64)\n",
        "    dt = time.perf_counter()-_t0\n",
        "    print('임베딩(sec):', round(dt,2))\n",
        "    idx_text = corpus['text'].tolist()\n",
        "    np.savez_compressed(cache_path, E=E, idx_text=np.array(idx_text, dtype=object))\n",
        "\n",
        "E.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 최근접 탐색(코사인) 및 검색 함수\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 0.346 Microsoft wants to improve your image New imaging software is making eyes at those squinty camera-phone pictures....\n",
            "2 0.337 Sharp brings 3D to PCs, without the funny specs Firm brings tech already used in phones and laptops to desktops. Screen ...\n",
            "3 0.315 The Eyes Are the Window to Hypertension The tiniest blood vessels of the eye can provide a glimpse that may warn of futu...\n",
            "4 0.247 Were the judges by any chance French? Kosuke Kitajima #39;s technique may get a sharper eye from officials today in the ...\n",
            "5 0.242 New NASA Supercomputer to Aid Theorists and Shuttle Engineers (SPACE.com) SPACE.com - NASA researchers have teamed up wi...\n"
          ]
        }
      ],
      "source": [
        "# sklearn NearestNeighbors로 코사인 기반 kNN 인덱스\n",
        "nn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "nn.fit(E)\n",
        "\n",
        "\n",
        "def search_topk(query: str, k: int = 5) -> list[tuple[int, float, str]]:\n",
        "    # 쿼리 임베딩\n",
        "    qv = embed_corpus([query], batch_size=1)\n",
        "    dist, idx = nn.kneighbors(qv, n_neighbors=k, return_distance=True)\n",
        "    # cosine distance → similarity = 1 - distance\n",
        "    out = []\n",
        "    for d, i in zip(dist[0], idx[0]):\n",
        "        out.append((int(i), float(1.0 - d), idx_text[i]))\n",
        "    return out\n",
        "\n",
        "# 예시 검색\n",
        "for i, (idx_i, sim, text) in enumerate(search_topk('New AI system beats benchmarks in vision tasks', k=5), 1):\n",
        "    print(i, round(sim,3), text[:120]+'...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 미니 RAG 조합 함수\n",
        "- retrieved 문서들을 템플릿으로 단순 요약/응답 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: What is the impact of interest rate hikes on the stock market?\n",
            "\n",
            "[관련 문서 요약]\n",
            "- (1) 유사도 0.50: Treasuries Up, Rate Hike Still in Offing (Reuters) Reuters - U.S. Treasury debt made moderate gains\\on Tuesday after a key reading of U.S. inflation proved soft...\n",
            "- (2) 유사도 0.46: Election-Year Rate Hike Puzzles Some WASHINGTON - Going against conventional wisdom, the Federal Reserve is raising interest rates in an election year. And it i...\n",
            "- (3) 유사도 0.43: South Korea lowers interest rates South Korea's central bank cuts interest rates by a quarter percentage point to 3.5 in a bid to drive growth in the economy....\n",
            "\n",
            "A: 위 문서들을 참고하면, 질문과 직접적으로 연관된 핵심은 위 목록에서 확인 가능합니다.\n"
          ]
        }
      ],
      "source": [
        "def compose_response(query: str, topk: list[tuple[int, float, str]], k: int = 3) -> str:\n",
        "    parts = [f\"Q: {query}\", \"\\n[관련 문서 요약]\"]\n",
        "    for j, (idx_i, sim, text) in enumerate(topk[:k], 1):\n",
        "        parts.append(f\"- ({j}) 유사도 {sim:.2f}: {text[:160]}...\")\n",
        "    parts.append(\"\\nA: 위 문서들을 참고하면, 질문과 직접적으로 연관된 핵심은 위 목록에서 확인 가능합니다.\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "q = 'What is the impact of interest rate hikes on the stock market?'\n",
        "res = search_topk(q, k=5)\n",
        "print(compose_response(q, res, k=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 간단 데모\n",
        "- 질의 입력 → top‑k 리스트와 응답 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Q: Latest advances in computer vision benchmarks\n",
            "\n",
            "[관련 문서 요약]\n",
            "- (1) 유사도 0.32: Microsoft wants to improve your image New imaging software is making eyes at those squinty camera-phone pictures....\n",
            "- (2) 유사도 0.32: Sharp brings 3D to PCs, without the funny specs Firm brings tech already used in phones and laptops to desktops. Screen creates different pixel images for each ...\n",
            "- (3) 유사도 0.32: Microsoft Upgrades Software for Digital Pictures  SEATTLE (Reuters) - Microsoft Corp. &lt;MSFT.O&gt; released on  Tuesday the latest version of its software for...\n",
            "\n",
            "A: 위 문서들을 참고하면, 질문과 직접적으로 연관된 핵심은 위 목록에서 확인 가능합니다.\n",
            "============================================================\n",
            "Q: Effects of monetary policy on markets\n",
            "\n",
            "[관련 문서 요약]\n",
            "- (1) 유사도 0.44: Fed minutes show dissent over inflation (USATODAY.com) USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last wee...\n",
            "- (2) 유사도 0.44: Treasuries Edge Ahead on Inflation Relief  NEW YORK (Reuters) - Treasury debt prices firmed on Tuesday  after a key reading of U.S. inflation proved  softer-tha...\n",
            "- (3) 유사도 0.43: Treasuries Up, Rate Hike Still in Offing (Reuters) Reuters - U.S. Treasury debt made moderate gains\\on Tuesday after a key reading of U.S. inflation proved soft...\n",
            "\n",
            "A: 위 문서들을 참고하면, 질문과 직접적으로 연관된 핵심은 위 목록에서 확인 가능합니다.\n",
            "============================================================\n",
            "Q: Championship highlights of the season\n",
            "\n",
            "[관련 문서 요약]\n",
            "- (1) 유사도 0.38: Today's schedule Pro baseball: Red Sox vs. Toronto at Fenway Park, 7 p.m.; Atlantic League -- Nashua vs. Camden at Holman Stadium, Nashua, 6:30 p.m.; Internatio...\n",
            "- (2) 유사도 0.37: Offense Needs Work There were few offensive highlights during Virginia Tech's first scrimmage of fall practice on Saturday....\n",
            "- (3) 유사도 0.37: Many similarities, differences between #39;04 US basketball and #39;80 Soviet hockey teams This was no miracle, but you could not tell by the amount of elation ...\n",
            "\n",
            "A: 위 문서들을 참고하면, 질문과 직접적으로 연관된 핵심은 위 목록에서 확인 가능합니다.\n"
          ]
        }
      ],
      "source": [
        "queries = [\n",
        "    'Latest advances in computer vision benchmarks',\n",
        "    'Effects of monetary policy on markets',\n",
        "    'Championship highlights of the season',\n",
        "]\n",
        "for q in queries:\n",
        "    res = search_topk(q, k=5)\n",
        "    print('='*60)\n",
        "    print(compose_response(q, res, k=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. TF-IDF 임베딩 재정의(설치 전제)\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 전역 캐시 (코퍼스 로드 후 채움)\n",
        "_VEC = None\n",
        "_MAT = None\n",
        "\n",
        "\n",
        "def tfidf_build(corpus_texts: List[str], max_features: int = 30000):\n",
        "    \"\"\"\n",
        "    코퍼스를 TF-IDF로 변환하고 전역 캐시에 저장합니다.\n",
        "    - normalize/L2는 사이킷런 내부에서 처리됨\n",
        "    - 희소 행렬을 유지해 메모리 절약\n",
        "    \"\"\"\n",
        "    global _VEC, _MAT\n",
        "    _VEC = TfidfVectorizer(max_features=max_features, ngram_range=(1, 2))\n",
        "    _MAT = _VEC.fit_transform(corpus_texts)\n",
        "    return _VEC, _MAT\n",
        "\n",
        "\n",
        "def tfidf_search(query: str, k: int = 5) -> List[Tuple[int, float, str]]:\n",
        "    \"\"\"\n",
        "    TF-IDF 코사인 유사도로 top-k 문서를 반환합니다.\n",
        "    반환: (문서인덱스, 유사도, 원문)\n",
        "    \"\"\"\n",
        "    if _VEC is None or _MAT is None:\n",
        "        raise RuntimeError('먼저 tfidf_build를 호출해 코퍼스를 준비하세요.')\n",
        "    qv = _VEC.transform([query])\n",
        "    sim = cosine_similarity(qv, _MAT)[0]\n",
        "    top = np.argsort(-sim)[:k]\n",
        "    return [(int(i), float(sim[i]), idx_text[i]) for i in top]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. TF-IDF 벡터화 실행 (코퍼스 텍스트)\n",
        "_ = tfidf_build(corpus['text'].tolist(), max_features=30000)\n",
        "print(_MAT.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. 세 가지 검색 방식 비교 데모\n",
        "queries = [\n",
        "    'Latest advances in computer vision benchmarks',\n",
        "    'Effects of monetary policy on markets',\n",
        "    'Championship highlights of the season',\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print('='*80)\n",
        "    print('Q:', q)\n",
        "    # SBERT\n",
        "    sbert_top = search_topk(q, k=5)\n",
        "    print('\\n[SBERT top-3]')\n",
        "    for j, (i, sim, text) in enumerate(sbert_top[:3], 1):\n",
        "        print(f' ({j}) {sim:.2f} | {text[:120]}...')\n",
        "    \n",
        "    # TF-IDF\n",
        "    tfidf_top = tfidf_search(q, k=5)\n",
        "    print('\\n[TF-IDF top-3]')\n",
        "    for j, (i, sim, text) in enumerate(tfidf_top[:3], 1):\n",
        "        print(f' ({j}) {sim:.2f} | {text[:120]}...')\n",
        "    \n",
        "    # Hybrid\n",
        "    hybrid_top = hybrid_search(q, k=5, alpha=0.5)\n",
        "    print('\\n[Hybrid top-3]')\n",
        "    for j, (i, score, text) in enumerate(hybrid_top[:3], 1):\n",
        "        print(f' ({j}) {score:.2f} | {text[:120]}...')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (metacode)",
      "language": "python",
      "name": "metacode-lecture"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
