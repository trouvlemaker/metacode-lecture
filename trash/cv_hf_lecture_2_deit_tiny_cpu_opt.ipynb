{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a92dd7b",
   "metadata": {},
   "source": [
    "# ğŸš€ 2ê°• (CPU-Optimized, Hugging Face): **DeiT-Tiny** Transfer Learning\n",
    "\n",
    "**GPU ì—†ì´ë„ ë™ì‘**í•˜ì§€ë§Œ, CPUì—ì„œëŠ” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ë‹¤ìŒê³¼ ê°™ì´ ìµœì í™”í–ˆìŠµë‹ˆë‹¤.\n",
    "- ëª¨ë¸: `facebook/deit-tiny-patch16-224` (ì‘ê³  ë¹ ë¦„)\n",
    "- **Feature Extraction(ë°±ë³¸ freeze)** ê¸°ë³¸, **Fine-tuning**ì€ ì„ íƒ\n",
    "- **Subset í•™ìŠµ ì˜µì…˜**(ê¸°ë³¸ 20%) + ì‘ì€ ë°°ì¹˜/ì—í­\n",
    "- `TrainingArguments(no_cuda=...)`ë¡œ CPU ê°•ì œ ê°€ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ff233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers datasets accelerate evaluate\n",
    "\n",
    "import os, numpy as np, random, matplotlib.pyplot as plt, torch\n",
    "from torchvision import datasets as tvdatasets\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 ë¡œë“œ â†’ numpy ë³€í™˜ â†’ train/val/test ë¶„í• \n",
    "root='./data'\n",
    "train_full = tvdatasets.CIFAR10(root=root, train=True, download=True)\n",
    "test_set   = tvdatasets.CIFAR10(root=root, train=False, download=True)\n",
    "class_names = train_full.classes\n",
    "\n",
    "def to_numpy_list(tv_dataset):\n",
    "    imgs, labs = [], []\n",
    "    for img, lab in tv_dataset:\n",
    "        imgs.append(np.array(img)); labs.append(lab)\n",
    "    return imgs, labs\n",
    "\n",
    "images_train, labels_train = to_numpy_list(train_full)\n",
    "images_test,  labels_test  = to_numpy_list(test_set)\n",
    "\n",
    "# Subset ì˜µì…˜ (CPUìš©): trainì˜ ì¼ë¶€ë§Œ ì‚¬ìš©\n",
    "SUBSET_FRACTION = 0.2   # 20%ë§Œ ì‚¬ìš© (í•„ìš”ì‹œ 0.1 ~ 0.3ë¡œ ì¡°ì •)\n",
    "idx = np.random.RandomState(42).permutation(len(images_train))\n",
    "subset_len = int(len(images_train)*SUBSET_FRACTION)\n",
    "sub_idx = idx[:subset_len]\n",
    "images_train = [images_train[i] for i in sub_idx]\n",
    "labels_train = [labels_train[i] for i in sub_idx]\n",
    "\n",
    "tr_imgs, va_imgs, tr_lbls, va_lbls = train_test_split(\n",
    "    images_train, labels_train, test_size=0.2, random_state=42, stratify=labels_train\n",
    ")\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_dict({\"image\": tr_imgs, \"label\": tr_lbls}),\n",
    "    \"validation\": Dataset.from_dict({\"image\": va_imgs, \"label\": va_lbls}),\n",
    "    \"test\": Dataset.from_dict({\"image\": images_test, \"label\": labels_test})\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ì€ ëª¨ë¸(DeiT-Tiny) + ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ\n",
    "model_name = \"facebook/deit-tiny-patch16-224\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=10,\n",
    "    id2label={i:c for i,c in enumerate(class_names)},\n",
    "    label2id={c:i for i,c in enumerate(class_names)},\n",
    ").to(device)\n",
    "\n",
    "def preprocess_examples(examples):\n",
    "    inputs = image_processor(images=examples[\"image\"], return_tensors=\"pt\")\n",
    "    inputs[\"labels\"] = torch.tensor(examples[\"label\"])\n",
    "    return inputs\n",
    "\n",
    "ds = ds.with_transform(preprocess_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction (ë°±ë³¸ freeze)\n",
    "for p in model.base_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "def collate_fn(batch):\n",
    "    out = {\"pixel_values\": torch.stack([b[\"pixel_values\"] for b in batch])}\n",
    "    out[\"labels\"] = torch.tensor([b[\"labels\"] for b in batch])\n",
    "    return out\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, preds), \"f1_macro\": f1_score(labels, preds, average=\"macro\")}\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./deit_tiny_fe\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",\n",
    "    no_cuda=not torch.cuda.is_available()  # CPU ê°•ì œ ê°€ëŠ¥\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    tokenizer=image_processor,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "fe_metrics = trainer.evaluate()\n",
    "fe_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7308ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ì„ íƒ) Fine-tuning: ìƒìœ„ ë¸”ë¡ë§Œ unfreeze (ê°€ë²¼ìš´ ì¶”ê°€ í•™ìŠµ)\n",
    "DO_FINETUNE = False  # CPUì—ì„œëŠ” False ê¶Œì¥, GPUë©´ Trueë¡œ ë³€ê²½\n",
    "\n",
    "if DO_FINETUNE:\n",
    "    for name, p in model.base_model.named_parameters():\n",
    "        if any(k in name for k in [\"encoder.layer.10\",\"encoder.layer.11\",\"layer.10\",\"layer.11\"]):\n",
    "            p.requires_grad = True\n",
    "\n",
    "    args_ft = TrainingArguments(\n",
    "        output_dir=\"./deit_tiny_ft\",\n",
    "        learning_rate=1e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=50,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        report_to=\"none\",\n",
    "        no_cuda=not torch.cuda.is_available()\n",
    "    )\n",
    "\n",
    "    trainer_ft = Trainer(\n",
    "        model=model,\n",
    "        args=args_ft,\n",
    "        train_dataset=ds[\"train\"],\n",
    "        eval_dataset=ds[\"validation\"],\n",
    "        tokenizer=image_processor,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer_ft.train()\n",
    "    ft_metrics = trainer_ft.evaluate()\n",
    "    print(ft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ í‰ê°€ + í˜¼ë™í–‰ë ¬\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_metrics = trainer.evaluate(ds[\"test\"])\n",
    "print('[Test] Accuracy:', test_metrics['eval_accuracy'])\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_logits(dset):\n",
    "    loader = DataLoader(dset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) for k,v in batch.items()}\n",
    "        out = model(**batch)\n",
    "        preds.append(out.logits.cpu().numpy())\n",
    "        labels.append(batch[\"labels\"].cpu().numpy())\n",
    "    return np.concatenate(preds), np.concatenate(labels)\n",
    "\n",
    "logits, y_true = predict_logits(ds[\"test\"])\n",
    "y_pred = logits.argmax(1)\n",
    "\n",
    "cm = confusion_matrix(y_true,y_pred,labels=list(range(10)))\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, interpolation='nearest'); plt.title('Confusion Matrix (DeiT-Tiny)'); plt.colorbar()\n",
    "plt.xticks(range(10), class_names, rotation=45); plt.yticks(range(10), class_names)\n",
    "plt.tight_layout(); plt.xlabel('Pred'); plt.ylabel('True'); plt.show()\n",
    "\n",
    "print('\\n[Classification Report]\\n', classification_report(y_true,y_pred,target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥\n",
    "trainer.save_model('deit_tiny_fe_cpu_opt')\n",
    "image_processor.save_pretrained('deit_tiny_fe_cpu_opt')\n",
    "print('saved: deit_tiny_fe_cpu_opt/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
