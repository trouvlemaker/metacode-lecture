{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43797ad7",
   "metadata": {},
   "source": [
    "# ğŸš€ 2ê°•: Transfer Learning ì‹¤ìŠµ â€” MobileNetV2 + Grad-CAM\n",
    "\n",
    "**ëª©í‘œ**\n",
    "- ì‚¬ì „í•™ìŠµ(Imagenet) ê¸°ë°˜ **MobileNetV2**ë¥¼ í™œìš©í•˜ì—¬ ì‘ì€ ë°ì´í„°ì—ë„ ë¹ ë¥´ê²Œ ë†’ì€ ì„±ëŠ¥ì„ ì–»ìŠµë‹ˆë‹¤.\n",
    "- **Feature Extraction â†’ Fine-tuning** ë‘ ë‹¨ê³„ë¡œ í•™ìŠµí•˜ê³ , **Grad-CAM**ìœ¼ë¡œ ì„¤ëª…ê°€ëŠ¥ì„±ì„ ë”í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì†Œìš”ì‹œê°„ ê°€ì´ë“œ (30ë¶„)**\n",
    "- ë„ì…/ë°ì´í„° ì¤€ë¹„(8ë¶„), ëª¨ë¸/í•™ìŠµ(15ë¶„), í‰ê°€/ì‹œê°í™”/Grad-CAM(7ë¶„)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1769ca",
   "metadata": {},
   "source": [
    "## 0. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54537f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4545c9",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„°ì…‹ ë¡œë“œ & ì „ì²˜ë¦¬ (CIFAR-10 â†’ 224Ã—224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "IMG_SIZE = 224\n",
    "def resize_images(x):\n",
    "    x = tf.image.resize(x, (IMG_SIZE, IMG_SIZE)).numpy()\n",
    "    return x\n",
    "\n",
    "x_tr = resize_images(x_tr)\n",
    "x_va = resize_images(x_va)\n",
    "x_te = resize_images(x_test)\n",
    "\n",
    "print('Shapes:', x_tr.shape, x_va.shape, x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfa148",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ” ë°ì´í„° ì¦ê°• (ì‹¤ì‹œê°„)\n",
    "data_aug = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b9374b",
   "metadata": {},
   "source": [
    "## 2. ì‚¬ì „í•™ìŠµ ëª¨ë¸ â€” Feature Extraction ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ§  MobileNetV2 (ImageNet ì‚¬ì „í•™ìŠµ) ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "base = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base.trainable = False  # Feature Extraction ë‹¨ê³„ì—ì„œëŠ” Freeze\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = data_aug(inputs)\n",
    "x = preprocess_input(x)  # MobileNetV2 ì „ì²˜ë¦¬\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True, monitor='val_accuracy')\n",
    "hist_fe = model.fit(x_tr, y_tr, validation_data=(x_va, y_va), epochs=5, batch_size=64, callbacks=[es], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ“ˆ í•™ìŠµ ê³¡ì„  í•¨ìˆ˜\n",
    "def plot_history(history, title='Training History'):\n",
    "    h = history.history\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(h['accuracy'], label='train_acc')\n",
    "    plt.plot(h['val_accuracy'], label='val_acc')\n",
    "    plt.title(title); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(h['loss'], label='train_loss')\n",
    "    plt.plot(h['val_loss'], label='val_loss')\n",
    "    plt.title(title); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_history(hist_fe, 'Feature Extraction History')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d3d7f",
   "metadata": {},
   "source": [
    "## 3. Fine-tuning ë‹¨ê³„ (ìƒìœ„ ë¸”ë¡ë§Œ ì¬í•™ìŠµ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ”“ ì¼ë¶€ ë ˆì´ì–´ Unfreeze (ìƒìœ„ 50ê°œ ë ˆì´ì–´ ì˜ˆì‹œ)\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "hist_ft = model.fit(x_tr, y_tr, validation_data=(x_va, y_va), epochs=5, batch_size=64, callbacks=[EarlyStopping(patience=2, restore_best_weights=True, monitor='val_accuracy')], verbose=1)\n",
    "plot_history(hist_ft, 'Fine-tuning History')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e132282",
   "metadata": {},
   "source": [
    "## 4. í…ŒìŠ¤íŠ¸ í‰ê°€ ë° í˜¼ë™í–‰ë ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91978c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_te, y_test, verbose=0)\n",
    "print(f\"[Transfer] Test Acc: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n",
    "\n",
    "y_pred = np.argmax(model.predict(x_te, verbose=0), axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=range(10))\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix (Transfer)')\n",
    "plt.colorbar(); plt.xticks(range(10), class_names, rotation=45); plt.yticks(range(10), class_names)\n",
    "plt.tight_layout(); plt.xlabel('Predicted'); plt.ylabel('True'); plt.show()\n",
    "\n",
    "print('\\n[Classification Report]\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3397af2f",
   "metadata": {},
   "source": [
    "## 5. ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d13249",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_idx = np.where(y_pred != y_test)[0]\n",
    "plt.figure(figsize=(8,8))\n",
    "for i, id_ in enumerate(mis_idx[:16], 1):\n",
    "    plt.subplot(4,4,i)\n",
    "    plt.imshow(x_te[id_].astype('uint8'))\n",
    "    plt.title(f\"T:{class_names[y_test[id_]]}\\nP:{class_names[y_pred[id_]]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a08f3",
   "metadata": {},
   "source": [
    "## 6. Grad-CAMìœ¼ë¡œ ëª¨ë¸ ì‹œê°ì  ì„¤ëª… ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ”¥ Grad-CAM êµ¬í˜„ í•¨ìˆ˜\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        class_idx = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, class_idx]\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-9)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "## ğŸ“Œ MobileNetV2ì˜ ë§ˆì§€ë§‰ Conv ë ˆì´ì–´ ì´ë¦„ ì˜ˆ: 'Conv_1'\n",
    "last_conv = 'Conv_1'\n",
    "\n",
    "## ìƒ˜í”Œ ì´ë¯¸ì§€ í•˜ë‚˜ ì„ íƒ\n",
    "idx = np.random.randint(0, len(x_te))\n",
    "img = x_te[idx].astype('uint8')\n",
    "img_input = np.expand_dims(img, axis=0)\n",
    "img_pre = preprocess_input(img_input.astype('float32'))\n",
    "\n",
    "## Heatmap ìƒì„±\n",
    "heatmap = make_gradcam_heatmap(img_pre, model, last_conv)\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "## ì›ë³¸ ìœ„ì— ì˜¤ë²„ë ˆì´\n",
    "import cv2\n",
    "heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "overlay = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.subplot(1,3,1); plt.imshow(img); plt.title('Original'); plt.axis('off')\n",
    "plt.subplot(1,3,2); plt.imshow(heatmap, cmap='jet'); plt.title('Grad-CAM Heatmap'); plt.axis('off')\n",
    "plt.subplot(1,3,3); plt.imshow(overlay[..., ::-1]); plt.title('Overlay'); plt.axis('off')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992945d",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ ì €ì¥/ë¡œë”© ë° ì‹¤ì „ íŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2503d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('transfer_mobilenetv2_finetuned.keras')\n",
    "print('ëª¨ë¸ ì €ì¥ ì™„ë£Œ: transfer_mobilenetv2_finetuned.keras')\n",
    "\n",
    "loaded = tf.keras.models.load_model('transfer_mobilenetv2_finetuned.keras')\n",
    "print('ë¡œë”© í…ŒìŠ¤íŠ¸:', loaded.evaluate(x_te, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbde7e6",
   "metadata": {},
   "source": [
    "### âœ… ì‹¤ì „ íŒ\n",
    "- ì‘ì€ ë°ì´í„°ì…‹ì—ì„œëŠ” **Feature Extraction** ë§Œìœ¼ë¡œë„ ì¶©ë¶„íˆ ë†’ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆìŒ.\n",
    "- Fine-tuningì€ **ìƒìœ„ ëª‡ ê°œ ë¸”ë¡ë§Œ** ì—´ê³  í•™ìŠµë¥ ì„ **ì•„ì£¼ ì‘ê²Œ** ì„¤ì •í•˜ì„¸ìš” (ì˜ˆ: 1e-5).\n",
    "- ì…ë ¥ í•´ìƒë„ë¥¼ ëª¨ë¸ ê¶Œì¥ê°’(224Ã—224)ë¡œ ë§ì¶”ê³ , ì „ì²˜ë¦¬ í•¨ìˆ˜(`preprocess_input`)ë¥¼ ê¼­ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "- ì„¤ëª…ê°€ëŠ¥ì„±(Grad-CAM)ì„ í†µí•´ **ëª¨ë¸ì´ ì–´ë””ë¥¼ ë³´ê³  íŒë‹¨í•˜ëŠ”ì§€** í™•ì¸í•˜ë©´ í’ˆì§ˆ ê´€ë¦¬ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
