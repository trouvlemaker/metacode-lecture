{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-6, 2강 임베딩 기반 유사도 검색 & 미니 RAG (CPU)\n",
        "\n",
        "- 목표: 문서 임베딩으로 top‑k 검색 구현, 간단 템플릿 요약으로 미니 RAG 구성\n",
        "- 데이터: 짧은 문서 코퍼스(뉴스 제목/요약), 2k 정도 샘플\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 구성 (Overview)\n",
        "- 코퍼스 로드/정제 → SBERT 임베딩 생성/캐시 → 최근접 탐색(코사인) → 미니 RAG 응답 조합 → 간단 데모\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 설정 및 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os, time, random, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "\n",
        "plt.rcParams['font.family'] = 'AppleGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "_HAS_SBERT = True\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer, util\n",
        "except Exception:\n",
        "    _HAS_SBERT = False\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# 시드 고정\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "set_seed(42)\n",
        "\n",
        "print('SBERT 사용 가능:', _HAS_SBERT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 코퍼스 준비\n",
        "- `datasets`에서 뉴스 샘플 로드(없으면 간단 더미 데이터)\n",
        "- 텍스트 길이 필터, 중복 제거\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_HAS_HF = True\n",
        "try:\n",
        "    from datasets import load_dataset\n",
        "except Exception:\n",
        "    _HAS_HF = False\n",
        "\n",
        "\n",
        "def load_news_corpus(n_per_class: int = 500) -> pd.DataFrame:\n",
        "    if not _HAS_HF:\n",
        "        # 더미 코퍼스\n",
        "        titles = [\n",
        "            'Central bank raises rates to curb inflation',\n",
        "            'Local team wins championship after dramatic final',\n",
        "            'Tech company unveils new AI-powered device',\n",
        "            'Scientists discover exoplanet with Earth-like features',\n",
        "        ] * n_per_class\n",
        "        return pd.DataFrame({'title': titles, 'text': titles})\n",
        "    ds = load_dataset('ag_news', split='train')\n",
        "    rows = []\n",
        "    for lab in range(4):\n",
        "        sub = ds.filter(lambda ex: ex['label']==lab).select(range(n_per_class))\n",
        "        for r in sub:\n",
        "            rows.append({'title': r['text'][:120], 'text': r['text']})\n",
        "    df = pd.DataFrame(rows)\n",
        "    # 간단 정제: 너무 짧은/긴 텍스트 제거, 중복 제거\n",
        "    df['len'] = df['text'].str.len()\n",
        "    df = df[(df['len']>=30) & (df['len']<=500)].drop_duplicates('text').drop(columns=['len']).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "corpus = load_news_corpus(300)\n",
        "print(corpus.shape)\n",
        "corpus.head(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 임베딩 생성 및 캐시(npz)\n",
        "- 소형 SBERT 모델 사용, CPU 배치 인코딩\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def embed_corpus(texts: list[str], model_name='sentence-transformers/all-MiniLM-L6-v2', batch_size=64):\n",
        "    if not _HAS_SBERT:\n",
        "        raise ImportError('sentence-transformers 필요')\n",
        "    model = SentenceTransformer(model_name, device='cpu')\n",
        "    outs = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        v = model.encode(texts[i:i+batch_size], batch_size=batch_size, show_progress_bar=False, convert_to_numpy=True, normalize_embeddings=True)\n",
        "        outs.append(v)\n",
        "    return np.vstack(outs)\n",
        "\n",
        "cache_path = './data/embeddings_agnews.npz'\n",
        "if os.path.exists(cache_path):\n",
        "    dat = np.load(cache_path)\n",
        "    E = dat['E']; idx_text = dat['idx_text']\n",
        "    idx_text = idx_text.tolist()\n",
        "else:\n",
        "    _t0 = time.perf_counter()\n",
        "    E = embed_corpus(corpus['text'].tolist(), batch_size=64)\n",
        "    dt = time.perf_counter()-_t0\n",
        "    print('임베딩(sec):', round(dt,2))\n",
        "    idx_text = corpus['text'].tolist()\n",
        "    np.savez_compressed(cache_path, E=E, idx_text=np.array(idx_text, dtype=object))\n",
        "\n",
        "E.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 최근접 탐색(코사인) 및 검색 함수\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sklearn NearestNeighbors로 코사인 기반 kNN 인덱스\n",
        "nn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "nn.fit(E)\n",
        "\n",
        "\n",
        "def search_topk(query: str, k: int = 5) -> list[tuple[int, float, str]]:\n",
        "    # 쿼리 임베딩\n",
        "    qv = embed_corpus([query], batch_size=1)\n",
        "    dist, idx = nn.kneighbors(qv, n_neighbors=k, return_distance=True)\n",
        "    # cosine distance → similarity = 1 - distance\n",
        "    out = []\n",
        "    for d, i in zip(dist[0], idx[0]):\n",
        "        out.append((int(i), float(1.0 - d), idx_text[i]))\n",
        "    return out\n",
        "\n",
        "# 예시 검색\n",
        "for i, (idx_i, sim, text) in enumerate(search_topk('New AI system beats benchmarks in vision tasks', k=5), 1):\n",
        "    print(i, round(sim,3), text[:120]+'...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 미니 RAG 조합 함수\n",
        "- retrieved 문서들을 템플릿으로 단순 요약/응답 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compose_response(query: str, topk: list[tuple[int, float, str]], k: int = 3) -> str:\n",
        "    parts = [f\"Q: {query}\", \"\\n[관련 문서 요약]\"]\n",
        "    for j, (idx_i, sim, text) in enumerate(topk[:k], 1):\n",
        "        parts.append(f\"- ({j}) 유사도 {sim:.2f}: {text[:160]}...\")\n",
        "    parts.append(\"\\nA: 위 문서들을 참고하면, 질문과 직접적으로 연관된 핵심은 위 목록에서 확인 가능합니다.\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "q = 'What is the impact of interest rate hikes on the stock market?'\n",
        "res = search_topk(q, k=5)\n",
        "print(compose_response(q, res, k=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 간단 데모\n",
        "- 질의 입력 → top‑k 리스트와 응답 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "queries = [\n",
        "    'Latest advances in computer vision benchmarks',\n",
        "    'Effects of monetary policy on markets',\n",
        "    'Championship highlights of the season',\n",
        "]\n",
        "for q in queries:\n",
        "    res = search_topk(q, k=5)\n",
        "    print('='*60)\n",
        "    print(compose_response(q, res, k=3))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
