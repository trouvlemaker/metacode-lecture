{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-5, 1강 STT(음성→텍스트) 기초와 데이터 핸들링 — Whisper 실습\n",
        "\n",
        "- 목표: 음성→텍스트(STT) 기본 개념과 워크플로우 이해, Whisper로 전사 및 정확도(WER, CER) 측정\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 구성 (Overview)\n",
        "1) **STT 개요 & 워크플로우**\n",
        "   - Whisper 핵심 개념, 모델 크기별 특징, 디코딩(temperature/beam) 개요\n",
        "\n",
        "2) **환경 준비**\n",
        "   - `ffmpeg` 확인, 라이브러리 설치/임포트, 한글 폰트 & 경고 억제 설정, `DEVICE`(CPU/GPU) 출력\n",
        "\n",
        "3) **데이터 준비**\n",
        "   - 오디오 로딩 유틸: 16kHz 리샘플 · 모노 변환 · 구간 추출(`load_audio_mono_16k`)\n",
        "\n",
        "4) **Whisper 전사 데모**\n",
        "   - 모델 선택(`tiny`, `base`, `small`), 언어 지정(`language='ko'` 등)  \n",
        "   - 짧은 파일 전사 기본 흐름(`transcribe_with_whisper`)\n",
        "\n",
        "5) **정확도 지표 (참고)**\n",
        "   - **WER/CER 동시 계산**: 정규화 원칙(단어/문자 단위) 문서화  \n",
        "   - `compute_error_rates()`로 `(CER, WER)` 반환\n",
        "\n",
        "6) **모델 크기 · 속도 · 품질 벤치마크**\n",
        "   - 동일 10–15초 샘플로 `tiny/base/small` 비교  \n",
        "   - 실행 시간, 텍스트 요약, (선택) CER/WER → `run_whisper_once`, `benchmark_whisper_models`\n",
        "\n",
        "7) **디코딩 파라미터 실험**\n",
        "   - `transcribe_with_params`: `temperature`, `beam_size`, `best_of` 조합 A/B 테스트\n",
        "\n",
        "8) **긴 오디오 전사 (슬라이딩 윈도우)**\n",
        "   - `transcribe_sliding(win_sec, hop_sec)`로 긴 MP3/WAV 처리  \n",
        "   - 결과: 전체 텍스트, 세그먼트, 윈도우 요약\n",
        "\n",
        "9) **시각화 & 에러 분석**\n",
        "   - 파형 + 세그먼트 오버레이: `plot_wave_and_segments`  \n",
        "   - 레퍼런스 vs 예측 **diff(삽입/삭제/치환)**: `diff_tokens`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 데이터 소스 (Short & Long)\n",
        "\n",
        "**1) 단문(Short) — KSS Dataset**  \n",
        "- 출처: *Korean Single Speaker Speech (KSS)*  \n",
        "- 문장 레퍼런스: `transcript.v.1.4.txt` (각 발화에 대한 텍스트가 정렬되어 있음)  \n",
        "- 사용법: 짧은 문장 전사 실습 및 WER/CER 평가용 레퍼런스 텍스트로 활용\n",
        "\n",
        "> 참고 링크  \n",
        "> - Kaggle: Korean Single Speaker Speech Dataset (KSS)  \n",
        ">   https://www.kaggle.com/datasets/bryanpark/korean-single-speaker-speech-dataset  \n",
        ">   (데이터 탭에서 `transcript.v.1.4.txt` 확인)\n",
        "\n",
        "---\n",
        "\n",
        "**2) 장문(Long) — 비타민 한국어 오디오 (Darakwon)**  \n",
        "- 출처: 다락원(Darakwon) 교재 부록 **무료 MP3 오디오**  \n",
        "- 사용법: 1–2분 길이의 대화 트랙을 **슬라이딩 윈도우 전사** 데모에 활용\n",
        "\n",
        "> 참고 링크  \n",
        "> - 비타민 한국어 4 MP3 다운로드(다락원)  \n",
        ">   https://www.darakwon.co.kr/mp3/FileDown_kor2.asp?p_id=6772&pf_type=5  \n",
        "\n",
        "---\n",
        "\n",
        "#### 운영 팁\n",
        "- **라이선스/이용 범위**: 교육·연구 목적 사용 시에도 각 페이지의 이용 조건을 확인하세요.  \n",
        "- **전처리**: Whisper 입력 표준(모노/16kHz)에 맞게 변환 → `load_audio_mono_16k()` 또는 `ffmpeg`로 리샘플링  \n",
        "- **예제 경로 변수**  \n",
        "  - 단문 예제(WAV): `EXAMPLE_WAV = \"./data/speech/1_0001.wav\"`  \n",
        "  - 장문 예제(MP3): `EXAMPLE_MP3 = \"./data/speech/Vitamin4_002_1-1.mp3\"` (실제 다운로드 파일명/경로에 맞게 수정)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg: /opt/homebrew/bin/ffmpeg\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "def check_ffmpeg():\n",
        "    \"\"\"\n",
        "    ffmpeg 설치 여부를 확인하는 함수.\n",
        "    - Whisper는 오디오 처리에 ffmpeg를 필요로 하는 경우가 많음.\n",
        "    - 미디어 변환/처리 도구로 사용하며 거의 모든 오디오·비디오 포맷을 디코딩/인코딩하고, 자르기/병합/리샘플/채널변환/볼륨조정 등을 수행.\n",
        "    - 본 과정에서의 역할\n",
        "        . mp3/wav 등 다양한 포맷을 Whisper가 읽을 수 있게 디코딩.\n",
        "        . STT 학습/추론에 맞게 16kHz·모노로 리샘플/다운믹스해 tmp_16k.wav 생성.\n",
        "        . 긴 파일 일부 구간만 추출(시간 오프셋/길이) 등 전처리.\n",
        "    - 설치 여부 확인 후 경로를 출력, 없으면 설치 방법 안내.\n",
        "    \"\"\"\n",
        "    path = shutil.which('ffmpeg')\n",
        "    print('ffmpeg:', path or '미설치 — macOS: brew install ffmpeg / Windows: choco install ffmpeg 또는 scoop install ffmpeg')\n",
        "\n",
        "\n",
        "# ffmpeg 확인 실행\n",
        "check_ffmpeg()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 준비 및 라이브러리 임포트\n",
        "\n",
        "- 시각화는 `matplotlib`만 사용합니다.\n",
        "- STT는 `openai-whisper`, 오디오 I/O/변환은 `torchaudio`, 평가는 `jiwer`를 사용합니다.\n",
        "- 한글 폰트와 경고 억제를 설정합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# UTF-8 인코딩 설정 (한글 등 다국어 문자 처리를 위해 사용)\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU; using FP32 instead\")\n",
        "\n",
        "\n",
        "# Whisper(OpenAI 음성 인식 라이브러리) 사용 가능 여부 확인\n",
        "try:\n",
        "    import whisper\n",
        "    _HAS_WHISPER = True\n",
        "except Exception:\n",
        "    _HAS_WHISPER = False\n",
        "\n",
        "# jiwer(WER: Word Error Rate 계산용 라이브러리) 사용 가능 여부 확인\n",
        "try:\n",
        "    import jiwer\n",
        "    _HAS_JIWER = True\n",
        "except Exception:\n",
        "    _HAS_JIWER = False\n",
        "\n",
        "# 경고 메시지 무시 설정\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # 미래 버전 관련 경고 무시\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # 폐지 예정 기능 경고 무시\n",
        "warnings.filterwarnings(\"ignore\", message=r\"Glyph.*missing from font.*\", category=UserWarning)  # 폰트 관련 경고 무시\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*load_with_torchcodec.*\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\".*save_with_torchcodec.*\", category=UserWarning)\n",
        "\n",
        "# Matplotlib 그래프 한글 폰트 설정 및 마이너스 기호 깨짐 방지\n",
        "plt.rcParams['font.family'] = 'AppleGothic'   # macOS용 한글 폰트\n",
        "plt.rcParams['axes.unicode_minus'] = False    # 음수(-) 기호가 깨지지 않도록 설정\n",
        "\n",
        "# PyTorch에서 사용할 디바이스 설정 (GPU 사용 가능하면 cuda, 아니면 cpu)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', DEVICE)\n",
        "\n",
        "# 출력 폴더 보장\n",
        "os.makedirs(\"./data/speech\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Whisper 모델 개요\n",
        "**Whisper는 OpenAI 연구팀이 22년 9월 21일에 공개한 전세계 다양한 언어를 안정적으로 인식하고 번역까지 가능한 범용 음성 인식 모델**  \n",
        "\n",
        "\n",
        "#### 주요 특징\n",
        "- **다국어 지원**: 97개 이상의 언어 음성을 텍스트로 변환 가능  \n",
        "- **번역 기능**: 한국어 음성을 영어 텍스트로 번역 같은 cross-lingual 기능 지원  \n",
        "- **대규모 학습 데이터**: 68만 시간 이상의 웹 음성 데이터로 학습 → 노이즈/억양에도 강함  \n",
        "- **세그먼트 타임스탬프**: 전사 결과에 시작/끝 시간이 포함되어 자막 생성 가능  \n",
        "\n",
        "---\n",
        "\n",
        "#### 모델 크기별 버전\n",
        "Whisper는 여러 크기의 모델이 제공됩니다. (속도 ↔ 정확도 트레이드오프)\n",
        "\n",
        "| 모델 | 파라미터 수 | 상대 속도 | 특징 |\n",
        "|---|---|---|---|\n",
        "| **tiny**   | 39M   | 가장 빠름 | 리소스 적음, 정확도 낮음 |\n",
        "| **base**   | 74M   | 빠름 | CPU 실습 적합 |\n",
        "| **small**  | 244M  | 중간 | 정확도 향상 |\n",
        "| **medium** | 769M  | 느림 | 더 높은 정확도 |\n",
        "| **large**  | 1550M | 가장 느림 | 최고 정확도, GPU 권장 |\n",
        "\n",
        "**CPU 실습**: tiny / base 권장  \n",
        "**GPU 사용**: small 이상 가능  \n",
        "\n",
        "---\n",
        "\n",
        "#### 장단점\n",
        "**장점**\n",
        "- 범용 다국어 모델 (하나로 여러 언어 처리 가능)  \n",
        "- 잡음, 억양, 사투리에 강인함  \n",
        "- 오픈소스로 무료 사용 가능  \n",
        "\n",
        "**단점**\n",
        "- 큰 모델은 CPU에서 매우 느림  \n",
        "- large 모델은 메모리 사용량이 큼  \n",
        "- 실시간보다는 “파일 단위 배치 처리”에 더 적합  \n",
        "\n",
        "---\n",
        "\n",
        "#### 활용 예시\n",
        "- 회의/강의 자동 자막 생성  \n",
        "- 유튜브/팟캐스트 스크립트 추출  \n",
        "- 다국어 영상의 영어 번역 자막 생성  \n",
        "- 고객센터 통화 분석  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whisper 모델 로드 성공: tiny\n"
          ]
        }
      ],
      "source": [
        "# CPU 최적화: 단일 모델 로드 + 그리디 디코딩\n",
        "DEFAULT_MODEL_CPU = 'tiny'     # CPU 환경에서 사용할 Whisper 모델 (가장 작은 모델, 속도 우선)\n",
        "_DEFAULT_MODEL_GPU = 'base'    # GPU 환경에서 사용할 Whisper 모델 (조금 더 큰 모델, 성능 우선)\n",
        "_MODEL_SINGLETON = None        # Whisper 모델을 단 한 번만 로드해 재사용하기 위한 전역 변수\n",
        "\n",
        "# Whisper 모델 로드 (환경에 따라 tiny 또는 base 모델 선택)\n",
        "if _HAS_WHISPER:\n",
        "    try:\n",
        "        # CPU면 tiny, GPU면 base 모델 로드\n",
        "        model_name = DEFAULT_MODEL_CPU if DEVICE == 'cpu' else _DEFAULT_MODEL_GPU\n",
        "        _MODEL_SINGLETON = whisper.load_model(model_name, device=DEVICE)\n",
        "        print('Whisper 모델 로드 성공:', model_name)\n",
        "    except Exception as e:\n",
        "        # 모델 로드 실패 시 None으로 설정\n",
        "        _MODEL_SINGLETON = None\n",
        "        print('Whisper 모델 로드 실패:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 빠른 음성 -> 텍스트 변환 함수 정의\n",
        "def fast_transcribe(path: str, language: str = 'ko'):\n",
        "    \"\"\"\n",
        "    Whisper를 이용해 음성 파일을 빠르게 텍스트로 변환하는 함수.\n",
        "    - 단일 모델 싱글톤을 활용해 불필요한 로드 방지\n",
        "    - Greedy decoding 방식(beam_size=1)으로 속도 최적화\n",
        "    - temperature=0.0 → 결과의 일관성 강화\n",
        "    - fp16=False → CPU 환경에서도 문제없이 동작 가능\n",
        "    \"\"\"\n",
        "    if not _HAS_WHISPER or _MODEL_SINGLETON is None:\n",
        "        raise ImportError('whisper 모델을 사용할 수 없습니다. 설치 또는 로드 오류를 확인하세요.')\n",
        "    \n",
        "    return _MODEL_SINGLETON.transcribe(\n",
        "        path,                 # 입력 오디오 파일 경로\n",
        "        language=language,    # 언어 (기본값: 한국어 'ko')\n",
        "        temperature=0.0,      # 탐색 무작위성 제거 (결과 일관성 ↑)\n",
        "        beam_size=1,          # beam search 대신 greedy decoding 사용 (속도 ↑)\n",
        "        # 1.Greedy decoding (beam_size = 1)\n",
        "        #매 스텝마다 가장 확률이 높은 토큰 하나만 선택\n",
        "        #속도 빠름, 메모리 적게 사용\n",
        "        #하지만 최적(global optimum)이 아닌 **국소적 최적(local optimum)**에 갇힐 수 있음 → 문장 품질 떨어질 수 있음\n",
        "\n",
        "        # 2. Beam search (beam_size > 1)\n",
        "        # 매 스텝마다 여러 후보 토큰을 유지하면서 탐색\n",
        "        # beam_size = 유지할 후보 개수\n",
        "        # 더 많은 후보를 고려하므로 정확도 향상 가능\n",
        "        # 하지만 속도 느려짐 + 메모리 사용 증가\n",
        "\n",
        "        # 예시\n",
        "        # 문장을 “오늘 날씨가 좋다”라고 할 때\n",
        "        # beam_size=1 (greedy)\n",
        "        # → 오늘 날씨 좋다 (중간에 “가”를 빼먹음)\n",
        "        # beam_size=5\n",
        "        # → 후보 여러 개를 탐색하다가\n",
        "        # → 오늘 날씨가 좋다 (더 자연스러운 문장 선택)\n",
        "\n",
        "        best_of=None,         # 후보 중 최적 선택 기능 비활성화 (속도 ↑)\n",
        "        fp16=False            # half-precision 비활성화 (CPU 호환성 ↑)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 데이터 준비 및 전처리\n",
        "- 예제 오디오 파일 경로 지정, 로드, 16kHz 리샘플, 모노 변환\n",
        "- 긴 파일은 일부 구간만 사용(강의 시간 고려, 10–15초 권장)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_audio_mono_16k(path: str, offset_sec: float = 0.0, duration_sec: float | None = None):\n",
        "    \"\"\"\n",
        "    오디오 파일을 로드하여 16kHz 모노 신호로 변환합니다.\n",
        "    - offset_sec: 시작 지점(초) → 이 시점부터 오디오를 잘라 사용\n",
        "    - duration_sec: 길이(초) → 지정 시 offset부터 duration 길이만큼 잘라서 반환\n",
        "    \"\"\"\n",
        "\n",
        "    # 파일 존재 여부 확인\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError('오디오 파일을 찾을 수 없습니다: ' + path)\n",
        "\n",
        "    # 오디오 로드 (torchaudio는 (채널, 시간) 형태 반환)\n",
        "    wav, sr = torchaudio.load(path)\n",
        "\n",
        "    # 모노 변환: 채널이 여러 개(스테레오 등)라면 평균 내어 하나의 채널로 변환\n",
        "    if wav.size(0) > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)\n",
        "\n",
        "    # 샘플링 레이트 변환 (16kHz로 통일)\n",
        "    if sr != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
        "        wav = resampler(wav)\n",
        "        sr = 16000\n",
        "\n",
        "    # offset과 duration 적용 (특정 구간만 잘라내기)\n",
        "    if offset_sec > 0 or duration_sec is not None:\n",
        "        start = int(offset_sec * sr)  # 시작 위치 (샘플 단위)\n",
        "        end = start + int(duration_sec * sr) if duration_sec is not None else wav.size(1)\n",
        "        wav = wav[:, start:end]\n",
        "\n",
        "    # (time,) 형태로 변환해서 반환 (채널 제거) + 샘플링 레이트(16k)\n",
        "    return wav.squeeze(0), sr\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 예시 경로 (수강생은 직접 자신의 음성 파일로 교체 가능)\n",
        "EXAMPLE_WAV = './data/speech/1_0001.wav'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Whisper 전사 데모\n",
        "- Whisper 모델(`tiny`, `base`, `small`) 중 선택 가능  \n",
        "- 언어 지정(`ko`, `en`, …), CPU/GPU 자동 감지 후 동작  \n",
        "- 긴 오디오 파일은 전체 한 번에 처리하기 어렵기 때문에 **부분 전사** 또는 **슬라이딩 윈도우** 전략 사용 권장  \n",
        "- 여기서는 짧은 15초 구간을 잘라서 전사 시연  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전사 결과:  그녀의 사랑을 얻기 위해 애썼지만, 헛수고였다. ...\n"
          ]
        }
      ],
      "source": [
        "def transcribe_with_whisper(path: str, model_name: str = 'base', language: str | None = None):\n",
        "    \"\"\"\n",
        "    Whisper 모델을 이용해 음성을 텍스트로 전사하는 함수\n",
        "    - path: 오디오 파일 경로 (.wav)\n",
        "    - model_name: 사용할 Whisper 모델 이름 (tiny, base, small, medium, large 등)\n",
        "    - language: 언어 코드 ('ko', 'en' 등). None이면 자동 감지\n",
        "    \"\"\"\n",
        "    if not _HAS_WHISPER:\n",
        "        raise ImportError(\n",
        "            'whisper 패키지가 설치되어 있지 않습니다. 설치: pip install -U openai-whisper'\n",
        "        )\n",
        "\n",
        "    # Whisper는 내부적으로 ffmpeg를 사용 → ffmpeg 설치 필요\n",
        "    model = whisper.load_model(model_name, device=DEVICE)\n",
        "\n",
        "    # Whisper 내장 transcribe() 사용 (자동 리샘플링/패딩 포함)\n",
        "    result = model.transcribe(path, language=language)\n",
        "    return result\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 데모 실행 (예시)\n",
        "try:\n",
        "    # 예제 wav 파일에서 앞 15초만 불러오기\n",
        "    wav, sr = load_audio_mono_16k(EXAMPLE_WAV, duration_sec=15)\n",
        "\n",
        "    # Whisper는 파일 경로 입력을 받기 때문에, 임시 wav 파일로 저장\n",
        "    tmp_path = './data/speech/tmp_16k.wav'\n",
        "    torchaudio.save(tmp_path, wav.unsqueeze(0), 16000)\n",
        "\n",
        "    # 전사 실행 (base 모델, 한국어 지정)\n",
        "    out = transcribe_with_whisper(tmp_path, model_name='small', language='ko')\n",
        "\n",
        "    # 전사 결과 출력 (앞부분 120자만 확인)\n",
        "    print('전사 결과:', out['text'][:120], '...')\n",
        "\n",
        "except Exception as e:\n",
        "    print('데모 실행 중 문제:', e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 정확도 평가 (WER/CER) — 참고용\n",
        "- **전제:** 레퍼런스 텍스트가 있을 때만 사용하세요.\n",
        "- **정규화 원칙**\n",
        "  - **WER(단어 단위)**: 공백은 **토큰 경계**이므로 유지합니다. ⇒ 소문자화, 다중 공백 정리, 앞뒤 공백 제거(필요 시 문장부호 제거).\n",
        "  - **CER(문자 단위)**: 한국어는 띄어쓰기 변동의 영향이 커서 **공백을 제거**하고 비교하는 편이 일반적입니다(필요 시 문장부호 제거).\n",
        "- **권장사항:** 실험/서비스마다 “무엇을 품질로 볼 것인가”를 문서화하고, 동일한 정규화 절차를 **일관되게 적용**하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_error_rates(hypothesis: str, reference: str):\n",
        "    \"\"\"\n",
        "    정규화 후 CER, WER를 함께 계산해 (cer, wer)로 반환합니다.\n",
        "\n",
        "    - WER: 단어 단위 평가 → 공백은 토큰 경계이므로 '유지'\n",
        "      · 적용: 소문자화, 다중 공백 정리, 앞뒤 공백 제거\n",
        "      · 선택: 문장부호 제거(RemovePunctuation) — 과도한 정규화에 주의\n",
        "\n",
        "    - CER: 문자 단위 평가 → 공백 자체가 오류율에 왜곡을 줄 수 있어 '제거'\n",
        "      · 적용: 다중 공백 정리, 앞뒤 공백 제거, 이후 공백 삭제(replace)\n",
        "      · 선택: 문장부호 제거(RemovePunctuation)\n",
        "\n",
        "    주의: 정규화 스펙은 실험 목적에 따라 달라질 수 있습니다.\n",
        "         반드시 문서화하여 팀 내/실험 간 일관성을 유지하세요.\n",
        "    \"\"\"\n",
        "    if not _HAS_JIWER:\n",
        "        raise ImportError('jiwer 필요')\n",
        "\n",
        "    # -----------------------------\n",
        "    # 1) WER용 정규화: 공백 '유지'\n",
        "    # -----------------------------\n",
        "    norm_w = jiwer.Compose([\n",
        "        jiwer.ToLowerCase(),         # 대소문자 통일\n",
        "        jiwer.RemoveMultipleSpaces(),# 다중 공백을 단일 공백으로\n",
        "        jiwer.Strip(),               # 앞/뒤 공백 제거\n",
        "        # jiwer.RemovePunctuation(), # 필요 시 활성화 (과정 문서화 필수)\n",
        "    ])\n",
        "    ref_w = norm_w(reference)\n",
        "    hyp_w = norm_w(hypothesis)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 2) CER용 정규화: 공백 '제거'\n",
        "    # -----------------------------\n",
        "    norm_c = jiwer.Compose([\n",
        "        jiwer.RemoveMultipleSpaces(),# 다중 공백 정리\n",
        "        jiwer.Strip(),               # 앞/뒤 공백 제거\n",
        "        # jiwer.RemovePunctuation(), # 필요 시 활성화 (과정 문서화 필수)\n",
        "    ])\n",
        "    # 문자 단위 비교를 위해 공백 자체 제거\n",
        "    ref_c = norm_c(reference).replace(\" \", \"\")\n",
        "    hyp_c = norm_c(hypothesis).replace(\" \", \"\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # 3) 지표 계산\n",
        "    # -----------------------------\n",
        "    wer = jiwer.wer(ref_w, hyp_w)\n",
        "    cer = jiwer.cer(ref_c, hyp_c)\n",
        "    return cer, wer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 모델 크기·속도·품질 벤치마크\n",
        "- 같은 10–15초 길이의 오디오 파일을 대상으로 `tiny` / `base` / `small` 모델을 비교합니다.  \n",
        "- 비교 항목:\n",
        "  - 전사 시간(sec)\n",
        "  - 전사 결과 텍스트의 앞부분\n",
        "  - (선택) 레퍼런스 텍스트가 있을 경우 **CER / WER** 계산 포함  \n",
        "- `run_whisper_once`: 단일 모델 전사 + 성능 측정  \n",
        "- `benchmark_whisper_models`: 여러 모델 반복 벤치마크 + 요약 출력 / DataFrame 반환  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_whisper_once(\n",
        "    path: str,\n",
        "    model_name: str,\n",
        "    language: str = 'ko',\n",
        "    reference: Optional[str] = None,\n",
        "    use_singleton: bool = True,\n",
        "    decode_opts: Optional[dict] = None,\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    단일 Whisper 모델로 전사를 1회 실행하고 성능 지표를 반환.\n",
        "\n",
        "    Returns:\n",
        "        {\n",
        "          'model': str,\n",
        "          'sec': float,\n",
        "          'text': str,\n",
        "          'CER': Optional[float],\n",
        "          'WER': Optional[float]\n",
        "        }\n",
        "    \"\"\"\n",
        "    if not _HAS_WHISPER:\n",
        "        raise ImportError('openai-whisper 필요')\n",
        "\n",
        "    # 디코딩 기본 옵션 (greedy, 속도 중심)\n",
        "    _default_decode = dict(language=language, temperature=0.0, beam_size=1, best_of=None, fp16=False)\n",
        "    if decode_opts:\n",
        "        _default_decode.update(decode_opts)\n",
        "\n",
        "    # 싱글턴 사용 여부\n",
        "    if use_singleton and _MODEL_SINGLETON is not None:\n",
        "        default_name = DEFAULT_MODEL_CPU if DEVICE == 'cpu' else _DEFAULT_MODEL_GPU\n",
        "        model = _MODEL_SINGLETON if model_name == default_name else whisper.load_model(model_name, device=DEVICE)\n",
        "    else:\n",
        "        model = whisper.load_model(model_name, device=DEVICE)\n",
        "\n",
        "    # 전사 + 시간 측정\n",
        "    t0 = time.perf_counter()\n",
        "    out = model.transcribe(path, **_default_decode)\n",
        "    dt = time.perf_counter() - t0\n",
        "\n",
        "    text = (out.get('text') or '').strip()\n",
        "    row = {'model': model_name, 'sec': round(dt, 2), 'text': text}\n",
        "\n",
        "    # 선택적으로 CER/WER 계산\n",
        "    if reference and _HAS_JIWER:\n",
        "        try:\n",
        "            cer, wer = compute_error_rates(text, reference)\n",
        "            row['CER'] = round(cer, 3)\n",
        "            row['WER'] = round(wer, 3)\n",
        "        except Exception:\n",
        "            row['CER'] = None\n",
        "            row['WER'] = None\n",
        "    else:\n",
        "        row['CER'] = None\n",
        "        row['WER'] = None\n",
        "\n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def benchmark_whisper_models(\n",
        "    path: str,\n",
        "    models: Tuple[str, ...] = ('tiny', 'base', 'small'),\n",
        "    language: str = 'ko',\n",
        "    reference: Optional[str] = None,\n",
        "    use_singleton: bool = True,\n",
        "    decode_opts: Optional[dict] = None,\n",
        "    return_df: bool = False,\n",
        "    verbose: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    여러 Whisper 모델을 반복 실행하여 벤치마크.\n",
        "    - return_df=True면 pandas.DataFrame을 반환(없으면 list[dict]).\n",
        "    - verbose=True면 요약 표 형태로 콘솔 출력.\n",
        "    \"\"\"\n",
        "    results: List[Dict] = []\n",
        "    for m in models:\n",
        "        row = run_whisper_once(\n",
        "            path=path,\n",
        "            model_name=m,\n",
        "            language=language,\n",
        "            reference=reference,\n",
        "            use_singleton=use_singleton,\n",
        "            decode_opts=decode_opts,\n",
        "        )\n",
        "        results.append(row)\n",
        "\n",
        "    if verbose:\n",
        "        print('model |  sec |  CER |  WER | text(앞부분)')\n",
        "        for r in results:\n",
        "            cer_str = '-' if r.get('CER') is None else f\"{r['CER']:.3f}\"\n",
        "            wer_str = '-' if r.get('WER') is None else f\"{r['WER']:.3f}\"\n",
        "            preview = (r['text'][:50] + '...') if r['text'] else ''\n",
        "            print(f\"{r['model']:>5} | {r['sec']:>4} | {cer_str:>5} | {wer_str:>5} | {preview}\")\n",
        "\n",
        "    if return_df:\n",
        "        try:\n",
        "            import pandas as pd\n",
        "            return pd.DataFrame(results)\n",
        "        except Exception:\n",
        "            # pandas가 없으면 리스트 반환\n",
        "            return results\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:17<00:00, 8.51MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model |  sec |  CER |  WER | text(앞부분)\n",
            " tiny | 0.28 | 0.150 | 0.333 | 그녀의 사랑을 얻기 위해 에서지만 허수고였다....\n",
            " base | 0.36 | 0.100 | 0.333 | 그녀의 사랑을 얻기 위해 애써지만 호수고였다....\n",
            "small | 0.89 | 0.050 | 0.167 | 그녀의 사랑을 얻기 위해 애썼지만, 헛수고였다....\n",
            "   model   sec                        text   CER    WER\n",
            "0   tiny  0.28   그녀의 사랑을 얻기 위해 에서지만 허수고였다.  0.15  0.333\n",
            "1   base  0.36   그녀의 사랑을 얻기 위해 애써지만 호수고였다.  0.10  0.333\n",
            "2  small  0.89  그녀의 사랑을 얻기 위해 애썼지만, 헛수고였다.  0.05  0.167\n"
          ]
        }
      ],
      "source": [
        "# 여러 모델 벤치마크\n",
        "results = benchmark_whisper_models(\n",
        "    path='./data/speech/tmp_16k.wav',\n",
        "    models=(\"tiny\", \"base\", \"small\"),\n",
        "    language=\"ko\",\n",
        "    reference=\"그녀의 사랑을 얻기 위해 애썼지만 헛수고였다.\",\n",
        "    use_singleton=True,   # 기본 모델 싱글턴 재사용\n",
        "    verbose=True,         # 콘솔 요약 표 출력\n",
        "    return_df=True        # DataFrame 반환\n",
        ")\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. 파라미터 조합 실험 (temperature, beam_size, best_of)\n",
        "- Whisper 전사 품질과 속도는 **디코딩 파라미터**에 따라 달라집니다.\n",
        "- 주요 파라미터:\n",
        "  - **temperature**:  \n",
        "    - `0.0`: 결정적이고 일관된 결과 (속도↑, 다양성↓)  \n",
        "    - 값이 커질수록 더 다양한 결과 가능 (정확도 향상 가능성↑, 재현성↓)  \n",
        "  - **beam_size**:  \n",
        "    - `1`: greedy decoding (속도↑, 정확도 보통)  \n",
        "    - `>1`: beam search, 더 많은 후보 탐색 (정확도↑ 가능, 속도↓)  \n",
        "  - **best_of**:  \n",
        "    - 여러 샘플 중 최적 결과 선택 (beam_size=1일 때만 의미 있음)  \n",
        "\n",
        " **실험**:  \n",
        "- temperature ∈ {0.0, 0.2}, beam_size ∈ {1, 5} 조합으로 짧은 오디오 클립을 비교해보세요.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_with_params(\n",
        "    path: str,\n",
        "    model_name: str = 'base',\n",
        "    language: str = 'ko',\n",
        "    temperature: float = 0.0,\n",
        "    beam_size: int = 1,\n",
        "    best_of: int | None = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Whisper 모델을 사용하여 다양한 파라미터 조합으로 음성을 전사합니다.\n",
        "    \n",
        "    Args:\n",
        "        path (str): 입력 오디오 파일 경로\n",
        "        model_name (str): 사용할 모델 이름 (tiny, base, small, medium, large)\n",
        "        language (str): 음성 언어 (기본값: 'ko' → 한국어)\n",
        "        temperature (float): 생성 다양성 조절 (0.0=일관성↑, 값↑=다양성↑)\n",
        "        beam_size (int): 탐색 폭 (1=greedy, 값↑=정확도↑ 가능, 속도↓)\n",
        "        best_of (int | None): 후보 중 최적 선택 (beam_size=1일 때 의미 있음)\n",
        "\n",
        "    Returns:\n",
        "        dict: Whisper 전사 결과 (텍스트, 타임스탬프 등 포함)\n",
        "\n",
        "    주의:\n",
        "        - 모델을 호출할 때마다 새로 로드하므로 반복 호출은 느릴 수 있습니다.\n",
        "        - 빠른 데모: fast_transcribe() (싱글턴 재사용)\n",
        "        - 파라미터 비교/실험: transcribe_with_params()\n",
        "    \"\"\"\n",
        "    if not _HAS_WHISPER:\n",
        "        raise ImportError('openai-whisper 필요')\n",
        "\n",
        "    # 모델 로드 (매 호출마다 새로 로드)\n",
        "    model = whisper.load_model(model_name, device=DEVICE)\n",
        "\n",
        "    # 전사 실행\n",
        "    return model.transcribe(\n",
        "        path,\n",
        "        language=language,\n",
        "        temperature=temperature,\n",
        "        beam_size=beam_size,\n",
        "        best_of=best_of,\n",
        "        fp16=False  # CPU 호환성 확보\n",
        "    )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "temp=0.0, beam=1 ->  그녀의 사랑을 얻기 위해 에서지만 허수고였다. CER=3.333, WER=3.000\n",
            "temp=0.0, beam=5 ->  그녀의 사랑을 얻기 위해 에서지만 허쉬고 였다. CER=3.333, WER=3.500\n",
            "temp=0.2, beam=1 ->  그녀의 사랑을 얻기 위해 에서지만 허수고였다. CER=3.333, WER=3.000\n",
            "temp=0.2, beam=5 ->  그녀의 사랑을 얻기 위해 에서지만 허수고였다. CER=3.333, WER=3.000\n"
          ]
        }
      ],
      "source": [
        "for temp in (0.0, 0.2):         # 0.0 → 결정적 / 0.2 → 약간의 무작위성 추가\n",
        "    for beam in (1, 5):         # 1 → greedy decoding / 5 → beam search\n",
        "        out = transcribe_with_params(\n",
        "            './data/speech/tmp_16k.wav',\n",
        "            model_name='tiny',\n",
        "            language='ko',\n",
        "            temperature=temp,\n",
        "            beam_size=beam,\n",
        "            best_of=None\n",
        "        )\n",
        "        cer, wer = compute_error_rates(out['text'], '레퍼런스 문장')\n",
        "        print(f\"temp={temp}, beam={beam} ->\", out['text'][:80], f\"CER={cer:.3f}, WER={wer:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. 긴 오디오 전사 (슬라이딩 윈도우)\n",
        "- Whisper 모델은 입력 길이에 한계가 있으므로, **긴 파일(>30초)**은 직접 잘라서 처리해야 합니다.  \n",
        "- 전략: 오디오를 일정 길이(`win_sec`)로 잘라 **슬라이딩 윈도우** 방식으로 겹치게(`hop_sec`) 전사합니다.  \n",
        "- 반환:\n",
        "  - 전체 전사 텍스트\n",
        "  - 세그먼트별(start, end, text)\n",
        "  - 윈도우별(start, end, text) 요약\n",
        "- 활용:\n",
        "  - 긴 MP3 파일을 읽어 30초 단위(`win_sec=30`)로 잘라 15초씩(`hop_sec=15`) 겹쳐가며 전사  \n",
        "  - 자연스러운 긴 파일 처리 / 자막 생성 등에 응용 가능\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXAMPLE_MP3 = './data/speech/Vitamin4_002_1-1.mp3'\n",
        "\n",
        "def transcribe_sliding(\n",
        "    model_name='base',\n",
        "    language='ko',\n",
        "    win_sec=30,\n",
        "    hop_sec=15\n",
        "):\n",
        "    \"\"\"\n",
        "    긴 오디오 파일을 슬라이딩 윈도우 방식으로 전사하는 함수.\n",
        "    - win_sec: 한 번에 처리할 오디오 길이(초)\n",
        "    - hop_sec: 윈도우 간 이동 간격(초). win_sec보다 작으면 구간이 겹침.\n",
        "    - 반환: 전체 텍스트, 세그먼트 리스트, 윈도우별 요약\n",
        "    \"\"\"\n",
        "\n",
        "    if not _HAS_WHISPER:\n",
        "        raise ImportError('openai-whisper 필요')\n",
        "\n",
        "    # 오디오 로드 → 모노(1채널), 16kHz 리샘플링\n",
        "    wav, sr = load_audio_mono_16k(EXAMPLE_MP3)\n",
        "    n = wav.numel()  # 전체 샘플 수\n",
        "\n",
        "    # 윈도우/홉 크기를 샘플 단위로 변환\n",
        "    win = int(win_sec * sr)\n",
        "    hop = int(hop_sec * sr)\n",
        "\n",
        "    # Whisper 모델 로드\n",
        "    model = whisper.load_model(model_name, device=DEVICE)\n",
        "\n",
        "    texts, segs, windows = [], [], []  # 전체 결과 저장용\n",
        "    idx = 0\n",
        "\n",
        "    # 슬라이딩 윈도우 루프\n",
        "    for start in range(0, max(1, n - win + 1), hop):\n",
        "        end = min(start + win, n)         # 오디오 끝을 넘지 않도록 제한\n",
        "        chunk = wav[start:end].unsqueeze(0)  # (1, 샘플수) 형태\n",
        "\n",
        "        # Whisper는 파일 입력을 받으므로 임시 wav 저장\n",
        "        tmp = './data/speech/tmp_chunk.wav'\n",
        "        torchaudio.save(tmp, chunk, 16000)\n",
        "\n",
        "        # 전사 실행 (greedy decoding, CPU 호환 fp16=False)\n",
        "        out = model.transcribe(\n",
        "            tmp,\n",
        "            language=language,\n",
        "            temperature=0.0,\n",
        "            beam_size=1,\n",
        "            best_of=None,\n",
        "            fp16=False\n",
        "        )\n",
        "\n",
        "        # 전사 텍스트 저장\n",
        "        text_i = out.get('text', '')\n",
        "        texts.append(text_i)\n",
        "        windows.append({'idx': idx, 'start': start / sr, 'end': end / sr, 'text': text_i})\n",
        "        idx += 1\n",
        "\n",
        "        # segment별 start/end 보정 후 저장\n",
        "        for s in out.get('segments', []):\n",
        "            segs.append({\n",
        "                'start': s['start'] + start / sr,\n",
        "                'end':   s['end']   + start / sr,\n",
        "                'text':  s['text']\n",
        "            })\n",
        "\n",
        "    # 최종 반환: 전체 텍스트, 세그먼트, 윈도우별 요약\n",
        "    return {\n",
        "        'text': ' '.join(texts),\n",
        "        'segments': segs,\n",
        "        'windows': windows\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_windows(res: dict, max_chars: int = 80):\n",
        "    for w in res.get('windows', []):\n",
        "        print(f\"[{w['idx']:02d}] {w['start']:.1f}–{w['end']:.1f}s | {w['text'][:max_chars]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00] 0.0–20.0s |  듣기 다음을 잘 듣고 물음에 답하십시오. 이래서 이 너도 여기서 운동해? 응. 기숙사에서도 가까운데다가 비싸지도 않잖아....\n",
            "[01] 5.0–25.0s |  물음에 답하십시오. 이래서 이. 너도 여기서 운동해? 응. 기숙사에서도 가까운데다가 비싸지도 않잖아. 그건 그래. 난 시작한 지 일주일 정도 ...\n",
            "[02] 10.0–30.0s |  너도 여기서 운동해? 응. 기숙사에서도 가까운데다가 비싸지도 않잖아. 그건 그래. 난 시작한 지 일주일 정도밖에 안 됐는데 넌 언제부터 시작했...\n",
            "[03] 15.0–35.0s |  기숙사에서도 가까운데다가 비싸지도 않잖아 그건 그래 난 시작한 지 일주일 정도밖에 안 됐는데 넌 언제부터 시작했어? 나는 6개월 정도 됐어...\n",
            "[04] 20.0–40.0s |  그건 그래. 난 시작한 지 일주일 정도밖에 안 됐는데 넌 언제부터 시작했어? 나는 6개월 정도 됐어. 그럼 잘 모르는 건 너한테 물어봐도 돼?...\n",
            "[05] 25.0–45.0s |  안 됐는데 넌 언제부터 시작했어? 나는 6개월 정도 됐어. 그럼 잘 모르는 건 너한테 물어봐도 돼? 물론이지. 오늘은 무슨 운동 할 건데?...\n",
            "[06] 30.0–50.0s |  나는 6개월 정도 됐어. 그럼 잘 모르는 건 너한테 물어봐도 돼? 물론이지. 오늘은 무슨 운동 할 건데? 글쎄. 근데 여기......\n",
            "[07] 35.0–55.0s |  그럼 잘 모르는 건 너한테 물어봐도 돼? 물론이지. 오늘은 무슨 운동 할 건데? 글쎄. 근데 여기 요가 수업도 있어? 응. 매일 저녁......\n",
            "[08] 40.0–60.0s |  물론이지. 오늘은 무슨 운동 할 건데? 글쎄. 근데 여기 요가 수업도 있어? 응. 매일 저녁 7시부터 1시간씩 있는 것 같더라. 너도 하려고?...\n",
            "[09] 45.0–65.0s |  글쎄? 근데 여기 요가 수업도 있어? 응. 매일 저녁 7시부터 1시간씩 있는 것 같더라. 너도 하려고? 하고 싶은데 어떻게 하면 그 수업......\n",
            "[10] 50.0–70.0s |  로가 수업도 있어? 응. 매일 저녁 7시부터 1시간씩 있는 것 같더라. 너도 하려고? 하고 싶은데, 어떻게 하면 그 수업을 들을 수 있어? 너...\n",
            "[11] 55.0–75.0s |  7시부터 1시간씩 있는 것 같더라. 너도 하려고? 하고 싶은데 어떻게 하면 그 수업을 들을 수 있어? 너도 헬스 회원이니까 카운터에 가서 신청...\n"
          ]
        }
      ],
      "source": [
        "out = transcribe_sliding(model_name='small', language='ko', win_sec=20, hop_sec=5)\n",
        "print_windows(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00] 0.0–20.0s |  듣기 다음을 잘 듣고 물음에 답하십시오 이래서 이 너도 여기서 운동해? 응 기숙사에서도 가까운데다가 비싸지도 않잖아...\n",
            "[01] 5.0–25.0s |  모름에 답하십시오. 이래서 이. 너도 여기서 운동해? 응. 기숙사에서도 가까운데다가 비싸지도 않잖아. 그건 그래. 난 시작한지 일주일 정도받....\n",
            "[02] 10.0–30.0s |  너도 여기서 운동해? 응! 기숙사에서도 가까운데다가 비싸지도 않잖아 그건 그래 난 시작한지 일주일 정도 밖에 안 됐는데 넌 언제부터 시작했어?...\n",
            "[03] 15.0–35.0s |  기숙사에서도 가까운데다가 비싸지도 않잖아 그건 그래 난 시작한지 일주일 정도 밖에 안 됐는데 넌 언제부터 시작했어? 나는 6개월 정도 됐어...\n",
            "[04] 20.0–40.0s |  그건 그래! 난 시작한지 일주일 정도 밖에 안 됐는데 넌 언제부터 시작했어? 나는 6개월 정도 됐어 그럼 잘 모르는 건 너한테 물어봐도 돼?...\n",
            "[05] 25.0–45.0s |  이렇게 안 됐는데. 넌 언제부터 시작했어? 나는 6개월 정도 됐어. 그럼 잘 모르는 건 너한테 물어봐도 돼? 물론이지. 오늘은 무슨 운동할 건...\n",
            "[06] 30.0–50.0s |  나는 6개월 정도 됐어. 그럼 잘 모르는 건 너한테 물어봐도 돼? 물론이지. 오늘은 무슨 운동할 건데? 글쎄? 근데 여기...\n",
            "[07] 35.0–55.0s |  그럼 잘 모르는 건 너한테 물어봐도 돼? 물론이지. 오늘은 무슨 운동할 건데? 글쎄? 근데 여기 요가수업도 있어? 음! 매일 저녁...\n",
            "[08] 40.0–60.0s |  물론이지. 오늘은 무슨 운동할 건데? 글쎄? 근데 여기 요가수업도 있어? 음! 매일 저녁 7시부터 1시간씩 있는 것 같더라? 너도 하려고?...\n",
            "[09] 45.0–65.0s |  글쎄? 근데 여기 요가수업도 있어? 응. 매일 저녁 일곱시부터 한 시간씩 있는 것 같더라. 너도 하려고? 하고 싶은데 어떻게 하면 그 수......\n",
            "[10] 50.0–70.0s |  누가 수업도 있어? 응. 매일 저녁 7시부터 1시간씩 있는 것 같더라. 너도 하려고? 하고 싶은데 어떻게 하면 그 수업을 들을 수 있어? 너도...\n",
            "[11] 55.0–75.0s |  일곱시부터 한 시간씩 있는 것 같더라? 너도 하려고? 하고 싶은데 어떻게 하면 그 수업을 들을 수 있어? 너도 헬스 회원이니까 카운터에 가서 ...\n"
          ]
        }
      ],
      "source": [
        "out = transcribe_sliding(model_name='base', language='ko', win_sec=20, hop_sec=5)\n",
        "print_windows(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. 오류 분석 미니툴 — ref/hyp 토큰 정렬로 삽입/삭제/대체 확인\n",
        "- 레퍼런스 텍스트와 예측 텍스트를 **단어 단위로 비교(diff)**합니다.\n",
        "- `difflib.SequenceMatcher`를 활용해 삽입(insert), 삭제(delete), 치환(replace) 등을 표시합니다.\n",
        "- 활용:\n",
        "  - Whisper 전사 결과가 레퍼런스와 어디서 차이가 나는지 빠르게 확인\n",
        "  - 학습/실습 시 오류 유형(빠진 단어, 잘못된 단어, 추가된 단어) 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import difflib\n",
        "\n",
        "def diff_tokens(reference: str, hypothesis: str):\n",
        "    \"\"\"\n",
        "    레퍼런스(reference)와 예측(hypothesis) 텍스트를 단어 단위로 비교(diff)합니다.\n",
        "    - 출력: 삽입(insert), 삭제(delete), 치환(replace)된 부분과 위치를 표시\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) 공백 단위로 토큰화\n",
        "    a = reference.split()\n",
        "    b = hypothesis.split()\n",
        "\n",
        "    # 2) 시퀀스 매처 생성 (a=정답, b=예측)\n",
        "    sm = difflib.SequenceMatcher(None, a, b)\n",
        "\n",
        "    # 3) diff 연산 코드(opcodes) 순회\n",
        "    # (tag, i1, i2, j1, j2)\n",
        "    # - tag: 'replace', 'delete', 'insert', 'equal'\n",
        "    # - i1:i2 → 레퍼런스 범위\n",
        "    # - j1:j2 → 예측 범위\n",
        "    for tag, i1, i2, j1, j2 in sm.get_opcodes():\n",
        "        if tag != 'equal':  # 동일(equal) 구간은 생략\n",
        "            print(\n",
        "                f\"{tag:>9}: ref[{i1}:{i2}] -> hyp[{j1}:{j2}]\",\n",
        "                \"|\", ' '.join(a[i1:i2]), \"->\", ' '.join(b[j1:j2])\n",
        "            )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  replace: ref[3:4] -> hyp[3:4] | 애쓰는 -> S는\n"
          ]
        }
      ],
      "source": [
        "diff_tokens('그는 괜찮은 척하려고 애쓰는 것 같았다.', '그는 괜찮은 척하려고 S는 것 같았다.')\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9. 파형 + 전사 구간 시각화\n",
        "- 오디오 파형과 Whisper 전사 결과(segments)를 **겹쳐서 시각화**합니다.\n",
        "- 각 segment 구간은 **주황색 음영 영역**으로 표시됩니다.\n",
        "- 활용 예시:\n",
        "  - 긴 오디오 전사 후 **어디서 어떤 구간이 인식되었는지** 빠르게 확인\n",
        "  - 특정 시간대의 전사 결과를 **오디오와 대조 분석**\n",
        "  - 데이터 품질 검증(잡음 구간, 미전사 구간 등 시각적 확인)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wav='./metacode-lecture/tmp_16k.wav'\n",
        "def plot_wave_and_segments(wav: torch.Tensor, sr: int, segments: list):\n",
        "    \"\"\"\n",
        "    오디오 파형과 Whisper 전사 구간(segments)을 함께 시각화.\n",
        "\n",
        "    Args:\n",
        "        wav (torch.Tensor): 오디오 파형 (1차원 텐서, 샘플 단위)\n",
        "        sr (int): 샘플링 레이트 (Hz)\n",
        "        segments (list[dict]): Whisper 전사 결과에서 추출한 segment 리스트\n",
        "            예: [{'start': float, 'end': float, 'text': str}, ...]\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) 시간축 (초 단위) 계산\n",
        "    t = np.arange(wav.numel()) / sr\n",
        "\n",
        "    # 2) 그래프 초기화\n",
        "    plt.figure(figsize=(12, 3))\n",
        "\n",
        "    # 3) 오디오 파형 그리기\n",
        "    plt.plot(t, wav.cpu().numpy(), color='steelblue')\n",
        "\n",
        "    # 4) 전사된 segment 구간을 주황색 음영으로 강조\n",
        "    for s in segments:\n",
        "        plt.axvspan(s['start'], s['end'], color='orange', alpha=0.2)\n",
        "\n",
        "    # 5) 축/레이블/제목 설정\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.title('Waveform with Whisper segments')\n",
        "\n",
        "    # 6) 레이아웃 정리 후 시각화 출력\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kay/Library/Caches/pypoetry/virtualenvs/metacode-SW7Y7iX4-py3.13/lib/python3.13/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 예시: 오디오 파형 + 전사 세그먼트 시각화\n",
        "wav, sr = load_audio_mono_16k(EXAMPLE_WAV, duration_sec=15)\n",
        "out = transcribe_with_whisper('./data/speech/tmp_16k.wav', model_name='base', language='ko')\n",
        "\n",
        "plot_wave_and_segments(wav, sr, out.get('segments', []))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Metacode Lecture (Python 3.13)",
      "language": "python",
      "name": "metacode-lecture"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
