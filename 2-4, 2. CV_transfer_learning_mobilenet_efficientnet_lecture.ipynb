{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-4, 2강 Computer Vision 전이학습(MobileNet/EfficientNet)으로 CIFAR-10 분류\n",
        "- 데이터 다운로드 → 데이터 탐색 → 사전학습 백본 선택 → 학습/검증 → 오류 사례 분석 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 전이학습 (Transfer Learning)\n",
        "\n",
        "- 전이학습은 **이미 학습된 모델을 새로운 문제에 재활용하는 기법**입니다.  \n",
        "- 처음부터 모델을 다 학습시키는 대신, 기존에 대규모 데이터로 잘 훈련된 모델의 지식(가중치, 패턴)을 가져와서 새로운 작업에 맞게 조금만 수정하거나 추가 학습하는 방식입니다.  \n",
        "\n",
        "---\n",
        "\n",
        "### 왜 전이학습을 쓸까?\n",
        "- **데이터 부족 문제 해결**: 새로운 문제에 사용할 데이터가 적어도, 기존 모델이 가진 \"일반적인 특징 추출 능력\"을 활용할 수 있음  \n",
        "- **학습 시간 단축**: 처음부터 학습하면 수일~수주 걸리지만, 전이학습은 몇 시간~며칠로 단축 가능  \n",
        "- **성능 향상**: 특히 이미지, 자연어 같은 영역에서는 사전 학습된 모델을 활용하는 게 성능이 훨씬 좋음  \n",
        "\n",
        "---\n",
        "\n",
        "### 전이학습의 방법\n",
        "\n",
        "#### 1. Feature Extraction (특징 추출만 활용)\n",
        "- 사전 학습된 모델의 초반부(저수준 특징: 선, 모양, 질감 등)는 그대로 사용  \n",
        "- 마지막 분류기 부분만 새로운 데이터에 맞게 학습  \n",
        "- **예시**: ImageNet으로 학습된 CNN을 가져와서, 마지막 레이어만 고양이·강아지 분류기로 교체  \n",
        "\n",
        "#### 2. Fine-Tuning (미세 조정)\n",
        "- 기존 모델 전체 또는 일부 층을 새로운 데이터로 재학습  \n",
        "- 데이터가 충분하면 전부 재학습, 부족하면 상위 레이어 일부만 조정  \n",
        "- **예시**: BERT를 가져와 한국어 감정 분석에 맞게 전체 가중치를 조금 수정  \n",
        "\n",
        "---\n",
        "\n",
        "### 예시\n",
        "- **이미지 분류**  \n",
        "  ResNet을 ImageNet으로 학습 → MRI 스캔 이미지 분류에 활용  \n",
        "\n",
        "- **자연어 처리**  \n",
        "  GPT, BERT 같은 대규모 언어모델을 가져와 특정 작업(챗봇, 감정분석, 요약)에 맞게 Fine-tuning  \n",
        "\n",
        "- **음성 인식**  \n",
        "  대규모 음성 데이터로 학습한 모델을 특정 억양/언어에 맞게 재학습  \n",
        "\n",
        "---\n",
        "\n",
        "###  비유\n",
        "전이학습은 **운전면허를 딴 사람이 새로운 차종에 적응하는 과정**과 비슷합니다.  \n",
        "운전의 기본(도로 규칙, 브레이크, 가속)은 이미 알고 있어서,  \n",
        "차종(세단, SUV, 트럭)에 맞게 조금만 연습하면 되는 것이죠.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MobileNet → EfficientNet의 계보 소개\n",
        "\n",
        "---\n",
        "\n",
        "### MobileNetV1 (2017)  \n",
        "- **핵심**: Depthwise separable convolution  \n",
        "- **목적**: 연산량을 줄여 모바일 환경에서도 CNN을 쓸 수 있게 하기  \n",
        "\n",
        "---\n",
        "\n",
        "### MobileNetV2 (2018)  \n",
        "- **핵심**: Inverted Residual + Linear Bottleneck  \n",
        "- **효과**: 효율성 + 성능 향상  \n",
        "\n",
        "---\n",
        "\n",
        "### MobileNetV3 (2019)  \n",
        "- **핵심**: Hard-Swish, NAS, SE 모듈 추가  \n",
        "- **목적**: 모바일 환경 최적화 강화  \n",
        "\n",
        "---\n",
        "\n",
        "### EfficientNet (2019)  \n",
        "- **핵심**: MBConv 블록 (MobileNetV2 기반) + SE  \n",
        "- **새로운 아이디어**: Compound Scaling  \n",
        "  - 너비·깊이·해상도를 **동시에 확장**  \n",
        "- **결과**: 같은 연산량에서 기존 모델보다 훨씬 높은 정확도  \n",
        "\n",
        "---\n",
        "\n",
        "## MobileNetV3-Small  \n",
        "\n",
        "**핵심 아이디어**: “작고 가볍게, 하지만 빠르고 똑똑하게!”  \n",
        "- 스마트폰이나 임베디드 기기처럼 **연산 능력이 약한 장치**에서도 원활히 동작하도록 설계된 초경량 모델.  \n",
        "- “Small” 버전이라서 특히 더 가볍고, **속도와 배터리 효율**이 중요한 환경에서 유리.  \n",
        "\n",
        "#### 주요 설계 요소\n",
        "- **Depthwise + Pointwise Convolution** → 큰 계산을 잘게 쪼개서 연산량 대폭 절감  \n",
        "- **Inverted Residual Block** → 입력 채널을 확장 → 연산 → 축소, 적은 파라미터로도 높은 표현력  \n",
        "- **Squeeze-and-Excitation(SE) 모듈** → 채널별 중요도를 재조정해 정확도 향상  \n",
        "- **Hard-Swish 활성화 함수** → Swish를 근사해 연산량 줄이면서도 성능 유지  \n",
        "- **NAS + NetAdapt** → 모바일 제약(메모리, 속도, 배터리)에 맞춘 자동 최적화  \n",
        "\n",
        "**비유**: **경차** — 연비 좋고 주차하기 쉽지만 최고 속도는 제한적. 도심 주행에는 최적화된 선택.  \n",
        "\n",
        "---\n",
        "\n",
        "## EfficientNet-B0  \n",
        "\n",
        "**핵심 아이디어**: “효율적으로 크게 키우자!”  \n",
        "- 깊이만 늘리거나 너비만 넓히는 대신, **너비·깊이·해상도**를 균형 있게 동시에 확장 (**Compound Scaling**).  \n",
        "- EfficientNet 시리즈의 가장 작은 기본형이지만, MobileNet보다 크고 **정확도가 더 높음**.  \n",
        "\n",
        "#### 주요 설계 요소\n",
        "- **MBConv 블록** → MobileNetV2 기반 Inverted Residual 구조 + SE 모듈  \n",
        "- **Squeeze-and-Excitation(SE)** → 중요한 특징을 강조해 성능 향상  \n",
        "- **Swish 활성화 함수** → MobileNetV3의 Hard-Swish보다 무겁지만 정확도는 더 높음  \n",
        "- **Compound Scaling** → 깊이·너비·해상도를 함께 확장해 효율 대비 정확도 극대화  \n",
        "\n",
        "**비유**: **준중형 세단** — 경차보다 힘이 좋고, 연비도 괜찮으며 장거리·고속도로 주행에도 안정적.  \n",
        "\n",
        "---\n",
        "\n",
        "# 요약 비교\n",
        "\n",
        "| 모델 | MobileNetV3-Small | EfficientNet-B0 |\n",
        "|------|------------------|----------------|\n",
        "| **목적** | 초경량, 초저전력 | 성능·효율 균형 |\n",
        "| **주요 기법** | Depthwise+Pointwise, Inverted Residual, SE, Hard-Swish, NAS | MBConv, SE, Swish, Compound Scaling |\n",
        "| **크기/속도** | 더 작고 빠름 | 좀 더 큼 |\n",
        "| **정확도** | 상대적으로 낮음 (~67%) | 더 높음 (~77%) |\n",
        "| **비유** | 경차 (효율 위주) | 준중형 세단 (성능/효율 밸런스) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 설정 및 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 환경 설정 및 공통 유틸\n",
        "# - 라이브러리 import, 디바이스/시드 설정, 한글 폰트 지정\n",
        "# - 재현성 확보와 시각화 환경 통일\n",
        "# -------------------------------\n",
        "# 필요한 라이브러리 임포트 (첫 강의 스타일 유지)\n",
        "import os, time, random, numpy as np, matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import DataLoader as DL\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "# -------------------------------\n",
        "# 디바이스(CPU/GPU) 선택 및 시드 고정\n",
        "# -------------------------------\n",
        "# GPU가 있으면 'cuda', 없으면 'cpu'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', device)\n",
        "\n",
        "# 시드 고정: 파이썬/넘파이/파이토치(및 CUDA) 모두 동일 시드 적용\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "# -------------------------------\n",
        "# 한글 폰트 설정 (그래프에서 한글 깨짐 방지)\n",
        "# -------------------------------\n",
        "plt.rcParams['font.family'] = 'AppleGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 데이터 다운로드 및 DataLoader 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 데이터 전처리 및 DataLoader 구성\n",
        "# - CIFAR-10 다운로드, 학습/검증/테스트 분할, 변환/증강 설정\n",
        "# - 전이학습 스케일(224)과 ImageNet 통계로 정규화 적용\n",
        "# -------------------------------\n",
        "\n",
        "# ImageNet 사전학습 모델의 입력 통계(평균/표준편차)\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# -------------------------------\n",
        "# 학습용 변환(증강 포함)\n",
        "# - Resize(224x224): 사전학습 백본 입력 크기에 맞추기\n",
        "# - RandomHorizontalFlip: 좌우반전으로 데이터 다양성 확보\n",
        "# - Normalize: ImageNet 통계로 스케일 맞춤\n",
        "# -------------------------------\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((224,224)), # MobileNet/EfficientNet은 224×224 스케일에 맞춰 학습\n",
        "    transforms.RandomHorizontalFlip(), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 평가/테스트용 변환(증강 제외)\n",
        "# - 학습 성능의 공정한 비교를 위해 결정적 변환만 적용\n",
        "# -------------------------------\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 데이터셋 다운로드/로딩 (CIFAR-10)\n",
        "# -------------------------------\n",
        "root = './data'\n",
        "train_full = datasets.CIFAR10(root=root, train=True, download=True, transform=train_tf)\n",
        "test_full  = datasets.CIFAR10(root=root, train=False, download=True, transform=test_tf)\n",
        "class_names = train_full.classes\n",
        "\n",
        "# -------------------------------\n",
        "# 학습/테스트 SUBSET 적용 (예: 10%만 사용)\n",
        "# - 실습/데모 속도 향상을 위해 일부만 사용\n",
        "# -------------------------------\n",
        "SUBSET = 0.1  # 10% 사용\n",
        "val_ratio = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 데이터 서브셋 분할 및 DataLoader 생성\n",
        "# - train/val/test 분할, 배치/섞기 설정, 샘플 크기 출력\n",
        "# - SUBSET로 전체에서 일정 비율만 추출해 실험 가속\n",
        "# -------------------------------\n",
        "# Train subset\n",
        "full_len = len(train_full)\n",
        "subset_len = int(full_len * SUBSET)\n",
        "train_subset, _ = random_split(train_full, [subset_len, full_len - subset_len])\n",
        "\n",
        "# subset에서 train/val 분할 (비율 유지)\n",
        "val_len   = int(subset_len * val_ratio)\n",
        "train_len = subset_len - val_len\n",
        "train_set, val_set = random_split(train_subset, [train_len, val_len])\n",
        "\n",
        "# Test subset\n",
        "test_full_len = len(test_full)\n",
        "test_subset_len = int(test_full_len * SUBSET)\n",
        "# train_full 데이터를 SUBSET 비율만큼만 랜덤 추출\n",
        "# - train_subset : 전체 데이터에서 SUBSET 비율만큼 무작위로 뽑은 부분집합\n",
        "# - _            : 나머지 데이터 (여기서는 사용하지 않으므로 버림)\n",
        "test_set, _ = random_split(test_full, [test_subset_len, test_full_len - test_subset_len])\n",
        "\n",
        "# DataLoader 구성 (배치/섞기/num_workers 동일 스타일)\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True,  num_workers=2)\n",
        "val_loader   = DataLoader(val_set,   batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_set,  batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print('Train/Val/Test sizes:', len(train_set), len(val_set), len(test_set))\n",
        "print('Sample image shape (C,H,W):', next(iter(train_loader))[0][0].shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 사전학습 백본 선택 (MobileNetV3 Small / EfficientNet-B0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 백본 선택 기본 설정\n",
        "# - NUM_CLASSES: 분류 클래스 수(=CIFAR-10 → 10)\n",
        "# - 기본 BACKBONE: 'mobilenet' 또는 'efficientnet' 중 초기값\n",
        "#   (실제 모델 생성은 train_model 내부에서 수행)\n",
        "# -------------------------------\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "BACKBONE = 'mobilenet'  # 'mobilenet' | 'efficientnet'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 학습/검증 루프 (첫 강의와 동일 인터페이스)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 학습/검증 루프 및 모델 학습 함수\n",
        "# - train_epoch / eval_epoch / train_model / 학습곡선 플롯\n",
        "# -------------------------------\n",
        "\n",
        "# -------------------------------\n",
        "# 한 Epoch 동안 모델 학습(train) 수행\n",
        "# -------------------------------\n",
        "def train_epoch(model, loader, loss_fn, optim_):\n",
        "    model.train()   # 학습 모드 (Dropout, BatchNorm 활성)\n",
        "    tl = 0; tc = 0; n = 0   # tl: 총 손실, tc: 총 정답 수, n: 전체 샘플 수\n",
        "    \n",
        "    for x, y in loader:  # 배치 단위 데이터 로딩 from DataLoader\n",
        "        x, y = x.to(device), y.to(device)    # GPU/CPU 장치에 데이터 올리기\n",
        "        \n",
        "        optim_.zero_grad()    # 이전 배치의 gradient 초기화\n",
        "        out = model(x)        # 모델 forward pass → 예측 결과\n",
        "        loss = loss_fn(out, y)  # 예측 vs 정답 비교 → 손실 계산\n",
        "        \n",
        "        loss.backward()       # 손실에 따른 gradient 계산 (역전파)\n",
        "        optim_.step()         # optimizer가 파라미터 업데이트\n",
        "        \n",
        "        # 배치 손실/정확도 누적\n",
        "        tl += loss.item() * x.size(0)                    # 배치 손실 * 배치 크기\n",
        "        tc += (out.argmax(1) == y).sum().item()          # 예측 결과와 정답 비교 → 맞은 개수\n",
        "        n  += x.size(0)                                  # 전체 샘플 수 카운트\n",
        "    \n",
        "    # 평균 손실, 평균 정확도 반환\n",
        "    return tl/n, tc/n\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 한 Epoch 동안 모델 평가(eval) 수행\n",
        "# -------------------------------\n",
        "@torch.no_grad()   # 평가 시 gradient 계산 비활성화 → 메모리/연산 절약\n",
        "def eval_epoch(model, loader, loss_fn):\n",
        "    model.eval()   # 평가 모드 (Dropout, BatchNorm 비활성)\n",
        "    tl = 0; tc = 0; n = 0\n",
        "    \n",
        "    for x, y in loader:  # 배치 단위 데이터 로딩 from DataLoader\n",
        "        x, y = x.to(device), y.to(device)    # GPU/CPU 장치에 데이터 올리기\n",
        "        \n",
        "        out = model(x)        # 모델 forward pass\n",
        "        loss = loss_fn(out, y)  # 손실 계산\n",
        "        \n",
        "        # 배치 손실/정확도 누적\n",
        "        tl += loss.item() * x.size(0)\n",
        "        tc += (out.argmax(1) == y).sum().item()\n",
        "        n  += x.size(0)\n",
        "    \n",
        "    # 평균 손실, 평균 정확도 반환\n",
        "    return tl/n, tc/n\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 학습/평가에 사용할 손실 함수 지정\n",
        "# - CrossEntropyLoss: 다중 클래스 분류에서 일반적으로 사용하는 손실 함수\n",
        "#   (softmax + NLLLoss가 결합된 형태)\n",
        "# -------------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 모델 학습 함수 정의\n",
        "# - train_model: 백본 생성/동결 옵션 포함, 학습 로그/히스토리 기록\n",
        "# -------------------------------\n",
        "def train_model(model=None, epochs=8, lr=1e-3, backbone=None, freeze_backbone=False):\n",
        "    if model is None:\n",
        "        chosen = backbone if backbone is not None else BACKBONE  # 지정 없으면 전역 BACKBONE 사용\n",
        "        \n",
        "        if chosen == 'mobilenet':\n",
        "            weights = models.MobileNet_V3_Small_Weights.DEFAULT   # 사전 학습 가중치 불러오기\n",
        "            base = models.mobilenet_v3_small(weights=weights)     # MobileNetV3 Small 로드\n",
        "            in_features = base.classifier[-1].in_features         # 마지막 FC layer 입력 차원\n",
        "            base.classifier[-1] = nn.Linear(in_features, NUM_CLASSES)  # 새로운 분류기(head)로 교체\n",
        "        \n",
        "        elif chosen == 'efficientnet':\n",
        "            weights = models.EfficientNet_B0_Weights.DEFAULT      # 사전 학습 가중치 불러오기\n",
        "            base = models.efficientnet_b0(weights=weights)        # EfficientNet-B0 로드\n",
        "            in_features = base.classifier[-1].in_features         # 마지막 FC layer 입력 차원\n",
        "            base.classifier[-1] = nn.Linear(in_features, NUM_CLASSES)  # 새로운 분류기(head)로 교체\n",
        "        \n",
        "        else:\n",
        "            raise ValueError('backbone must be \"mobilenet\" or \"efficientnet\"')\n",
        "\n",
        "        model = base.to(device)   # GPU/CPU 장치에 모델 올리기\n",
        "\n",
        "        # --------------------------------------------\n",
        "        # 백본 동결 (feature extractor로만 쓰고 분류기만 학습)\n",
        "        # --------------------------------------------\n",
        "        if freeze_backbone:\n",
        "            for name, p in model.named_parameters():\n",
        "                if 'classifier' not in name:   # classifier 파라미터는 학습 가능\n",
        "                    p.requires_grad = False    # backbone 파라미터는 학습 불가\n",
        "\n",
        "        # --------------------------------------------\n",
        "        # 전역 상태 업데이트\n",
        "        # - 이후 셀에서 동일 모델과 backbone 재사용 가능\n",
        "        # --------------------------------------------\n",
        "        globals()['model'] = model\n",
        "        globals()['BACKBONE'] = chosen\n",
        "\n",
        "        print('Selected backbone:', chosen)\n",
        "        print('Trainable params:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "\n",
        "    optim_ = optim.Adam(model.parameters(), lr=lr)  # Adam optimizer\n",
        "    hist = {\n",
        "        'train_acc':[], 'val_acc':[], \n",
        "        'train_loss':[], 'val_loss':[]\n",
        "    }   # 학습/검증 손실 및 정확도 기록용 딕셔너리\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # 1) 학습(train) 단계\n",
        "        tr_l, tr_a = train_epoch(model, train_loader, criterion, optim_)\n",
        "        # 2) 검증(validation) 단계\n",
        "        va_l, va_a = eval_epoch(model, val_loader, criterion)\n",
        "        \n",
        "        # 3) 결과 기록\n",
        "        hist['train_loss'].append(tr_l); hist['val_loss'].append(va_l)\n",
        "        hist['train_acc'].append(tr_a);  hist['val_acc'].append(va_a)\n",
        "\n",
        "        # 4) 진행 상황 출력\n",
        "        print(f'[Ep {ep}/{epochs}] train={tr_a:.3f}/{tr_l:.3f}  val={va_a:.3f}/{va_l:.3f}')\n",
        "\n",
        "    return hist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------------------------\n",
        "# 학습 곡선 플로팅 함수\n",
        "# - 입력: h (train/val의 loss & acc 기록을 담은 dict)\n",
        "# - 동작: Accuracy 곡선, Loss 곡선을 각각 그려 시각화\n",
        "# --------------------------------------------\n",
        "def plot_hist(h, title):\n",
        "    # ----------------------------\n",
        "    # 1) 정확도(Accuracy) 시각화\n",
        "    # ----------------------------\n",
        "    plt.figure(figsize=(6,4))                    # 그래프 크기 설정\n",
        "    plt.plot(h['train_acc'], label='train_acc')  # 학습 정확도 곡선\n",
        "    plt.plot(h['val_acc'], label='val_acc')      # 검증 정확도 곡선\n",
        "    plt.title(title+' (Accuracy)')               # 그래프 제목\n",
        "    plt.legend()                                 # 범례 표시\n",
        "    plt.tight_layout()                           # 여백 자동 조정\n",
        "    plt.show()                                   # 그래프 출력\n",
        "\n",
        "    # ----------------------------\n",
        "    # 2) 손실(Loss) 시각화\n",
        "    # ----------------------------\n",
        "    plt.figure(figsize=(6,4))                    # 그래프 크기 설정\n",
        "    plt.plot(h['train_loss'], label='train_loss')# 학습 손실 곡선\n",
        "    plt.plot(h['val_loss'], label='val_loss')    # 검증 손실 곡선\n",
        "    plt.title(title+' (Loss)')                   # 그래프 제목\n",
        "    plt.legend()                                 # 범례 표시\n",
        "    plt.tight_layout()                           # 여백 자동 조정\n",
        "    plt.show()                                   # 그래프 출력\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 학습 실행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 학습 실행 진입점\n",
        "# - train_model 호출, 백본/하이퍼파라미터 선택\n",
        "# -------------------------------\n",
        "print('TRAIN_start')\n",
        "hist = train_model(backbone='mobilenet', epochs=4, lr=1e-3)  # 'mobilenet' | 'efficientnet'\n",
        "print('TRAIN_end')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 학습 곡선(정확도/손실) 시각화\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 학습 곡선 시각화\n",
        "# - 정확도/손실 곡선 플롯\n",
        "# -------------------------------\n",
        "plot_hist(hist, f'{BACKBONE.upper()} ' )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. 오분류 분석 (혼동행렬, Top-3 혼동 쌍, 사례 시각화)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 혼동행렬 및 오분류 분석 (1)\n",
        "# - 예측 결과 수집 → 혼동행렬(confusion matrix) 계산 및 시각화\n",
        "# -------------------------------\n",
        "\n",
        "# 원본 테스트셋 (subset 아님, 오리지널 전체 CIFAR-10 테스트셋)\n",
        "# 이미지를 직접 확인할 때 사용 (transform은 ToTensor만 적용)\n",
        "raw_test = datasets.CIFAR10(\n",
        "    root='./data', train=False, download=False, transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# test_set이 Subset이면 indices 속성으로 원본 인덱스를 가져옴\n",
        "# Subset이 아니면 그냥 [0 ~ len(raw_test)) 범위 사용\n",
        "subset_to_full_idx = (\n",
        "    np.array(test_set.indices) if hasattr(test_set, 'indices') \n",
        "    else np.arange(len(raw_test))\n",
        ")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 모델의 전체 예측 및 라벨 수집 함수\n",
        "# - DataLoader를 순회하며 y(정답), ŷ(예측)를 모두 numpy 배열로 반환\n",
        "# --------------------------------------------\n",
        "@torch.no_grad()   # 평가 시 gradient 계산 불필요 → 속도/메모리 절약\n",
        "def get_all_preds_with_subset(model, subset_loader):\n",
        "    model.eval()       # 평가 모드\n",
        "    ys = []            # 실제 정답(label) 모음\n",
        "    ps = []            # 모델 예측(pred) 모음\n",
        "    for x, y in subset_loader:\n",
        "        x = x.to(device)               # 입력 배치 장치로 이동\n",
        "        out = model(x)                 # 모델 forward pass\n",
        "        ps.append(out.argmax(1).cpu().numpy())  # 예측 라벨 저장\n",
        "        ys.append(y.numpy())                       # 실제 라벨 저장\n",
        "    return np.concatenate(ys), np.concatenate(ps)  # 전체 합치기\n",
        "\n",
        "# --------------------------------------------\n",
        "# 혼동행렬 계산\n",
        "# --------------------------------------------\n",
        "y_true, y_pred = get_all_preds_with_subset(model, test_loader)   # 정답 vs 예측\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))\n",
        "\n",
        "# --------------------------------------------\n",
        "# 혼동행렬 시각화\n",
        "# --------------------------------------------\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(cm, interpolation='nearest')   # 2D 행렬 이미지 출력\n",
        "plt.title('Confusion Matrix (Test Subset)')\n",
        "plt.colorbar()                            # 색상 막대 표시\n",
        "plt.xticks(range(NUM_CLASSES), class_names, rotation=45)  # x축: 예측 클래스\n",
        "plt.yticks(range(NUM_CLASSES), class_names)               # y축: 실제 클래스\n",
        "plt.tight_layout()\n",
        "plt.xlabel('Predicted')   # 열: 예측\n",
        "plt.ylabel('True')        # 행: 실제\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 혼동행렬 및 오분류 분석 (2)\n",
        "# - 혼동행렬(cm)을 바탕으로 가장 많이 헷갈린 클래스 쌍 Top-3 추출\n",
        "# -------------------------------\n",
        "\n",
        "pairs = []   # (클래스 쌍, 혼동 횟수) 저장용 리스트\n",
        "\n",
        "# 모든 클래스 쌍 (i: 실제 클래스, j: 예측 클래스) 순회\n",
        "for i in range(NUM_CLASSES):\n",
        "    for j in range(NUM_CLASSES):\n",
        "        if i != j and cm[i, j] > 0:   # 자기 자신(i==j)은 제외, 혼동이 발생한 경우만\n",
        "            pairs.append(((i, j), cm[i, j]))  # ((실제, 예측), 혼동횟수) 저장\n",
        "\n",
        "# 혼동 횟수 기준으로 내림차순 정렬 → 상위 3개 선택\n",
        "pairs = sorted(pairs, key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "# 사람이 보기 좋게 클래스 이름으로 변환하여 출력\n",
        "print('Top-3 혼동 클래스 쌍:', [\n",
        "    (class_names[i], class_names[j], n) for (i, j), n in pairs\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 혼동행렬 및 오분류 분석 (3)\n",
        "# - 혼동 사례 인덱스 탐색 및 시각화\n",
        "# -------------------------------\n",
        "\n",
        "# 특정 (실제 라벨, 예측 라벨) 쌍에 해당하는 오분류 사례의 원본 인덱스 추출\n",
        "def find_mismatch_indices_subset(true_label, pred_label, max_show=6):\n",
        "    out_idx = []   # 오분류된 샘플들의 원본 인덱스 저장\n",
        "    count = 0      # 현재까지 찾은 개수\n",
        "    ptr = 0        # subset 내 전체 진행된 데이터 개수 (global index 계산용)\n",
        "\n",
        "    # test_set을 DataLoader로 순회 (batch 단위 예측)\n",
        "    for batch_x, batch_y in DL(test_set, batch_size=128, shuffle=False):\n",
        "        logits = model(batch_x.to(device))                # 모델 예측(logits)\n",
        "        preds = logits.argmax(1).cpu().numpy()            # 예측 라벨\n",
        "        for k in range(len(batch_y)):                     # 배치 내 개별 샘플 확인\n",
        "            if batch_y[k].item() == true_label and preds[k] == pred_label:\n",
        "                # subset 인덱스(ptr + k)를 full 인덱스로 변환\n",
        "                full_idx = subset_to_full_idx[ptr + k]\n",
        "                out_idx.append(full_idx)\n",
        "                count += 1\n",
        "                if count >= max_show:                     # max_show 개수만큼 찾으면 종료\n",
        "                    return out_idx\n",
        "        ptr += len(batch_y)                               # 진행된 샘플 개수 업데이트\n",
        "\n",
        "    return out_idx   # 찾은 인덱스 리스트 반환\n",
        "\n",
        "# --------------------------------------------\n",
        "# Top-3 혼동 클래스 쌍(pairs)별 실제 이미지 시각화\n",
        "# --------------------------------------------\n",
        "for (i, j), _ in pairs:   # (실제 라벨, 잘못 예측된 라벨)\n",
        "    ids_full = find_mismatch_indices_subset(i, j, max_show=6)\n",
        "    if not ids_full:       # 혼동 사례가 없으면 건너뜀\n",
        "        continue\n",
        "\n",
        "    plt.figure(figsize=(6,3))\n",
        "    for k, idx in enumerate(ids_full):\n",
        "        img, _ = raw_test[idx]                    # 원본 CIFAR-10 이미지 로드\n",
        "        plt.subplot(2, 3, k+1)                    # 2행 3열 subplot에 배치\n",
        "        plt.imshow(img.permute(1,2,0))            # (C,H,W) → (H,W,C) 변환 후 출력\n",
        "        plt.axis('off')\n",
        "        plt.title(f'T:{class_names[i]} → P:{class_names[j]}')  # 실제 vs 예측 표시\n",
        "    \n",
        "    plt.suptitle(f'혼동 사례(Subset): {class_names[i]} vs {class_names[j]}')  # 전체 제목\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 학습 실행 진입점\n",
        "# - train_model 호출, 백본/하이퍼파라미터 선택\n",
        "# -------------------------------\n",
        "print('TRAIN_start')\n",
        "hist = train_model(backbone='efficientnet', epochs=4, lr=1e-3)  # 'mobilenet' | 'efficientnet'\n",
        "print('TRAIN_end')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 학습 곡선 시각화\n",
        "# - 정확도/손실 곡선 플롯\n",
        "# -------------------------------\n",
        "plot_hist(hist, f'{BACKBONE.upper()} ' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 혼동행렬 및 오분류 분석 (1)\n",
        "# - 예측 결과 수집 → 혼동행렬(confusion matrix) 계산 및 시각화\n",
        "# -------------------------------\n",
        "\n",
        "# 원본 테스트셋 (subset 아님, 오리지널 전체 CIFAR-10 테스트셋)\n",
        "# 이미지를 직접 확인할 때 사용 (transform은 ToTensor만 적용)\n",
        "raw_test = datasets.CIFAR10(\n",
        "    root='./data', train=False, download=False, transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# test_set이 Subset이면 indices 속성으로 원본 인덱스를 가져옴\n",
        "# Subset이 아니면 그냥 [0 ~ len(raw_test)) 범위 사용\n",
        "subset_to_full_idx = (\n",
        "    np.array(test_set.indices) if hasattr(test_set, 'indices') \n",
        "    else np.arange(len(raw_test))\n",
        ")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 모델의 전체 예측 및 라벨 수집 함수\n",
        "# - DataLoader를 순회하며 y(정답), ŷ(예측)를 모두 numpy 배열로 반환\n",
        "# --------------------------------------------\n",
        "@torch.no_grad()   # 평가 시 gradient 계산 불필요 → 속도/메모리 절약\n",
        "def get_all_preds_with_subset(model, subset_loader):\n",
        "    model.eval()       # 평가 모드\n",
        "    ys = []            # 실제 정답(label) 모음\n",
        "    ps = []            # 모델 예측(pred) 모음\n",
        "    for x, y in subset_loader:\n",
        "        x = x.to(device)               # 입력 배치 장치로 이동\n",
        "        out = model(x)                 # 모델 forward pass\n",
        "        ps.append(out.argmax(1).cpu().numpy())  # 예측 라벨 저장\n",
        "        ys.append(y.numpy())                       # 실제 라벨 저장\n",
        "    return np.concatenate(ys), np.concatenate(ps)  # 전체 합치기\n",
        "\n",
        "# --------------------------------------------\n",
        "# 혼동행렬 계산\n",
        "# --------------------------------------------\n",
        "y_true, y_pred = get_all_preds_with_subset(model, test_loader)   # 정답 vs 예측\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))\n",
        "\n",
        "# --------------------------------------------\n",
        "# 혼동행렬 시각화\n",
        "# --------------------------------------------\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(cm, interpolation='nearest')   # 2D 행렬 이미지 출력\n",
        "plt.title('Confusion Matrix (Test Subset)')\n",
        "plt.colorbar()                            # 색상 막대 표시\n",
        "plt.xticks(range(NUM_CLASSES), class_names, rotation=45)  # x축: 예측 클래스\n",
        "plt.yticks(range(NUM_CLASSES), class_names)               # y축: 실제 클래스\n",
        "plt.tight_layout()\n",
        "plt.xlabel('Predicted')   # 열: 예측\n",
        "plt.ylabel('True')        # 행: 실제\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 혼동행렬 및 오분류 분석 (2)\n",
        "# - 혼동행렬(cm)을 바탕으로 가장 많이 헷갈린 클래스 쌍 Top-3 추출\n",
        "# -------------------------------\n",
        "\n",
        "pairs = []   # (클래스 쌍, 혼동 횟수) 저장용 리스트\n",
        "\n",
        "# 모든 클래스 쌍 (i: 실제 클래스, j: 예측 클래스) 순회\n",
        "for i in range(NUM_CLASSES):\n",
        "    for j in range(NUM_CLASSES):\n",
        "        if i != j and cm[i, j] > 0:   # 자기 자신(i==j)은 제외, 혼동이 발생한 경우만\n",
        "            pairs.append(((i, j), cm[i, j]))  # ((실제, 예측), 혼동횟수) 저장\n",
        "\n",
        "# 혼동 횟수 기준으로 내림차순 정렬 → 상위 3개 선택\n",
        "pairs = sorted(pairs, key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "# 사람이 보기 좋게 클래스 이름으로 변환하여 출력\n",
        "print('Top-3 혼동 클래스 쌍:', [\n",
        "    (class_names[i], class_names[j], n) for (i, j), n in pairs\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 혼동행렬 및 오분류 분석 (3)\n",
        "# - 혼동 사례 인덱스 탐색 및 시각화\n",
        "# -------------------------------\n",
        "\n",
        "# 특정 (실제 라벨, 예측 라벨) 쌍에 해당하는 오분류 사례의 원본 인덱스 추출\n",
        "def find_mismatch_indices_subset(true_label, pred_label, max_show=6):\n",
        "    out_idx = []   # 오분류된 샘플들의 원본 인덱스 저장\n",
        "    count = 0      # 현재까지 찾은 개수\n",
        "    ptr = 0        # subset 내 전체 진행된 데이터 개수 (global index 계산용)\n",
        "\n",
        "    # test_set을 DataLoader로 순회 (batch 단위 예측)\n",
        "    for batch_x, batch_y in DL(test_set, batch_size=128, shuffle=False):\n",
        "        logits = model(batch_x.to(device))                # 모델 예측(logits)\n",
        "        preds = logits.argmax(1).cpu().numpy()            # 예측 라벨\n",
        "        for k in range(len(batch_y)):                     # 배치 내 개별 샘플 확인\n",
        "            if batch_y[k].item() == true_label and preds[k] == pred_label:\n",
        "                # subset 인덱스(ptr + k)를 full 인덱스로 변환\n",
        "                full_idx = subset_to_full_idx[ptr + k]\n",
        "                out_idx.append(full_idx)\n",
        "                count += 1\n",
        "                if count >= max_show:                     # max_show 개수만큼 찾으면 종료\n",
        "                    return out_idx\n",
        "        ptr += len(batch_y)                               # 진행된 샘플 개수 업데이트\n",
        "\n",
        "    return out_idx   # 찾은 인덱스 리스트 반환\n",
        "\n",
        "# --------------------------------------------\n",
        "# Top-3 혼동 클래스 쌍(pairs)별 실제 이미지 시각화\n",
        "# --------------------------------------------\n",
        "for (i, j), _ in pairs:   # (실제 라벨, 잘못 예측된 라벨)\n",
        "    ids_full = find_mismatch_indices_subset(i, j, max_show=6)\n",
        "    if not ids_full:       # 혼동 사례가 없으면 건너뜀\n",
        "        continue\n",
        "\n",
        "    plt.figure(figsize=(6,3))\n",
        "    for k, idx in enumerate(ids_full):\n",
        "        img, _ = raw_test[idx]                    # 원본 CIFAR-10 이미지 로드\n",
        "        plt.subplot(2, 3, k+1)                    # 2행 3열 subplot에 배치\n",
        "        plt.imshow(img.permute(1,2,0))            # (C,H,W) → (H,W,C) 변환 후 출력\n",
        "        plt.axis('off')\n",
        "        plt.title(f'T:{class_names[i]} → P:{class_names[j]}')  # 실제 vs 예측 표시\n",
        "    \n",
        "    plt.suptitle(f'혼동 사례(Subset): {class_names[i]} vs {class_names[j]}')  # 전체 제목\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Metacode Lecture (Python 3.13)",
      "language": "python",
      "name": "metacode-lecture"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
