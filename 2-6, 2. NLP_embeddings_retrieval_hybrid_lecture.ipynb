{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-6, 2강 NLP 임베딩 기반 검색 — TF‑IDF vs SBERT vs Hybrid (CPU)\n",
        "\n",
        "- 목표: 의미/키워드 검색 방식을 비교하고, 하이브리드로 직관적 성능 차이를 체감\n",
        "- 제약: CPU 전용 환경(훈련/추론 모두 CPU)\n",
        "- 데이터: AG News 코퍼스(소규모 서브셋)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 구성 (Overview)\n",
        "- 0. 환경 설정 및 라이브러리\n",
        "- 1. 데이터 로드 및 corpus 생성 (AG News)\n",
        "- 2. 임베딩 2가지: SBERT / TF‑IDF\n",
        "- 3. 단일 질문 검색: TF‑IDF / SBERT / Hybrid\n",
        "- 4. 결과 비교: 직관적 성능 분석(토픽/키워드/문맥)\n",
        "- 5. 추가: 하이브리드 가중치/속도/stopwords 영향\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 설정 및 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kimjinseok/Desktop/metacode-lecture/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 0. 환경 설정 및 라이브러리\n",
        "# =========================\n",
        "\n",
        "# 표준 라이브러리\n",
        "import os, time, random\n",
        "from typing import List, Tuple\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# 수치/데이터/시각화\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 사이킷런\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction import text as sk_text\n",
        "\n",
        "# datasets / sentence-transformers (CPU 고정)\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*matmul.*\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Matplotlib: 한글 폰트 및 마이너스 기호 설정\n",
        "# -----------------------------------------\n",
        "plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# 재현성(시드) 고정\n",
        "# ------------------------\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ------------------------\n",
        "# 간단 타이머\n",
        "# ------------------------\n",
        "@contextmanager\n",
        "def timer(msg: str):\n",
        "    t0 = time.perf_counter()\n",
        "    yield\n",
        "    print(f\"[TIME] {msg}: {time.perf_counter() - t0:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 데이터 로드 및 corpus 생성 (AG News)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# AG News 서브셋 로더\n",
        "# ------------------------\n",
        "label_names: List[str] = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "\n",
        "def load_ag_news_subset(n_per_class: int = 200) -> Tuple[List[str], List[int]]:\n",
        "    \"\"\"\n",
        "    AG News에서 클래스별로 동일 개수(n_per_class)만큼 샘플을 추출해\n",
        "    텍스트 리스트(xs)와 정수 라벨 리스트(ys)를 반환합니다.\n",
        "\n",
        "    Args:\n",
        "        n_per_class (int): 각 클래스(0~3)에서 가져올 샘플 수. 기본 200.\n",
        "\n",
        "    Returns:\n",
        "        xs (List[str]): 뉴스 텍스트 리스트\n",
        "        ys (List[int]): 라벨 리스트 (0=World, 1=Sports, 2=Business, 3=Sci/Tech)\n",
        "    \"\"\"\n",
        "    # -------------------------\n",
        "    # 1) AG News train split 로드 (총 120k 샘플)\n",
        "    # -------------------------\n",
        "    ds = load_dataset(\"ag_news\", split=\"train\")\n",
        "\n",
        "    xs, ys = [], []\n",
        "\n",
        "    # -------------------------\n",
        "    # 2) 클래스별 균등 샘플링\n",
        "    #    - 라벨(0~3) 기준으로 필터링\n",
        "    #    - 앞에서 n_per_class개만 선택\n",
        "    #    - 필요 시 .shuffle(seed=42)로 무작위 추출 가능\n",
        "    # -------------------------\n",
        "    for lab in range(4):\n",
        "        sub = ds.filter(lambda ex: ex[\"label\"] == lab)\n",
        "        # sub = sub.shuffle(seed=42)  # 무작위 샘플이 필요하면 주석 해제\n",
        "        sub = sub.select(range(n_per_class))\n",
        "\n",
        "        # -------------------------\n",
        "        # 3) 결과 누적: 텍스트/라벨\n",
        "        # -------------------------\n",
        "        xs += [r[\"text\"] for r in sub]\n",
        "        ys += [int(r[\"label\"]) for r in sub]\n",
        "\n",
        "    # -------------------------\n",
        "    # 4) 반환\n",
        "    # -------------------------\n",
        "    return xs, ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIME] AG News 로드: 4.15s\n",
            "800 samples\n",
            "label_names: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
            "\n",
            "[클래스별 샘플 예시]\n",
            "[World] Venezuelans Vote Early in Referendum on Chavez Rule (Reuters) Reuters - Venezuelans turned out early\\and in large number...\n",
            "[World] S.Koreans Clash with Police on Iraq Troop Dispatch (Reuters) Reuters - South Korean police used water cannon in\\central ...\n",
            "[Sports] Phelps, Thorpe Advance in 200 Freestyle (AP) AP - Michael Phelps took care of qualifying for the Olympic 200-meter frees...\n",
            "[Sports] Reds Knock Padres Out of Wild-Card Lead (AP) AP - Wily Mo Pena homered twice and drove in four runs, helping the Cincinn...\n",
            "[Business] Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics,...\n",
            "[Business] Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\which has a reputat...\n",
            "[Sci/Tech] 'Madden,' 'ESPN' Football Score in Different Ways (Reuters) Reuters - Was absenteeism a little high\\on Tuesday among the...\n",
            "[Sci/Tech] Group to Propose New High-Speed Wireless Format (Reuters) Reuters - A group of technology companies\\including Texas Inst...\n"
          ]
        }
      ],
      "source": [
        "with timer(\"AG News 로드\"):\n",
        "    # 각 클래스에서 200개씩 불러와 텍스트/라벨 리스트 생성\n",
        "    # label_names: [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "    corpus_texts, corpus_labels = load_ag_news_subset(n_per_class=200)\n",
        "\n",
        "# 전체 샘플 수와 라벨 이름 확인\n",
        "print(len(corpus_texts), \"samples\")\n",
        "print(\"label_names:\", label_names)\n",
        "\n",
        "# -------------------------\n",
        "# 클래스별 샘플 예시 2개씩 출력\n",
        "# - shown 딕셔너리로 클래스별 출력 개수 제한(2개)\n",
        "# - 텍스트는 길수 있으므로 앞 120자만 미리보기 형태로 출력\n",
        "# -------------------------\n",
        "print(\"\\n[클래스별 샘플 예시]\")\n",
        "shown = {i: 0 for i in range(4)}  # 각 라벨별로 몇 개를 보여줬는지 카운트\n",
        "for t, lab in zip(corpus_texts, corpus_labels):\n",
        "    if shown[lab] < 2:\n",
        "        print(f\"[{label_names[lab]}] {str(t)[:120]}...\")\n",
        "        shown[lab] += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 임베딩 2가지: SBERT / TF‑IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# TF-IDF 인덱스 구축\n",
        "# ------------------------\n",
        "# stopwords: 영어 불용어 사용(키워드 매칭 과다 방지)\n",
        "stop_words = list(sk_text.ENGLISH_STOP_WORDS) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIME] TF-IDF fit_transform(corpus): 0.08s\n",
            "TF-IDF shape: (800, 21987)\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# TF-IDF 벡터화\n",
        "# -------------------------\n",
        "# - max_features=30000 : 전체 단어/바이그램 중 상위 3만 개만 사용(빈도 기준)\n",
        "# - ngram_range=(1, 2) : 유니그램과 바이그램을 함께 사용\n",
        "# - stop_words        : 불용어 리스트(예: 영어면 'english' 또는 커스텀 리스트)\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=30000,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words=stop_words\n",
        ")\n",
        "\n",
        "with timer(\"TF-IDF fit_transform(corpus)\"):\n",
        "    X_tfidf = vectorizer.fit_transform(corpus_texts)\n",
        "\n",
        "# 결과 차원: (문서 개수, 사용된 토큰 개수)\n",
        "print(\"TF-IDF shape:\", X_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# SBERT 임베딩 구축 (CPU)\n",
        "# ------------------------\n",
        "\n",
        "def sbert_encode(texts: List[str], batch_size: int = 64,\n",
        "                 model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Sentence-BERT 모델로 문장 임베딩을 생성합니다. (CPU 기본)\n",
        "    - encode()의 normalize_embeddings=False로 두고, 아래에서 수동 L2 정규화 수행\n",
        "    - NaN/Inf 방지도 함께 처리\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): 인코딩할 문장(문서) 리스트\n",
        "        batch_size (int): 배치 크기 (메모리/속도 트레이드오프)\n",
        "        model_name (str): sentence-transformers 허브 모델 이름\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: (N, D) 형태의 L2-정규화된 임베딩 배열 (float64)\n",
        "    \"\"\"\n",
        "    # 모델 로드 (CPU). GPU 사용 시 device=\"cuda\"로 변경 가능\n",
        "    model = SentenceTransformer(model_name, device=\"cpu\")\n",
        "\n",
        "    arrs = []\n",
        "    # 배치 단위로 순회\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        # convert_to_numpy=True: 바로 NumPy 배열 반환\n",
        "        # normalize_embeddings=False: 아래에서 직접 L2 정규화 예정\n",
        "        arr = model.encode(\n",
        "            texts[i:i+batch_size],\n",
        "            batch_size=batch_size,\n",
        "            show_progress_bar=False,\n",
        "            convert_to_numpy=True,\n",
        "            normalize_embeddings=False\n",
        "        ).astype(np.float64)\n",
        "\n",
        "        # ----- 안정적인 L2 정규화 -----\n",
        "        # 분모가 0이 되는 경우를 방지하기 위해 clip으로 하한선 설정\n",
        "        norms = np.linalg.norm(arr, axis=1, keepdims=True)\n",
        "        arr = arr / np.clip(norms, 1e-12, None)\n",
        "\n",
        "        # 숫자 안정성: NaN/±Inf → 0.0 치환\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        arrs.append(arr)\n",
        "\n",
        "    # 배치 결과를 하나의 (N, D) 배열로 결합\n",
        "    return np.vstack(arrs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIME] SBERT encode(corpus): 27.86s\n",
            "SBERT shape: (800, 384)\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# 실행: 코퍼스 임베딩 생성\n",
        "# -------------------------\n",
        "with timer(\"SBERT encode(corpus)\"):\n",
        "    # sbert_encode:\n",
        "    # - Sentence-BERT로 코퍼스의 각 문장을 D차원 임베딩으로 변환\n",
        "    X_sbert = sbert_encode(corpus_texts)\n",
        "\n",
        "# 임베딩 배열의 크기 출력 (예: (800, 384) → 800문서, 384차원 임베딩)\n",
        "print(\"SBERT shape:\", X_sbert.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 단일 질문 검색: TF‑IDF / SBERT / Hybrid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# 검색 함수 3종\n",
        "# ------------------------\n",
        "\n",
        "def search_tfidf(query: str, topk: int = 5):\n",
        "    \"\"\"\n",
        "    TF-IDF 기반 키워드 매칭 검색.\n",
        "    - vectorizer: 이미 fit된 TfidfVectorizer\n",
        "    - X_tfidf  : (N, V) CSR 희소행렬. 일반적으로 L2 정규화(norm='l2')가 기본.\n",
        "    - 코사인 유사도 기반으로 가장 유사한 문서 인덱스와 점수를 반환.\n",
        "\n",
        "    Args:\n",
        "        query (str): 질의문\n",
        "        topk (int): 상위 반환 개수\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[int, float]]: (문서 인덱스, 유사도 점수) 리스트\n",
        "    \"\"\"\n",
        "    # (1, V) sparse row\n",
        "    qv = vectorizer.transform([query])\n",
        "    # sparse 간 연산 지원. vectorizer가 L2 정규화했다면 linear_kernel로 대체 가능.\n",
        "    sims = cosine_similarity(qv, X_tfidf)[0]  # shape: (N,)\n",
        "    idx = np.argsort(-sims)[:topk]\n",
        "    \n",
        "    return [(int(i), float(sims[i])) for i in idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_sbert(query: str, topk: int = 5):\n",
        "    \"\"\"\n",
        "    SBERT(문장 임베딩) 기반语義 검색.\n",
        "    - sbert_encode: 내부에서 L2 정규화 수행 → 코사인 유사도 = 내적\n",
        "    - X_sbert     : (N, D) 실수 배열, 각 행은 단위벡터.\n",
        "\n",
        "    Args:\n",
        "        query (str): 질의문\n",
        "        topk (int): 상위 반환 개수\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[int, float]]: (문서 인덱스, 유사도 점수) 리스트\n",
        "    \"\"\"\n",
        "    # (1, D) 배열\n",
        "    qv = sbert_encode([query])           # 이미 L2 정규화된 단위벡터\n",
        "    sims = (X_sbert @ qv.T).ravel()      # 내적 = 코사인 유사도\n",
        "    idx = np.argsort(-sims)[:topk]\n",
        "    \n",
        "    return [(int(i), float(sims[i])) for i in idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_hybrid(query: str, topk: int = 5, alpha: float = 0.5):\n",
        "    \"\"\"\n",
        "    하이브리드 검색(TF-IDF + SBERT 가중 합).\n",
        "    - alpha=1.0이면 SBERT만, 0.0이면 TF-IDF만 사용.\n",
        "    - 서로 다른 점수 스케일을 단순 합산하므로, alpha는 데이터/도메인에 맞게 튜닝 권장.\n",
        "\n",
        "    Args:\n",
        "        query (str): 질의문\n",
        "        topk (int): 상위 반환 개수\n",
        "        alpha (float): SBERT 가중치 [0, 1]\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[int, float]]: (문서 인덱스, 하이브리드 점수) 리스트\n",
        "    \"\"\"\n",
        "    # TF-IDF 쿼리 벡터 및 유사도\n",
        "    qv_tfidf = vectorizer.transform([query])\n",
        "    sims_tfidf = cosine_similarity(qv_tfidf, X_tfidf)[0]\n",
        "\n",
        "    # SBERT 쿼리 벡터 및 유사도(내적=코사인)\n",
        "    qv_sbert = sbert_encode([query])\n",
        "    sims_sbert = (X_sbert @ qv_sbert.T).ravel()\n",
        "\n",
        "    # 가중 합\n",
        "    sims = alpha * sims_sbert + (1 - alpha) * sims_tfidf\n",
        "    idx = np.argsort(-sims)[:topk]\n",
        "    \n",
        "    return [(int(i), float(sims[i])) for i in idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"What is the impact of interest rate hikes on the stock market?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- (0.188) [Business] Veteran inventor in market float Trevor Baylis, the veteran inventor famous for creating the Freeplay clockwork radio, is planning to float his company on the stock market.\n",
            "- (0.180) [Business] In a Down Market, Head Toward Value Funds There is little cause for celebration in the stock market these days, but investors in value-focused mutual funds have reason to feel a bit smug -- if only because they've lost less than the folks who stuck with growth.\n",
            "- (0.172) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
            "- (0.172) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market this week during the depth of the\\summer doldrums.\n",
            "- (0.170) [Business] Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market this week during the depth of the  summer doldrums.\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# 단일 고정 질의(지시 사항대로)\n",
        "# ------------------------\n",
        "#\n",
        "\n",
        "# 결과 수집 리스트\n",
        "rows_tfidf, rows_sbert, rows_hybrid = [], [], []\n",
        "\n",
        "# ------------------------\n",
        "# TF-IDF 검색 및 결과 수집\n",
        "# ------------------------\n",
        "# search_tfidf(query, topk=5) → [(문서인덱스, 유사도점수), ...]\n",
        "for k, (i, s) in enumerate(search_tfidf(query, topk=5), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_tfidf.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- (0.458) [World] Election-Year Rate Hike Puzzles Some WASHINGTON - Going against conventional wisdom, the Federal Reserve is raising interest rates in an election year. And it is Fed Chairman Alan Greenspan, a Republican, who is leading the charge even though an incumbent Republican in the White House is facing voter unrest about the state of the economy...\n",
            "- (0.434) [Business] South Korea lowers interest rates South Korea's central bank cuts interest rates by a quarter percentage point to 3.5 in a bid to drive growth in the economy.\n",
            "- (0.396) [Business] Stocks Higher on Oil Price Relief (Reuters) Reuters - U.S. stocks gained on Monday, getting\\a boost from lower oil prices after news the Venezuelan\\president survived a recall eased fears about the country's oil\\exports.\n",
            "- (0.374) [Business] Will Schwab Reward Patience? The company saw an improvement in its trades, but will this market be kind to the brokerages?\n",
            "- (0.373) [World] Stocks Higher Despite Soaring Oil Prices NEW YORK - Wall Street shifted higher Monday as bargain hunters shrugged off skyrocketing oil prices and bought shares following an upbeat sales report from Wal-Mart Stores and a bright outlook from Lowe's.    The Dow Jones industrial average was up 84.07, or 0.9 percent, at 9,909.42, after edging 0.1 percent higher last week...\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# SBERT 검색 및 결과 수집\n",
        "# ------------------------\n",
        "# search_sbert(query, topk=5) → [(문서인덱스, 코사인유사도), ...]\n",
        "for k, (i, s) in enumerate(search_sbert(query, topk=5), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_sbert.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- (0.298) [World] Election-Year Rate Hike Puzzles Some WASHINGTON - Going against conventional wisdom, the Federal Reserve is raising interest rates in an election year. And it is Fed Chairman Alan Greenspan, a Republican, who is leading the charge even though an incumbent Republican in the White House is facing voter unrest about the state of the economy...\n",
            "- (0.282) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
            "- (0.279) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market this week during the depth of the\\summer doldrums.\n",
            "- (0.270) [Business] Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market next week during the depth of the  summer doldrums.\n",
            "- (0.270) [Business] Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market this week during the depth of the  summer doldrums.\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# Hybrid 검색 및 결과 수집\n",
        "# ------------------------\n",
        "# search_hybrid(query, topk=5, alpha=0.6)\n",
        "# - alpha: SBERT 가중치(0~1). 1.0=SBERT만, 0.0=TF-IDF만\n",
        "for k, (i, s) in enumerate(search_hybrid(query, topk=5, alpha=0.6), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_hybrid.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# CSV 저장 (각각)\n",
        "# ------------------------\n",
        "# - 출력 경로: ./outputs/\n",
        "# - 인코딩: UTF-8 (엑셀에서 바로 열 때는 'utf-8-sig'도 고려)\n",
        "out = os.path.join(os.path.abspath(\".\"), \"outputs\")\n",
        "os.makedirs(out, exist_ok=True)\n",
        "\n",
        "pd.DataFrame(rows_tfidf).to_csv(os.path.join(out, \"tfidf_top5.csv\"),\n",
        "                                index=False, encoding=\"utf-8\")\n",
        "pd.DataFrame(rows_sbert).to_csv(os.path.join(out, \"sbert_top5.csv\"),\n",
        "                                index=False, encoding=\"utf-8\")\n",
        "pd.DataFrame(rows_hybrid).to_csv(os.path.join(out, \"hybrid_top5.csv\"),\n",
        "                                 index=False, encoding=\"utf-8\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 결과 비교: 직관적 성능 분석(토픽/키워드/문맥)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TF-IDF Top-5]\n",
            " 1. (0.188) [Business] Veteran inventor in market float Trevor Baylis, the veteran inventor famous for creating the Freeplay clockwork radio, is planning to float his company on the stock market.\n",
            " 2. (0.180) [Business] In a Down Market, Head Toward Value Funds There is little cause for celebration in the stock market these days, but investors in value-focused mutual funds have reason to feel a bit smug -- if only because they've lost less than the folks who stuck with growth.\n",
            " 3. (0.172) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
            " 4. (0.172) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market this week during the depth of the\\summer doldrums.\n",
            " 5. (0.170) [Business] Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market this week during the depth of the  summer doldrums.\n",
            "\n",
            "[SBERT Top-5]\n",
            " 1. (0.458) [World] Election-Year Rate Hike Puzzles Some WASHINGTON - Going against conventional wisdom, the Federal Reserve is raising interest rates in an election year. And it is Fed Chairman Alan Greenspan, a Republican, who is leading the charge even though an incumbent Republican in the White House is facing voter unrest about the state of the economy...\n",
            " 2. (0.434) [Business] South Korea lowers interest rates South Korea's central bank cuts interest rates by a quarter percentage point to 3.5 in a bid to drive growth in the economy.\n",
            " 3. (0.396) [Business] Stocks Higher on Oil Price Relief (Reuters) Reuters - U.S. stocks gained on Monday, getting\\a boost from lower oil prices after news the Venezuelan\\president survived a recall eased fears about the country's oil\\exports.\n",
            " 4. (0.374) [Business] Will Schwab Reward Patience? The company saw an improvement in its trades, but will this market be kind to the brokerages?\n",
            " 5. (0.373) [World] Stocks Higher Despite Soaring Oil Prices NEW YORK - Wall Street shifted higher Monday as bargain hunters shrugged off skyrocketing oil prices and bought shares following an upbeat sales report from Wal-Mart Stores and a bright outlook from Lowe's.    The Dow Jones industrial average was up 84.07, or 0.9 percent, at 9,909.42, after edging 0.1 percent higher last week...\n",
            "\n",
            "[Hybrid(0.6) Top-5]\n",
            " 1. (0.298) [World] Election-Year Rate Hike Puzzles Some WASHINGTON - Going against conventional wisdom, the Federal Reserve is raising interest rates in an election year. And it is Fed Chairman Alan Greenspan, a Republican, who is leading the charge even though an incumbent Republican in the White House is facing voter unrest about the state of the economy...\n",
            " 2. (0.282) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
            " 3. (0.279) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market this week during the depth of the\\summer doldrums.\n",
            " 4. (0.270) [Business] Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market next week during the depth of the  summer doldrums.\n",
            " 5. (0.270) [Business] Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market this week during the depth of the  summer doldrums.\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# 비교용 테이블/프린트\n",
        "# ------------------------\n",
        "\n",
        "def show_results(title: str, pairs):\n",
        "    \"\"\"\n",
        "    검색 결과 목록을 깔끔하게 프린트하는 유틸\n",
        "    Args:\n",
        "        title (str): 섹션 제목\n",
        "        pairs (List[Tuple[int, float]]): (문서 인덱스, 점수) 리스트\n",
        "    \"\"\"\n",
        "    print(f\"\\n[{title}]\")\n",
        "    for rank, (i, s) in enumerate(pairs, start=1):\n",
        "        # 줄바꿈 제거 + 앞부분만 미리보기\n",
        "        txt = corpus_texts[i].replace(\"\\n\", \" \")\n",
        "        print(f\"{rank:>2}. ({s:.3f}) [{label_names[corpus_labels[i]]}] {txt}\")\n",
        "\n",
        "# 각 검색기에서 상위 5개 문서 인덱스/점수 가져오기\n",
        "r_tfidf = search_tfidf(query, topk=5)\n",
        "r_sbert = search_sbert(query, topk=5)\n",
        "r_hybrid = search_hybrid(query, topk=5, alpha=0.6)  # SBERT 가중치 0.6\n",
        "\n",
        "# 결과 프린트\n",
        "show_results(\"TF-IDF Top-5\", r_tfidf)\n",
        "show_results(\"SBERT Top-5\", r_sbert)\n",
        "show_results(\"Hybrid(0.6) Top-5\", r_hybrid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[레이블 빈도 비교]\n",
            "TF-IDF {'Business': 5}\n",
            "SBERT {'World': 2, 'Business': 3}\n",
            "Hybrid {'World': 1, 'Business': 4}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ------------------------\n",
        "# 간단한 직관 비교: 레이블 빈도\n",
        "# ------------------------\n",
        "from collections import Counter\n",
        "\n",
        "def label_counts(pairs):\n",
        "    \"\"\"\n",
        "    (문서 인덱스, 점수) 리스트 → 레이블명 카운트 딕셔너리\n",
        "    \"\"\"\n",
        "    return Counter([label_names[corpus_labels[i]] for i, _ in pairs])\n",
        "\n",
        "print(\"\\n[레이블 빈도 비교]\")\n",
        "for name, pairs in [(\"TF-IDF\", r_tfidf), (\"SBERT\", r_sbert), (\"Hybrid\", r_hybrid)]:\n",
        "    print(name, dict(label_counts(pairs)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------\n",
        "# CSV 저장 (r_* 바로 직렬화)\n",
        "# ------------------------\n",
        "# - rank/score/doc_id/label/text 컬럼으로 저장\n",
        "# - 엑셀 호환이 필요하면 encoding=\"utf-8-sig\" 권장\n",
        "rows_tfidf  = [{\"rank\": k, \"score\": float(s), \"doc_id\": int(i),\n",
        "                \"label\": label_names[corpus_labels[i]], \"text\": corpus_texts[i]}\n",
        "               for k, (i, s) in enumerate(r_tfidf, start=1)]\n",
        "rows_sbert  = [{\"rank\": k, \"score\": float(s), \"doc_id\": int(i),\n",
        "                \"label\": label_names[corpus_labels[i]], \"text\": corpus_texts[i]}\n",
        "               for k, (i, s) in enumerate(r_sbert, start=1)]\n",
        "rows_hybrid = [{\"rank\": k, \"score\": float(s), \"doc_id\": int(i),\n",
        "                \"label\": label_names[corpus_labels[i]], \"text\": corpus_texts[i]}\n",
        "               for k, (i, s) in enumerate(r_hybrid, start=1)]\n",
        "\n",
        "out = os.path.join(os.path.abspath(\".\"), \"outputs\")\n",
        "os.makedirs(out, exist_ok=True)\n",
        "\n",
        "pd.DataFrame(rows_tfidf ).to_csv(os.path.join(out, \"tfidf_top5_cell14.csv\" ), index=False, encoding=\"utf-8\")\n",
        "pd.DataFrame(rows_sbert ).to_csv(os.path.join(out, \"sbert_top5_cell14.csv\" ), index=False, encoding=\"utf-8\")\n",
        "pd.DataFrame(rows_hybrid).to_csv(os.path.join(out, \"hybrid_top5_cell14.csv\"), index=False, encoding=\"utf-8\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 추가: 하이브리드 가중치/속도/stopwords 영향\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alpha=0.0 -> ['Business', 'Business', 'Business', 'Business', 'Business']\n",
            "alpha=0.3 -> ['Business', 'Business', 'Business', 'Business', 'Business']\n",
            "alpha=0.6 -> ['World', 'Business', 'Business', 'Business', 'Business']\n",
            "alpha=0.9 -> ['World', 'Business', 'Business', 'Business', 'Business']\n",
            "alpha=1.0 -> ['World', 'Business', 'Business', 'Business', 'World']\n",
            "[TIME] TF-IDF 질의 시간: 0.00s\n",
            "[TIME] SBERT 질의 시간: 2.33s\n",
            "[TIME] Hybrid(alpha=0.6) 질의 시간: 2.26s\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# 하이브리드 가중치 변화 예시\n",
        "# ------------------------\n",
        "# - search_hybrid: alpha ∈ [0,1]에서 SBERT vs TF-IDF 비중을 조절\n",
        "#   alpha=1.0 → SBERT 100%, alpha=0.0 → TF-IDF 100%\n",
        "# - 상위 5개 문서의 라벨 분포가 alpha 변화에 따라 어떻게 달라지는지 직관적으로 확인\n",
        "for a in [0.0, 0.3, 0.6, 0.9, 1.0]:\n",
        "    pairs = search_hybrid(query, topk=5, alpha=a)\n",
        "    top_labels = [label_names[corpus_labels[i]] for i, _ in pairs]\n",
        "    print(f\"alpha={a:.1f} -> {top_labels}\")\n",
        "\n",
        "# ------------------------\n",
        "# 속도 비교\n",
        "# ------------------------\n",
        "# - timer: 사용자 정의 컨텍스트 매니저(벽시계 시간 측정)라고 가정\n",
        "# - 유의: SBERT는 최초 호출 시 모델 로드/웨이트 준비로 인해 첫 타이밍이 더 느릴 수 있음(콜드 스타트).\n",
        "#         공정한 비교를 원하면 워밍업 쿼리를 1~2회 먼저 실행하세요.\n",
        "with timer(\"TF-IDF 질의 시간\"):\n",
        "    _ = search_tfidf(query, topk=10)\n",
        "\n",
        "with timer(\"SBERT 질의 시간\"):\n",
        "    _ = search_sbert(query, topk=10)\n",
        "\n",
        "with timer(\"Hybrid(alpha=0.6) 질의 시간\"):\n",
        "    _ = search_hybrid(query, topk=10, alpha=0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIME] TF-IDF(no stopwords) fit_transform: 0.15s\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# stopwords 영향: 불용어 제거 on/off 비교\n",
        "# ------------------------\n",
        "# - 기존 vectorizer는 stop_words=stop_words로 설정되어 있다고 가정\n",
        "# - 아래는 불용어 제거를 하지 않는 대안 벡터라이저를 만들어 성능 차이를 관찰\n",
        "# - 주의: ngram_range=(1,2), max_features=30000은 메모리/시간 트레이드오프가 큼\n",
        "alt_vectorizer = TfidfVectorizer(\n",
        "    max_features=30000,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words=None   # 불용어 제거 없음\n",
        ")\n",
        "\n",
        "with timer(\"TF-IDF(no stopwords) fit_transform\"):\n",
        "    # 같은 코퍼스에 대해 새로운 어휘 사전과 TF-IDF 행렬을 학습/생성\n",
        "    X_tfidf_raw = alt_vectorizer.fit_transform(corpus_texts)\n",
        "\n",
        "def search_tfidf_raw(q: str, topk: int = 5):\n",
        "    \"\"\"\n",
        "    불용어 제거를 하지 않은 대안 벡터라이저(alt_vectorizer)로 검색.\n",
        "    Returns: [(문서 인덱스, 코사인 유사도), ...]\n",
        "    \"\"\"\n",
        "    qv = alt_vectorizer.transform([q])\n",
        "    sims = cosine_similarity(qv, X_tfidf_raw)[0]\n",
        "    idx = np.argsort(-sims)[:topk]\n",
        "    return [(int(i), float(sims[i])) for i in idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TF-IDF(stopwords) vs TF-IDF(raw) 비교]\n",
            "- with stopwords:\n",
            "  (0.188) [Business] Veteran inventor in market float Trevor Baylis, the veteran inventor famous for creating the Freepla...\n",
            "  (0.180) [Business] In a Down Market, Head Toward Value Funds There is little cause for celebration in the stock market ...\n",
            "  (0.172) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about th...\n",
            "- no stopwords:\n",
            "  (0.179) [Business] Hungarian central bank cuts key interest rate by half percentage point (AFP) AFP - The Hungarian cen...\n",
            "  (0.157) [Business] Veteran inventor in market float Trevor Baylis, the veteran inventor famous for creating the Freepla...\n",
            "  (0.132) [Business] Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about th...\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# 결과 비교 출력\n",
        "# ------------------------\n",
        "# - 같은 질의에 대해 stopwords 사용/미사용의 상위 문서가 어떻게 달라지는지 비교\n",
        "print(\"\\n[TF-IDF(stopwords) vs TF-IDF(raw) 비교]\")\n",
        "print(\"- with stopwords:\")\n",
        "for i, s in search_tfidf(query, topk=3):\n",
        "    print(f\"  ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i][:100]}...\")\n",
        "\n",
        "print(\"- no stopwords:\")\n",
        "for i, s in search_tfidf_raw(query, topk=3):\n",
        "    print(f\"  ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i][:100]}...\")\n",
        "\n",
        "# 참고:\n",
        "# - 속도 비교는 단일 실행(run) 결과이므로 변동성 있음 → timeit/반복 평균을 쓰면 더 신뢰도 높음.\n",
        "# - Hybrid 점수는 스케일 차이의 영향을 받을 수 있음 → 필요 시 각 점수를 MinMax/Z-score로 정규화 후 합산.\n",
        "# - 공정 비교를 위해 전처리(토큰화/소문자화/stemming 등)는 동일하게 유지하는 것이 좋음.\n",
        "# - 매우 긴 문서/질의가 섞이면 TF-IDF는 길이 보정(sublinear_tf=True 등), SBERT는 문장 길이 분포에 주의.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
