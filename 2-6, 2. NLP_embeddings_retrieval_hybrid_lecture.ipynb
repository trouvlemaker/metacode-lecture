{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-6, 2강 NLP 임베딩 기반 검색 — TF‑IDF vs SBERT vs Hybrid (CPU)\n",
        "\n",
        "- 목표: 의미/키워드 검색 방식을 비교하고, 하이브리드로 직관적 성능 차이를 체감\n",
        "- 제약: CPU 전용 환경(훈련/추론 모두 CPU)\n",
        "- 데이터: AG News 코퍼스(소규모 서브셋)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 구성 (Overview)\n",
        "- 데이터 로드 및 corpus 생성 → 임베딩 (SBERT, TF‑IDF) → 질문 검색 (TF‑IDF / SBERT / Hybrid) → 결과 비교: 직관적 성능 분석(토픽/키워드/문맥)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 설정 및 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 0. 환경 설정 및 라이브러리\n",
        "# =========================\n",
        "\n",
        "# 표준 라이브러리\n",
        "import os, time, random\n",
        "from typing import List, Tuple\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# 수치/데이터/시각화\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 사이킷런\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction import text as sk_text\n",
        "\n",
        "# datasets / sentence-transformers (CPU 고정)\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*matmul.*\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Matplotlib: 한글 폰트 및 마이너스 기호 설정\n",
        "# -----------------------------------------\n",
        "plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# 재현성(시드) 고정\n",
        "# ------------------------\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ------------------------\n",
        "# 간단 타이머\n",
        "# ------------------------\n",
        "@contextmanager\n",
        "def timer(msg: str):\n",
        "    t0 = time.perf_counter()\n",
        "    yield\n",
        "    print(f\"[TIME] {msg}: {time.perf_counter() - t0:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 데이터 로드 및 corpus 생성 (AG News)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# AG News 서브셋 로더\n",
        "# ------------------------\n",
        "label_names: List[str] = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "\n",
        "def load_ag_news_subset(n_per_class: int = 200) -> Tuple[List[str], List[int]]:\n",
        "    \"\"\"\n",
        "    AG News에서 클래스별로 동일 개수(n_per_class)만큼 샘플을 추출해\n",
        "    텍스트 리스트(xs)와 정수 라벨 리스트(ys)를 반환합니다.\n",
        "\n",
        "    Args:\n",
        "        n_per_class (int): 각 클래스(0~3)에서 가져올 샘플 수. 기본 200.\n",
        "\n",
        "    Returns:\n",
        "        xs (List[str]): 뉴스 텍스트 리스트\n",
        "        ys (List[int]): 라벨 리스트 (0=World, 1=Sports, 2=Business, 3=Sci/Tech)\n",
        "    \"\"\"\n",
        "    # -------------------------\n",
        "    # 1) AG News train split 로드 (총 120k 샘플)\n",
        "    # -------------------------\n",
        "    ds = load_dataset(\"ag_news\", split=\"train\")\n",
        "\n",
        "    xs, ys = [], []\n",
        "\n",
        "    # -------------------------\n",
        "    # 2) 클래스별 균등 샘플링\n",
        "    #    - 라벨(0~3) 기준으로 필터링\n",
        "    #    - 앞에서 n_per_class개만 선택\n",
        "    # -------------------------\n",
        "    for lab in range(4):\n",
        "        sub = ds.filter(lambda ex: ex[\"label\"] == lab)\n",
        "        sub = sub.select(range(n_per_class))\n",
        "\n",
        "        xs += [r[\"text\"] for r in sub]\n",
        "        ys += [int(r[\"label\"]) for r in sub]\n",
        "        \n",
        "    return xs, ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with timer(\"AG News 로드\"):\n",
        "    # 각 클래스에서 200개씩 불러와 텍스트/라벨 리스트 생성\n",
        "    # label_names: [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "    corpus_texts, corpus_labels = load_ag_news_subset(n_per_class=200)\n",
        "\n",
        "# 전체 샘플 수와 라벨 이름 확인\n",
        "print(len(corpus_texts), \"samples\")\n",
        "print(\"label_names:\", label_names)\n",
        "\n",
        "# -------------------------\n",
        "# 클래스별 샘플 예시 2개씩 출력\n",
        "# - shown 딕셔너리로 클래스별 출력 개수 제한(2개)\n",
        "# - 텍스트는 길수 있으므로 앞 120자만 미리보기 형태로 출력\n",
        "# -------------------------\n",
        "print(\"\\n[클래스별 샘플 예시]\")\n",
        "shown = {i: 0 for i in range(4)}  # 각 라벨별로 몇 개를 보여줬는지 카운트\n",
        "for t, lab in zip(corpus_texts, corpus_labels):\n",
        "    if shown[lab] < 2:\n",
        "        print(f\"[{label_names[lab]}] {str(t)[:120]}...\")\n",
        "        shown[lab] += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 임베딩 2가지: SBERT / TF‑IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# TF-IDF 인덱스 구축\n",
        "# ------------------------\n",
        "# stopwords: 영어 불용어 사용(키워드 매칭 과다 방지)\n",
        "stop_words = list(sk_text.ENGLISH_STOP_WORDS) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# TF-IDF 벡터화\n",
        "# -------------------------\n",
        "# - max_features=30000 : 전체 단어/바이그램 중 상위 3만 개만 사용(빈도 기준)\n",
        "# - ngram_range=(1, 2) : 유니그램과 바이그램을 함께 사용\n",
        "# - stop_words        : 불용어 리스트(예: 영어면 'english' 또는 커스텀 리스트)\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=30000,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words=stop_words\n",
        ")\n",
        "\n",
        "with timer(\"TF-IDF fit_transform(corpus)\"):\n",
        "    X_tfidf = vectorizer.fit_transform(corpus_texts)\n",
        "\n",
        "# 결과 차원: (문서 개수, 사용된 토큰 개수)\n",
        "print(\"TF-IDF shape:\", X_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# SBERT 임베딩 구축 (CPU)\n",
        "# ------------------------\n",
        "\n",
        "def sbert_encode(texts: List[str], batch_size: int = 64,\n",
        "                 model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Sentence-BERT 모델로 문장 임베딩을 생성합니다. (CPU 기본)\n",
        "    - encode()의 normalize_embeddings=False로 두고, 아래에서 수동 L2 정규화 수행\n",
        "    - NaN/Inf 방지도 함께 처리\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): 인코딩할 문장(문서) 리스트\n",
        "        batch_size (int): 배치 크기 (메모리/속도 트레이드오프)\n",
        "        model_name (str): sentence-transformers 허브 모델 이름\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: (N, D) 형태의 L2-정규화된 임베딩 배열 (float64)\n",
        "    \"\"\"\n",
        "    # 모델 로드 (CPU). GPU 사용 시 device=\"cuda\"로 변경 가능\n",
        "    model = SentenceTransformer(model_name, device=\"cpu\")\n",
        "\n",
        "    arrs = []\n",
        "    # 배치 단위로 순회\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        # convert_to_numpy=True: 바로 NumPy 배열 반환\n",
        "        # normalize_embeddings=False: 아래에서 직접 L2 정규화 예정\n",
        "        arr = model.encode(\n",
        "            texts[i:i+batch_size],\n",
        "            batch_size=batch_size,\n",
        "            show_progress_bar=False,\n",
        "            convert_to_numpy=True,\n",
        "            normalize_embeddings=False\n",
        "        ).astype(np.float64)\n",
        "\n",
        "        # ----- 안정적인 L2 정규화 -----\n",
        "        # 분모가 0이 되는 경우를 방지하기 위해 clip으로 하한선 설정\n",
        "        norms = np.linalg.norm(arr, axis=1, keepdims=True)\n",
        "        arr = arr / np.clip(norms, 1e-12, None)\n",
        "\n",
        "        # 숫자 안정성: NaN/±Inf → 0.0 치환\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        arrs.append(arr)\n",
        "\n",
        "    # 배치 결과를 하나의 (N, D) 배열로 결합\n",
        "    return np.vstack(arrs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# 실행: 코퍼스 임베딩 생성\n",
        "# -------------------------\n",
        "with timer(\"SBERT encode(corpus)\"):\n",
        "    # sbert_encode:\n",
        "    # - Sentence-BERT로 코퍼스의 각 문장을 D차원 임베딩으로 변환\n",
        "    X_sbert = sbert_encode(corpus_texts)\n",
        "\n",
        "# 임베딩 배열의 크기 출력 (예: (800, 384) → 800문서, 384차원 임베딩)\n",
        "print(\"SBERT shape:\", X_sbert.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 단일 질문 검색: TF‑IDF / SBERT / Hybrid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# 검색 함수 3종\n",
        "# ------------------------\n",
        "\n",
        "def search_tfidf(query: str, topk: int = 5):\n",
        "    \"\"\"\n",
        "    TF-IDF 기반 키워드 매칭 검색.\n",
        "    - vectorizer: 이미 fit된 TfidfVectorizer\n",
        "    - X_tfidf  : (N, V) CSR 희소행렬. 일반적으로 L2 정규화(norm='l2')가 기본.\n",
        "    - 코사인 유사도 기반으로 가장 유사한 문서 인덱스와 점수를 반환.\n",
        "\n",
        "    Args:\n",
        "        query (str): 질의문\n",
        "        topk (int): 상위 반환 개수\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[int, float]]: (문서 인덱스, 유사도 점수) 리스트\n",
        "    \"\"\"\n",
        "    # (1, V) sparse row\n",
        "    qv = vectorizer.transform([query])\n",
        "    # sparse 간 연산 지원. vectorizer가 L2 정규화했다면 linear_kernel로 대체 가능.\n",
        "    sims = cosine_similarity(qv, X_tfidf)[0]  # shape: (N,)\n",
        "    idx = np.argsort(-sims)[:topk]\n",
        "    \n",
        "    return [(int(i), float(sims[i])) for i in idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_sbert(query: str, topk: int = 5):\n",
        "    \"\"\"\n",
        "    SBERT(문장 임베딩) 기반 [유사의미] 검색.\n",
        "    - sbert_encode: 내부에서 L2 정규화 수행 → 코사인 유사도 = 내적\n",
        "    - X_sbert     : (N, D) 실수 배열, 각 행은 단위벡터.\n",
        "\n",
        "    Args:\n",
        "        query (str): 질의문\n",
        "        topk (int): 상위 반환 개수\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[int, float]]: (문서 인덱스, 유사도 점수) 리스트\n",
        "    \"\"\"\n",
        "    # (1, D) 배열\n",
        "    qv = sbert_encode([query])           # 이미 L2 정규화된 단위벡터\n",
        "    sims = (X_sbert @ qv.T).ravel()      # 내적 = 코사인 유사도\n",
        "    idx = np.argsort(-sims)[:topk]\n",
        "    \n",
        "    return [(int(i), float(sims[i])) for i in idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_hybrid(query: str, topk: int = 5, alpha: float = 0.5):\n",
        "    \"\"\"\n",
        "    하이브리드 검색(TF-IDF + SBERT 가중 합).\n",
        "    - alpha=1.0이면 SBERT만, 0.0이면 TF-IDF만 사용.\n",
        "    - 서로 다른 점수 스케일을 단순 합산하므로, alpha는 데이터/도메인에 맞게 튜닝 권장.\n",
        "\n",
        "    Args:\n",
        "        query (str): 질의문\n",
        "        topk (int): 상위 반환 개수\n",
        "        alpha (float): SBERT 가중치 [0, 1]\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[int, float]]: (문서 인덱스, 하이브리드 점수) 리스트\n",
        "    \"\"\"\n",
        "    # TF-IDF 쿼리 벡터 및 유사도\n",
        "    qv_tfidf = vectorizer.transform([query])\n",
        "    sims_tfidf = cosine_similarity(qv_tfidf, X_tfidf)[0]\n",
        "\n",
        "    # SBERT 쿼리 벡터 및 유사도(내적=코사인)\n",
        "    qv_sbert = sbert_encode([query])\n",
        "    sims_sbert = (X_sbert @ qv_sbert.T).ravel()\n",
        "\n",
        "    # 가중 합\n",
        "    sims = alpha * sims_sbert + (1 - alpha) * sims_tfidf\n",
        "    idx = np.argsort(-sims)[:topk]\n",
        "    \n",
        "    return [(int(i), float(sims[i])) for i in idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"What is the impact of interest rate hikes on the stock market?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# 질의에 대한 검색 및 결과 출력\n",
        "# ------------------------\n",
        "#\n",
        "\n",
        "# 결과 수집 리스트\n",
        "rows_tfidf, rows_sbert, rows_hybrid = [], [], []\n",
        "\n",
        "# ------------------------\n",
        "# TF-IDF 검색 및 결과 수집\n",
        "# ------------------------\n",
        "# search_tfidf(query, topk=5) → [(문서인덱스, 유사도점수), ...]\n",
        "for k, (i, s) in enumerate(search_tfidf(query, topk=5), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_tfidf.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# SBERT 검색 및 결과 수집\n",
        "# ------------------------\n",
        "# search_sbert(query, topk=5) → [(문서인덱스, 코사인유사도), ...]\n",
        "for k, (i, s) in enumerate(search_sbert(query, topk=5), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_sbert.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# Hybrid 검색 및 결과 수집\n",
        "# ------------------------\n",
        "# search_hybrid(query, topk=5, alpha=0.6)\n",
        "# - alpha: SBERT 가중치(0~1). 1.0=SBERT만, 0.0=TF-IDF만\n",
        "for k, (i, s) in enumerate(search_hybrid(query, topk=5, alpha=0.6), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_hybrid.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"what kind of techninal skill is important to get a job?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 수집 리스트\n",
        "rows_tfidf, rows_sbert, rows_hybrid = [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k, (i, s) in enumerate(search_tfidf(query, topk=5), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_tfidf.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k, (i, s) in enumerate(search_sbert(query, topk=5), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_sbert.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k, (i, s) in enumerate(search_hybrid(query, topk=5), start=1):\n",
        "    print(f\"- ({s:.3f}) [{label_names[corpus_labels[i]]}] {corpus_texts[i]}\")\n",
        "    rows_hybrid.append({\n",
        "        \"rank\": k,\n",
        "        \"score\": float(s),\n",
        "        \"doc_id\": int(i),\n",
        "        \"label\": label_names[corpus_labels[i]],\n",
        "        \"text\": corpus_texts[i]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# CSV 저장 (각각)\n",
        "# ------------------------\n",
        "# - 출력 경로: ./outputs/\n",
        "# - 인코딩: UTF-8 (엑셀에서 바로 열 때는 'utf-8-sig'도 고려)\n",
        "out = os.path.join(os.path.abspath(\".\"), \"data\")\n",
        "os.makedirs(out, exist_ok=True)\n",
        "\n",
        "pd.DataFrame(rows_tfidf).to_csv(os.path.join(out, \"./nlp/tfidf_top5.csv\"),\n",
        "                                index=False, encoding=\"utf-8\")\n",
        "pd.DataFrame(rows_sbert).to_csv(os.path.join(out, \"./nlp/sbert_top5.csv\"),\n",
        "                                index=False, encoding=\"utf-8\")\n",
        "pd.DataFrame(rows_hybrid).to_csv(os.path.join(out, \"./nlp/hybrid_top5.csv\"),\n",
        "                                 index=False, encoding=\"utf-8\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 결과 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# 비교용 테이블/프린트\n",
        "# ------------------------\n",
        "\n",
        "def show_results(title: str, pairs):\n",
        "    \"\"\"\n",
        "    검색 결과 목록을 깔끔하게 프린트하는 유틸\n",
        "    Args:\n",
        "        title (str): 섹션 제목\n",
        "        pairs (List[Tuple[int, float]]): (문서 인덱스, 점수) 리스트\n",
        "    \"\"\"\n",
        "    print(f\"\\n[{title}]\")\n",
        "    for rank, (i, s) in enumerate(pairs, start=1):\n",
        "        # 줄바꿈 제거 + 앞부분만 미리보기\n",
        "        txt = corpus_texts[i].replace(\"\\n\", \" \")\n",
        "        print(f\"{rank:>2}. ({s:.3f}) [{label_names[corpus_labels[i]]}] {txt}\")\n",
        "\n",
        "# 각 검색기에서 상위 5개 문서 인덱스/점수 가져오기\n",
        "r_tfidf = search_tfidf(query, topk=5)\n",
        "r_sbert = search_sbert(query, topk=5)\n",
        "r_hybrid = search_hybrid(query, topk=5, alpha=0.6)  # SBERT 가중치 0.6\n",
        "\n",
        "# 결과 프린트\n",
        "show_results(\"TF-IDF Top-5\", r_tfidf)\n",
        "show_results(\"SBERT Top-5\", r_sbert)\n",
        "show_results(\"Hybrid(0.6) Top-5\", r_hybrid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# 간단한 직관 비교: 레이블 빈도\n",
        "# ------------------------\n",
        "from collections import Counter\n",
        "\n",
        "def label_counts(pairs):\n",
        "    \"\"\"\n",
        "    (문서 인덱스, 점수) 리스트 → 레이블명 카운트 딕셔너리\n",
        "    \"\"\"\n",
        "    return Counter([label_names[corpus_labels[i]] for i, _ in pairs])\n",
        "\n",
        "print(\"\\n[레이블 빈도 비교]\")\n",
        "for name, pairs in [(\"TF-IDF\", r_tfidf), (\"SBERT\", r_sbert), (\"Hybrid\", r_hybrid)]:\n",
        "    print(name, dict(label_counts(pairs)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# 문맥 번역 비교 : 번역 내용 비교\n",
        "# ------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os                           # 환경변수 접근(os.getenv) 및 경로 검사(os.path.exists)용\n",
        "from dotenv import load_dotenv      # .env 파일을 읽어 환경변수로 로드\n",
        "from google.oauth2 import service_account  # 서비스 계정 기반 Credentials 생성을 위한 모듈\n",
        "from google.cloud import translate_v2 as translate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 번역 클라이언트 생성\n",
        "def make_translate_client():\n",
        "    cred_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
        "    if cred_path and os.path.exists(cred_path):\n",
        "        creds = service_account.Credentials.from_service_account_file(cred_path)\n",
        "        return translate.Client(credentials=creds)\n",
        "    return translate.Client() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import html\n",
        "\n",
        "def translate_text(text: str, target_lang: str, source_lang: str | None = None) -> str:\n",
        "\n",
        "    client = make_translate_client()\n",
        "    resp = client.translate(text, target_language=target_lang, source_language=source_lang)\n",
        "    # v2 API는 HTML-escaped 문자열을 반환하므로 unescape, 이상한 발음/기호 낭독 방지\n",
        "    return html.unescape(resp[\"translatedText\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV 파일 경로\n",
        "input_file = \"./data/nlp/tfidf_top5.csv\"\n",
        "output_file = \"./data/nlp/tfidf_top5_translated.csv\"\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# text 컬럼 번역\n",
        "df['translated_text'] = df['text'].apply(lambda x: translate_text(x, target_lang='ko'))\n",
        "\n",
        "# 번역된 결과를 새로운 CSV 파일로 저장\n",
        "df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "tfidf_top5 = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV 파일 경로\n",
        "input_file = \"./data/nlp/sbert_top5.csv\"\n",
        "output_file = \"./data/nlp/sbert_top5_translated.csv\"\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# text 컬럼 번역\n",
        "df['translated_text'] = df['text'].apply(lambda x: translate_text(x, target_lang='ko'))\n",
        "\n",
        "# 번역된 결과를 새로운 CSV 파일로 저장\n",
        "df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "sbert_top5 = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV 파일 경로\n",
        "input_file = \"./data/nlp/hybrid_top5.csv\"\n",
        "output_file = \"./data/nlp/hybrid_top5_translated.csv\"\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# text 컬럼 번역\n",
        "df['translated_text'] = df['text'].apply(lambda x: translate_text(x, target_lang='ko'))\n",
        "\n",
        "# 번역된 결과를 새로운 CSV 파일로 저장\n",
        "df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "hybrid_top5 = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_top5['translated_text'][1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sbert_top5['translated_text'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hybrid_top5['translated_text'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Metacode Lecture (Python 3.13)",
      "language": "python",
      "name": "metacode-lecture"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
