{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2-3, 2-1강 시계열 예측 모델링 — Classical & Baselines (Bike Sharing)\n",
        "\n",
        "- **목표**: 회귀(선형/랜덤포레스트), 시계열 전용(SARIMA/Prophet) 모델을 단계별로 학습·평가하여 비교합니다.\n",
        "- **데이터**: Kaggle Bike Sharing Demand (시간 단위, `count` 대상)\n",
        "- **규칙(강의용)**: `matplotlib`만 사용 (seaborn X), 색상 지정 X, 서브플롯 X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 강의 개요 및 학습 목표\n",
        "- 시계열 예측의 중요성과 활용: 수요/재고/인력/교통/에너지 등\n",
        "- 일반 회귀 vs 시계열 모델 차이: IID 가정 vs 자기상관/계절성/추세\n",
        "- 실습을 통한 모델 성능 비교 학습 및 해석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. 환경 준비 및 라이브러리 임포트\n",
        "\n",
        "- 시각화는 `matplotlib`만 사용합니다.\n",
        "- 회귀 모델(`scikit-learn`), 시계열(`statsmodels`), Prophet(선택)을 사용합니다.\n",
        "- 한글 폰트와 경고 억제를 설정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    _HAS_PROPHET = True\n",
        "except Exception:\n",
        "    _HAS_PROPHET = False\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=r\"Glyph.*missing from font.*\", category=UserWarning)\n",
        "\n",
        "# 한글 폰트 설정\n",
        "import matplotlib\n",
        "matplotlib.rcParams[\"font.family\"] = \"sans-serif\"\n",
        "matplotlib.rcParams[\"font.sans-serif\"] = [\n",
        "    \"AppleGothic\",\"NanumGothic\",\"Malgun Gothic\",\"Noto Sans CJK KR\",\"Noto Sans KR\",\"DejaVu Sans\"\n",
        "]\n",
        "matplotlib.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 데이터 준비 및 전처리\n",
        "- `bike-sharing-demand/train.csv` 로드, `datetime` 파싱/정렬\n",
        "- 시간 파생변수 생성(년/월/일/요일/시간)\n",
        "- 시간 순서대로 train/val/test 분할\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_hourly_data():\n",
        "    path = 'bike-sharing-demand/train.csv'\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError('train.csv 경로를 찾을 수 없습니다.')\n",
        "    df = pd.read_csv(path)\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "    df = df.sort_values('datetime').reset_index(drop=True)\n",
        "    cols = ['datetime','season','holiday','workingday','weather','temp','atemp','humidity','windspeed','casual','registered','count']\n",
        "    return df[cols]\n",
        "\n",
        "\n",
        "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    out['year'] = out['datetime'].dt.year\n",
        "    out['month'] = out['datetime'].dt.month\n",
        "    out['day'] = out['datetime'].dt.day\n",
        "    out['dayofweek'] = out['datetime'].dt.dayofweek\n",
        "    out['hour'] = out['datetime'].dt.hour\n",
        "    return out\n",
        "\n",
        "\n",
        "def split_by_time(df: pd.DataFrame, train_ratio: float = 0.8, val_ratio: float = 0.1):\n",
        "    n = len(df)\n",
        "    n_train = int(n * train_ratio)\n",
        "    n_val = int(n * val_ratio)\n",
        "    train = df.iloc[:n_train]\n",
        "    val = df.iloc[n_train:n_train+n_val]\n",
        "    test = df.iloc[n_train+n_val:]\n",
        "    return train, val, test\n",
        "\n",
        "\n",
        "df = load_hourly_data()\n",
        "print('데이터 크기:', df.shape, '기간:', df['datetime'].min(), '→', df['datetime'].max())\n",
        "df_feat = add_time_features(df)\n",
        "train_df, val_df, test_df = split_by_time(df_feat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 일반 회귀 베이스라인: 선형 회귀 vs 랜덤포레스트\n",
        "- 입력: 시간 파생 + 기상/상태 변수, 타깃: `count`\n",
        "- 평가: MAE/MSE/RMSE/MAPE, 방향정확도(DA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-1. 정상성 검정 및 ACF/PACF 분석\n",
        "- ADF(정상성) 검정\n",
        "- ACF/PACF 시각화로 (p,d,q)(P,D,Q,s) 가이드 얻기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "adf_stat, pval, *_ = adfuller(daily.dropna())\n",
        "print(f'ADF 통계량={adf_stat:.3f}, p-value={pval:.5f}')\n",
        "plt.figure(figsize=(10,3))\n",
        "plot_acf(daily.dropna(), lags=30)\n",
        "plt.tight_layout(); plt.show()\n",
        "plt.figure(figsize=(10,3))\n",
        "plot_pacf(daily.dropna(), lags=30)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_supervised_features(df: pd.DataFrame, target: str = 'count'):\n",
        "    feature_cols = ['season','holiday','workingday','weather','temp','atemp','humidity','windspeed','year','month','day','dayofweek','hour']\n",
        "    X = df[feature_cols].copy()\n",
        "    X = pd.get_dummies(X, columns=['season','holiday','workingday','weather','year','month','dayofweek','hour'], drop_first=False)\n",
        "    y = df[target].astype(float)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    mae = float(mean_absolute_error(y_true, y_pred))\n",
        "    mse = float(mean_squared_error(y_true, y_pred))\n",
        "    rmse = float(np.sqrt(mse))\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        mape = float(np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), 1e-8, None))) * 100.0)\n",
        "    prev = np.concatenate([[y_true[0]], y_true[:-1]])\n",
        "    da = float(np.mean((np.sign(y_true - prev) == np.sign(y_pred - prev)).astype(float)))\n",
        "    return mae, mse, rmse, mape, da\n",
        "\n",
        "\n",
        "def plot_actual_vs_pred(dt_index, y_true, y_pred, title):\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.plot(dt_index, y_true, label='Actual')\n",
        "    plt.plot(dt_index, y_pred, label='Pred')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "X_train, y_train = to_supervised_features(train_df)\n",
        "X_val, y_val = to_supervised_features(val_df)\n",
        "X_test, y_test = to_supervised_features(test_df)\n",
        "\n",
        "lin = LinearRegression().fit(X_train, y_train)\n",
        "lin_val_pred = lin.predict(X_val)\n",
        "lin_test_pred = lin.predict(X_test)\n",
        "print('Linear/VAL', compute_metrics(y_val.to_numpy(), lin_val_pred))\n",
        "print('Linear/TEST', compute_metrics(y_test.to_numpy(), lin_test_pred))\n",
        "plot_actual_vs_pred(val_df['datetime'].values, y_val.to_numpy(), lin_val_pred, '선형회귀 검증 예측 vs 실제')\n",
        "plot_actual_vs_pred(test_df['datetime'].values, y_test.to_numpy(), lin_test_pred, '선형회귀 테스트 예측 vs 실제')\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_val_pred = rf.predict(X_val)\n",
        "rf_test_pred = rf.predict(X_test)\n",
        "print('RF/VAL', compute_metrics(y_val.to_numpy(), rf_val_pred))\n",
        "print('RF/TEST', compute_metrics(y_test.to_numpy(), rf_test_pred))\n",
        "plot_actual_vs_pred(val_df['datetime'].values, y_val.to_numpy(), rf_val_pred, '랜덤포레스트 검증 예측 vs 실제')\n",
        "plot_actual_vs_pred(test_df['datetime'].values, y_test.to_numpy(), rf_test_pred, '랜덤포레스트 테스트 예측 vs 실제')\n",
        "\n",
        "try:\n",
        "    importances = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "    print('RF 중요도 TOP 15:\\n', importances.head(15))\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 하이퍼파라미터 최적화 & 시계열 교차검증\n",
        "- `TimeSeriesSplit`을 이용한 교차검증\n",
        "- 랜덤포레스트 간단 Grid Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "\n",
        "X_all, y_all = to_supervised_features(df_feat)\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "params = {\"n_estimators\": [200, 300], \"max_depth\": [None, 12, 24]}\n",
        "rf_gs = GridSearchCV(RandomForestRegressor(random_state=42, n_jobs=-1), param_grid=params, cv=tscv, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
        "rf_gs.fit(X_all, y_all)\n",
        "print('최적 하이퍼파라미터:', rf_gs.best_params_)\n",
        "print('CV RMSE:', -rf_gs.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. 앙상블 모델링 (가중 평균)\n",
        "- 선형회귀와 랜덤포레스트의 검증 예측을 가중 평균\n",
        "- 검증 성능으로 가중치 선택 후 테스트 평가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_ensemble(y1, y2, w):\n",
        "    return w*y1 + (1-w)*y2\n",
        "\n",
        "best_w, best_rmse = None, float('inf')\n",
        "for w in np.linspace(0,1,11):\n",
        "    ens = weighted_ensemble(lin_val_pred, rf_val_pred, w)\n",
        "    _, _, rmse, _, _ = compute_metrics(y_val.to_numpy(), ens)\n",
        "    if rmse < best_rmse:\n",
        "        best_rmse = rmse\n",
        "        best_w = w\n",
        "print(f'검증기반 최적 가중치 w={best_w:.2f}, RMSE={best_rmse:.3f}')\n",
        "\n",
        "ens_test = weighted_ensemble(lin_test_pred, rf_test_pred, best_w)\n",
        "print('Ensemble(TEST)', compute_metrics(y_test.to_numpy(), ens_test))\n",
        "plot_actual_vs_pred(test_df['datetime'].values, y_test.to_numpy(), ens_test, '앙상블 테스트 예측 vs 실제')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. 잔차 분석\n",
        "- 테스트 구간 잔차 시각화 및 분포 확인\n",
        "- 패턴/이분산/비정상성 여부 점검\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "residual = y_test.to_numpy() - rf_test_pred\n",
        "plt.figure(figsize=(12,3.5))\n",
        "plt.plot(test_df['datetime'].values, residual)\n",
        "plt.title('잔차 시계열 (RF)')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(residual, bins=30)\n",
        "plt.title('잔차 분포 (RF)')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. 강의 요약 및 다음 단계\n",
        "- 모델별 지표 비교 및 해석 정리\n",
        "- 시계열 특성(계절/추세/자기상관)을 반영한 모델 선택 가이드\n",
        "- 다음 강의: LSTM/딥러닝 확장 및 하이브리드/앙상블 고도화\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 시계열 전용 모델: SARIMA, Prophet(선택)\n",
        "- 일 단위 평균으로 집계 후 예측\n",
        "- SARIMA 기본 파라미터로 시연, Prophet은 설치 시 실행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def aggregate_daily(df: pd.DataFrame) -> pd.Series:\n",
        "    return df.set_index('datetime')['count'].resample('D').mean()\n",
        "\n",
        "\n",
        "daily = aggregate_daily(df)\n",
        "N = len(daily)\n",
        "N_tr, N_va = int(N*0.8), int(N*0.1)\n",
        "daily_tr = daily.iloc[:N_tr]\n",
        "daily_va = daily.iloc[N_tr:N_tr+N_va]\n",
        "daily_te = daily.iloc[N_tr+N_va:]\n",
        "\n",
        "sar = SARIMAX(daily_tr, order=(1,1,1), seasonal_order=(1,1,1,7), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
        "va_fc = sar.forecast(steps=len(daily_va)).to_numpy()\n",
        "te_fc = SARIMAX(daily_tr.append(daily_va), order=(1,1,1), seasonal_order=(1,1,1,7), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False).forecast(steps=len(daily_te)).to_numpy()\n",
        "\n",
        "print('SARIMA/VAL', compute_metrics(daily_va.to_numpy(), va_fc))\n",
        "print('SARIMA/TEST', compute_metrics(daily_te.to_numpy(), te_fc))\n",
        "plot_actual_vs_pred(daily_va.index, daily_va.to_numpy(), va_fc, 'SARIMA 검증 예측 vs 실제 (일)')\n",
        "plot_actual_vs_pred(daily_te.index, daily_te.to_numpy(), te_fc, 'SARIMA 테스트 예측 vs 실제 (일)')\n",
        "\n",
        "if _HAS_PROPHET:\n",
        "    dprop = pd.DataFrame({'ds': daily_tr.index, 'y': daily_tr.values})\n",
        "    m = Prophet(seasonality_mode='additive', weekly_seasonality=True, daily_seasonality=False, yearly_seasonality=False)\n",
        "    m.fit(dprop)\n",
        "    future = pd.DataFrame({'ds': pd.date_range(start=daily_tr.index[-1] + pd.Timedelta(days=1), periods=len(daily_va), freq='D')})\n",
        "    yhat_val = m.predict(future)['yhat'].to_numpy()\n",
        "    print('Prophet/VAL', compute_metrics(daily_va.to_numpy(), yhat_val))\n",
        "else:\n",
        "    print('Prophet 미설치: 건너뜀')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 성능 비교 요약\n",
        "- MAE, MSE, RMSE, MAPE, 방향정확도(DA) 지표 비교\n",
        "- 모델별 예측 vs 실제 시각화로 패턴 비교\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
